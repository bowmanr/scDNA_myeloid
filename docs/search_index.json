[["index.html", "Single cell mutational profiling delineates clonal trajectories in myeloid malignancies Chapter 1 Foreward", " Single cell mutational profiling delineates clonal trajectories in myeloid malignancies Robert Bowman 2021-05-10 Chapter 1 Foreward What you’ll find here is a walk-through on how we analyzed the data in the manuscript here. This is one of the largest projects I have undertaken, and one of the first where I have made a concerted effort to make the code completely available, and easily accessible. I think like most of my biologically-trained peers, the idea of sharing all of the code in the project, and its’ certain inefficiencies, is a humbling process. I am excited to hear feedback on our approach, and am sure there are many places where the code, the approach, and the science can be improved. Given the rate of progress in the single cell field as a whole, I anticipate that many of the approaches we employed here will be quickly updated with new ones as time goes on. Infact, even as we completed this project, sample handling was changed as new R packages were rolled out from the team out at Mission Bio. I’ll keep this updated with our most recent approaches as I anticiapte this will continue to change rapidly. All inquiries on bioinformatic troubleshooting or methodology can be referred to myself (Bobby, bowmanr@mskcc.org, bowman_rl. Linde Miles (milesl@mskcc.org lindemilesphd) is the approrpiate person to direct questions toward for the wet lab work including sample preparation, library preparation and sequencing. For anything else, you’re probably best off emailing me, Linde and Ross (leviner@mskcc.org, rosslevinemd) collectively, we’re all very invested in seeing others harvest more out of this data. "],["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction To begin, I assume that you have read through our paper on Biorxiv, and I hope to update this one day with a link to a peer reviewed journal. I’ll summarize our goals briefly. We sought to: + Understand the genetic makeup of myeloid malignancy on a single cell level. + Determine the number, size, and diversity of clones as disease progressed. + Identify patterns of comutation, and abundance in dominant vs minor clones. + Determine if genetic alterations, alone or in combination, altered the immunophenotype of malignant cells. In order to acheive these goals, we used a commercial platform from Mission Bio called Tapestri. Conflict of interest statements can be found in our manuscript on Biorxiv. In short, this methodology uses single cell droplet encapsulation and barcoded beads to perform amplicon next generation sequencing. We designed a custom panel to focus on the 30 most commonly mutated genes in myeloid malignancies. Full details on the panel and sample processing can be found in the manuscript. A work flow is presented below: Much of the upfront analysis is performed on the Tapestri Pipeline produced by Mission Bio available on the Bluebee platform. I will defer all questions on the exact details of the parameters used in this phase of analysis to the Mission Bio team. I would suggest reading here and here as starting points. Here we will primarily with how the data was processed downstream in R and to the right of the red dashed line. Our primary output from Bluebee as the .loom file which contained a useful formating of the multi sample VCF file produced by GATK. For the publication, this .loom file was loaded into Tapestri Insights, a GUI from Mission Bio that allowed for sample filtering based on parameters described in the manuscript. From there a filtered set of cells were exported from Tapestri Insights, and matrices for each column of the VCF file were produced. I will include some of this code and decription of why we did it this way in an Appendix A, but since then, MissionBio has releassed a convenient R package and I find all future analyses will go from there. So, instead, this guide will use their package, I anticipate some of the data might change from our publication, but I guess we’ll see. "],["data-extraction-and-setup.html", "2.1 Data Extraction and Setup", " 2.1 Data Extraction and Setup This section will explore how we take the data from the tapestri pipeline and process it in R. This was previously done with an intermediate step through Tapestri Insights, however R package development from the Mission Bio team has now obviated that step. For the manuscript, we indeed used Tapestri Insights, but I now recommend the appraoch here. One major file we’ll work with the numeric genotype matrix, which contains numeric values representing: NGT.csv - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown). Calls are made by GATK/Haplotypecaller. "],["hdf5-and-loom-input.html", "2.2 HDF5 and Loom input", " 2.2 HDF5 and Loom input This is a very quick example of how data can be loaded into R using loom and h5 files without the tapestri package. For the H5 files from tapestri pipeline v2, I found the rhdf5 package rather intuitive, even though the loomR package is largely based on hdf5r. It is unlikely that the code below is the most efficient way to load and extract these files, so part of this might not be helpful if you are already familiar with the hdf5 format. What may be helpful is the logic and order of events we take for filtering variants and cells of interet. See sample data on github and google drive library(rhdf5) library(dplyr) library(tidyr) setwd(&quot;/Users/bowmanr/Projects/scDNA/scDNA_myeloid/&quot;) file&lt;-(&quot;./data/Sample17020.dna_protein.h5&quot;) First the extraction of protein data, which is very straightforward. This can be later subset on which cells are preserved after genotype filtering. See latter sections for normalization. protein_mat&lt;-h5read(file=file,name=&quot;/assays/protein_read_counts/layers/read_counts&quot;) rownames(protein_mat) &lt;- h5read(file=file,name=&quot;/assays/protein_read_counts/ca/id&quot;) colnames(protein_mat)&lt;- h5read(file=file,name=&quot;/assays/protein_read_counts/ra/barcode&quot;) print(rownames(protein_mat)) ## [1] &quot;CD10&quot; &quot;CD117&quot; &quot;CD11b&quot; &quot;CD11c&quot; ## [5] &quot;CD123&quot; &quot;CD13&quot; &quot;CD138&quot; &quot;CD14&quot; ## [9] &quot;CD141&quot; &quot;CD16&quot; &quot;CD163&quot; &quot;CD19&quot; ## [13] &quot;CD1c&quot; &quot;CD2&quot; &quot;CD22&quot; &quot;CD25&quot; ## [17] &quot;CD3&quot; &quot;CD30&quot; &quot;CD303&quot; &quot;CD304&quot; ## [21] &quot;CD33&quot; &quot;CD34&quot; &quot;CD38&quot; &quot;CD4&quot; ## [25] &quot;CD44&quot; &quot;CD45&quot; &quot;CD45RA&quot; &quot;CD45RO&quot; ## [29] &quot;CD49d&quot; &quot;CD5&quot; &quot;CD56&quot; &quot;CD62L&quot; ## [33] &quot;CD62P&quot; &quot;CD64&quot; &quot;CD69&quot; &quot;CD7&quot; ## [37] &quot;CD71&quot; &quot;CD8&quot; &quot;CD83&quot; &quot;CD90&quot; ## [41] &quot;Fc&amp;#949;RI&amp;#945;&quot; &quot;HLA-DR&quot; &quot;IgG1&quot; &quot;IgG2a&quot; ## [45] &quot;IgG2b&quot; print((protein_mat)[1:5,1:5]) ## AACAACCTAACGAATCGC AACAACCTACCTCTGCAT AACAACCTAGGTGATAGG ## CD10 145 168 45 ## CD117 54 179 50 ## CD11b 68 578 94 ## CD11c 23 308 5 ## CD123 120 241 40 ## AACAACCTAGTCACAGAG AACAACTGGCAGATCATT ## CD10 31 320 ## CD117 46 1017 ## CD11b 53 422 ## CD11c 6 145 ## CD123 48 602 Now we will move to extracting variant data. For the sake of processing time, we will first impose a cutoff that a given variant must be present in at least 1% of cells. This is a cutoff we used in our manuscript. This is a subjective cutoff, and will likely be a varying feature for many studies. VAF_cutoff &lt;- 0.01 NGT&lt;-h5read(file=file,name=&quot;/assays/dna_variants/layers/NGT&quot;) NGT[NGT==3]&lt;-NA VAF_select&lt;-which((rowSums(NGT,na.rm=TRUE)/(ncol(NGT)*2))&gt;VAF_cutoff) AF&lt;-h5read(file=file,name=&quot;/assays/dna_variants/layers/AF&quot;,index=list(VAF_select,NULL)) DP&lt;-h5read(file=file,name=&quot;/assays/dna_variants/layers/DP&quot;,index=list(VAF_select,NULL)) GQ&lt;-h5read(file=file,name=&quot;/assays/dna_variants/layers/GQ&quot;,index=list(VAF_select,NULL)) NGTlim&lt;-h5read(file=file,name=&quot;/assays/dna_variants/layers/NGT&quot;,index=list(VAF_select,NULL)) NGTlim[NGTlim==3]&lt;-NA variants&lt;-h5read(file=file,name=&quot;/assays/dna_variants/ca/id&quot;,index=list(VAF_select)) cell_barcodes &lt;-h5read(file=file,name=&quot;/assays/dna_variants/ra/barcode&quot;) colnames(NGTlim) &lt;-cell_barcodes rownames(NGTlim) &lt;- variants print(rownames(NGTlim)[1:5]) ## [1] &quot;chr1:43815097:T/C&quot; &quot;chr1:115256538:G/A&quot; &quot;chr1:115256539:T/C&quot; ## [4] &quot;chr1:115256539:T/G&quot; &quot;chr1:115256540:A/G&quot; print(NGTlim[1:5,1:5]) ## AACAACCTAACGAATCGC AACAACCTACCTCTGCAT AACAACCTAGGTGATAGG ## chr1:43815097:T/C 1 NA 0 ## chr1:115256538:G/A 0 0 0 ## chr1:115256539:T/C NA NA NA ## chr1:115256539:T/G NA NA NA ## chr1:115256540:A/G 0 0 0 ## AACAACCTAGTCACAGAG AACAACTGGCAGATCATT ## chr1:43815097:T/C 0 1 ## chr1:115256538:G/A 0 1 ## chr1:115256539:T/C 0 1 ## chr1:115256539:T/G 0 0 ## chr1:115256540:A/G 0 0 dim(NGTlim) ## [1] 105 6315 Now alternatively with loom files from tapestri pipeline v1, where you will also want the VCF header file to extract cell barcodes. This is not strictly necessary for DNA only analysis, but critical for integration with protein. I imagine most users will be working with v2 data, but I leave it here for you incase you need it, or are replicating data from our initial manuscript. It is worth noting that the matrices from the loom files are transposed compared to the H5, hence the t() to orient them for consistent downstream processing. library(loomR) setwd(&quot;/Users/bowmanr/Projects/scDNA/scDNA_myeloid/&quot;) lfile &lt;- connect(filename = &quot;./data/MSK91_IGO_09868_L_7_S7_R_191122041131.cells.loom&quot;, mode = &quot;r&quot;) NGT&lt;-t(lfile$matrix[,]) NGT[NGT==3]&lt;-NA VAF_select&lt;-which((rowSums(NGT,na.rm=TRUE)/(ncol(NGT)*2))&gt;VAF_cutoff) VAF_cutoff &lt;- 0.01 DP &lt;- t(lfile$layers$DP[,VAF_select]) GQ &lt;- t(lfile$layers$GQ[,VAF_select]) AF &lt;- t(lfile$layers$AD[,VAF_select])/DP *100 NGTlim&lt;-t(lfile$matrix[,VAF_select]) NGTlim[NGTlim==3]&lt;-NA variants&lt;-lfile$row.attrs$id[VAF_select] #for loom files from Tapestri v1 cell_barcodes &lt;-names(read.delim(&quot;./data/MSK91.vcf_header.txt&quot;,sep=&quot;\\t&quot;)) colnames(NGTlim) &lt;-cell_barcodes rownames(NGTlim) &lt;- variants The v2 pipeline also outputs loom files, but given the easy packaging of protein and DNA data in the single H5 file, I can’t find a good reason to use the loom. Nevertheless, small differences in formatting are observed. #for loom files from Tapestri v2 you do not need the VCF header file. cell_barcodes &lt;-lfile$col.attrs$barcode[] Now let’s filter the data using the default cutoffs from Tapestri Insights and what we used in our manuscript. DP_cut=10 #read depth AF_cut=20 #allele frequency cutoff GQ_cut=30 #geotype quality cutoff variant_presence_cutoff=50 #variant must be genotyped in greater than 50% of cells cell_genotype_cutoff=50 # cell must possess genotype information for at least 50% of the variants of interest #bind together long form AF, DP, GQ and NGT data filtered_long&lt;-data.frame(setNames( # produce long form allele frequency data data.frame(AF, &quot;variants&quot;=variants), c(all_of(cell_barcodes),&quot;variants&quot;)) %&gt;% pivot_longer(cols=!c(variants), names_to=&quot;Cell&quot;, values_to=&quot;AF&quot;), #produce long form allele depth data data.frame(DP)%&gt;% pivot_longer(cols=everything(), names_to=&quot;Cell&quot;, values_to=&quot;DP&quot;)%&gt;%dplyr::select(DP), #produce long form genotype quality data data.frame(GQ)%&gt;% pivot_longer(cols=everything(), names_to=&quot;Cell&quot;, values_to=&quot;GQ&quot;)%&gt;%dplyr::select(GQ), #produce long form genotype call data data.frame(NGTlim)%&gt;% pivot_longer(cols=everything(), names_to=&quot;Cell&quot;, values_to=&quot;NGT&quot;)%&gt;%dplyr::select(NGT)) %&gt;% #filter DP and GQ filter(DP&gt;DP_cut&amp; GQ&gt;GQ_cut)%&gt;% #filter AF for each genotype call mutate(pass=case_when( NGT==1&amp;(AF&gt;AF_cut)&amp;(AF&lt;(100-AF_cut)) ~ &quot;include&quot;, NGT==1&amp;((AF&lt;=AF_cut)|(AF&gt;=(100-AF_cut))) ~ &quot;exclude&quot;, NGT==2&amp;AF&gt;=(100-AF_cut) ~ &quot;include&quot;, NGT==2&amp;AF&lt;(100-AF_cut) ~ &quot;exclude&quot;, NGT==0&amp;AF&lt;=AF_cut ~ &quot;include&quot;, NGT==0&amp;AF&gt;AF_cut ~ &quot;exclude&quot;, TRUE ~&quot;other&quot; ))%&gt;% filter(pass==&quot;include&quot;) # here we check to make sure a variant is not NA (genotype 3) in &gt;50% of cells # we can also filter out variants that are likely SNPs and only show up as WT, het or homozygous This assumes SNPs would never undergo allele dropout, which is pretty unlikely, so this filter is not realistic. I leave it here incase it is helpful to someone. final_variants &lt;-filtered_long%&gt;% group_by(variants)%&gt;% summarize(diversity=sum(c(0,1,2)%in%NGT), gt.mv=(length(NGT)/length(all_of(cell_barcodes)))*100)%&gt;% filter(#diversity&gt;1&amp; gt.mv&gt;variant_presence_cutoff)%&gt;% pull(variants) # here we filter for cells that now contain genotype information for atleast 50% of our curated set of variants. final_cells&lt;- filtered_long%&gt;% filter(variants%in%final_variants)%&gt;% group_by(Cell)%&gt;% summarize(gt.mc=(length(NGT)/length(all_of(final_variants)))*100)%&gt;% filter(gt.mc&gt;=cell_genotype_cutoff)%&gt;% pull(Cell) # lastly we reconsstruct a new NGT matrix of cell-genotype pairs that passsed the above filters. final_NGT&lt;- filtered_long%&gt;% filter(Cell%in%final_cells&amp;variants%in%final_variants)%&gt;% pivot_wider(id_cols=Cell,names_from=variants,values_from=NGT) Below is some code on how we can annotate the variants. I manually curated a transcript ID table for our genes of interest so that when the protein changes were reported they were consistent with the common hotspot mutations in which we are interested. The lines below introduce the required packages and how to create a limted TxDB object. would suggest just running this once and saving an rds object. It’s a little time intensive. library(VariantAnnotation) library(GenomicRanges) library(magrittr) require(RMariaDB) library(plyranges) library(BSgenome.Hsapiens.UCSC.hg19) library(TxDb.Hsapiens.UCSC.hg19.knownGene) annotation_key &lt;-read.csv(&quot;./data/annotation_key.csv&quot;) hg19refseq_txdb &lt;- makeTxDbFromUCSC(genome=&quot;hg19&quot;, transcript_ids=annotation_key$ccds_id, tablename=&quot;ccdsGene&quot;) annotation_key%&lt;&gt;%inner_join(select(hg19refseq_txdb, keys=annotation_key$ccds_id, columns=c(&quot;TXID&quot;,&quot;TXNAME&quot;), keytype = &quot;TXNAME&quot;), by=c(&quot;ccds_id&quot;=&quot;TXNAME&quot;))%&gt;% mutate(TXID=as.character(TXID)) For H5 files from v2 pipeline. banned &lt;-read.csv(&quot;./data/banned_list.csv&quot;) SNV_mat&lt;-data.frame(do.call(cbind, h5read(file=file,name=&quot;/assays/dna_variants/ca/&quot;, index=list(VAF_select)))) %&gt;% filter(id%in%final_variants&amp; !id%in%banned[,1])%&gt;% mutate(ALT=ifelse(ALT==&quot;*&quot;,&quot;N&quot;,ALT))%&gt;% mutate(CHROM=paste0(&quot;chr&quot;,CHROM)) For loom files from v1 pipeline lfile &lt;- connect(filename = &quot;./data/MSK91_IGO_09868_L_7_S7_R_191122041131.cells.loom&quot;, mode = &quot;r&quot;) SNV_mat&lt;-data.frame(do.call(cbind, list(&quot;ALT&quot;=lfile$row.attrs$ALT[], &quot;CHROM&quot;=lfile$row.attrs$CHROM[], &quot;POS&quot;=lfile$row.attrs$POS[], &quot;QUAL&quot;=lfile$row.attrs$QUAL[], &quot;REF&quot;=lfile$row.attrs$REF[], &quot;amplicon&quot;=lfile$row.attrs$amplicon[], &quot;id&quot;=lfile$row.attrs$id[]))) %&gt;% filter(id%in%final_variants&amp; !id%in%banned[,1])%&gt;% mutate(ALT=ifelse(ALT==&quot;*&quot;,&quot;N&quot;,ALT))%&gt;% mutate(CHROM=paste0(&quot;chr&quot;,CHROM)) Now we will map the variants of interest to genes, and if they land in a coding exon, predict the amino acid change. For INDELs this gets messy, still trying to figure out how too name them nicely (and open to feedback!). The printed results below are for the H5 input described above. #necessary for meaningful GRangess SNV_mat$REF&lt;-as(SNV_mat$REF, &quot;DNAStringSet&quot;) SNV_mat$ALT&lt;-as(SNV_mat$ALT, &quot;DNAStringSet&quot;) variant_gRange&lt;-makeGRangesFromDataFrame(SNV_mat, seqnames.field = &quot;CHROM&quot;, start.field=&quot;POS&quot;, end.field=&quot;POS&quot;, keep.extra.columns=TRUE) #necessary for downstream joining of variant_gRange$QUERYID&lt;-1:length(variant_gRange) #identify and isolate non coding variants non_coding_variants &lt;- locateVariants(variant_gRange, hg19refseq_txdb, AllVariants())%&gt;% data.frame()%&gt;% filter(as.character(LOCATION)!=&quot;coding&quot;)%&gt;% inner_join(variant_gRange,by=&quot;QUERYID&quot;,copy=TRUE) ## Warning in valid.GenomicRanges.seqinfo(x, suggest.trim = TRUE): GRanges object contains 5 out-of-bound ranges located on sequences 17, ## 24, 26, and 30. Note that ranges located on a sequence whose length is ## unknown (NA) or on a circular sequence are not considered out-of-bound ## (use seqlengths() and isCircular() to get the lengths and circularity ## flags of the underlying sequences). You can use trim() to trim these ## ranges. See ?`trim,GenomicRanges-method` for more information. #identify and isolate coding variants coding_variants &lt;- predictCoding(variant_gRange, hg19refseq_txdb, seqSource=Hsapiens, varAllele=variant_gRange$ALT)%&gt;% data.frame() ## Warning in valid.GenomicRanges.seqinfo(x, suggest.trim = TRUE): GRanges object contains 5 out-of-bound ranges located on sequences 17, ## 24, 26, and 30. Note that ranges located on a sequence whose length is ## unknown (NA) or on a circular sequence are not considered out-of-bound ## (use seqlengths() and isCircular() to get the lengths and circularity ## flags of the underlying sequences). You can use trim() to trim these ## ranges. See ?`trim,GenomicRanges-method` for more information. #Bind it all together into one big table. out &lt;- bind_rows(non_coding_variants,coding_variants) %&gt;% inner_join(annotation_key)%&gt;% mutate(AA=ifelse(!is.na(REFAA), paste0(gene_name,&quot;.&quot;,REFAA,PROTEINLOC,VARAA), paste0(gene_name,&quot;.intronic&quot;)))%&gt;% dplyr::select(id,AA) #append Bulk VAF for reference in future cutoffs and allele selection final_mutation_info&lt;-data.frame(out, &quot;Bulk_VAF&quot;=colSums(final_NGT[,out$id], na.rm=TRUE)/ (nrow(final_NGT)*2)*100) print(head(final_mutation_info)) ## id AA Bulk_VAF ## 1 chr2:25463121:C/T DNMT3A.intronic 0.1979414 ## 2 chr2:25463483:G/A DNMT3A.intronic 45.1702296 ## 3 chr2:25464334:A/C DNMT3A.intronic 1.3855899 ## 4 chr2:198266943:C/T SF3B1.intronic 97.9018211 ## 5 chr2:209113048:G/GA IDH1.intronic 5.0910530 ## 6 chr3:128202879:C/T GATA2.intronic 0.1821061 "],["tapestri-package.html", "2.3 Tapestri Package", " 2.3 Tapestri Package The purpose of this section is to demonstrate how to extract the data. We will use the tapestri package. NOTE: I understand this package is no longer available, please stay tuned for details The tapestri package is available from Mission Bio. We’ll use this to read in our sample files. You’ll notice in a lot of the code, we are going to run loops and lapply over all of the samples. For reproducibility purposes, I am going to show a limited example on 5 samples for preprocessing, and later we will load an rds object with all the data in the paper. Critical files used for analysis can be found on google drive here. We’re working on getting all of the processsed and raw data up on dbGAP now. Next, make a project folder and set the working directory to that folder: setwd(&quot;/Users/bowmanr/Projects/scDNA&quot;) Load in the relevant packages we will use later. options(stringsAsFactors = FALSE) library(VariantAnnotation) library(plyranges) library(BSgenome.Hsapiens.UCSC.hg19) library(TxDb.Hsapiens.UCSC.hg19.knownGene) library(dplyr) library(tidyr) library(purrr) Place the downloaded files into a new folder called “data” also make an “analysis” folder. We’ll save things there frequently just to provide checkpoints so everything does not need to be run from scratch. system(&quot;mkdir /Users/bowmanr/Projects/scDNA/data&quot;) system(&quot;mkdir /Users/bowmanr/Projects/scDNA/analysis&quot;) The following took &lt;20 minutes for the 6 samples on my mac book, but obivously would take much longer for the whole cohort. The final step using the “convert_to_analyte” function in unnecessary, but you will see it comes into play when we merge with the DNA+protein data later in the paper. sample_set &lt;- list.files(&quot;./data/&quot;,full.names = TRUE) names(sample_set) &lt;-list.files(&quot;./data/&quot;) for(i in names(sample_set)){ barcode_files&lt;-grep(&quot;barcode&quot;,list.files(sample_set[i],full.names=TRUE),value=TRUE) loom_files&lt;-grep(&quot;loom$&quot;,list.files(sample_set[i],full.names=TRUE),value=TRUE) header_files&lt;-grep(&quot;vcf_header.txt$&quot;,list.files(sample_set[i],full.names=TRUE),value=TRUE) barcodes &lt;- read_barcodes(barcode_files,header_files) loom &lt;- connect_to_loom(loom_files) ngt_file &lt;- extract_genotypes(loom, barcodes, gt.filter=TRUE, gt.gqc = 30, gt.dpc = 10, gt.afc = 20, gt.mv = 50, gt.mc = 50, gt.mm = 1, gt.mask = TRUE) snv &lt;- convert_to_analyte(data=as.data.frame(ngt_file), type=&#39;snv&#39;, name=i) saveRDS(snv,paste0(&quot;./analysis/&quot;,i,&quot;.rds&quot;)) } "],["post-processing.html", "2.4 Post processing", " 2.4 Post processing Next we’ll read the files back in and put them into a list. After that I will walk through some steps we used to process the data a little further. Here we made a decision in the project to focus only on protein encoding SNVs, of course there is likely rich data in the splice mutations and that is for further followup. Importantly, we also made the decision to focus only on cells with complete genotype information, and exclude cells that had missing genotypes for a cell of interest. A complimentary manuscript by Koichi Takahashi’s group at MD Anderson analyzed their dataset, and I encourage whoever is reading this to take a look at their bioRxiv preprint. I’ll update this reference once they paper is published. Our steps for post processing are below: + Filter variants through a blacklist removing recurrent variants that we think are likely sequencing errors + Annotating SNVS for protein encoding functions, and removing synonymous and splice variants + Remove variants that are mutated in &lt;2 cells + Remove remaining cells with any unknown genotypes + Remove variants that are mutated in &lt;2 cells again now that we have removed cells that were low quality processed_SNV_files &lt;-grep(&quot;MSK&quot;,list.files(&quot;./analysis/&quot;,full.names = TRUE),value=TRUE) names(processed_SNV_files)&lt;-do.call(rbind,strsplit(grep(&quot;MSK&quot;,list.files(&quot;./analysis/&quot;),value=TRUE),split=&quot;\\\\.&quot;))[,1] SNV&lt;-setNames(lapply(names(processed_SNV_files),function(x){ y&lt;-readRDS(processed_SNV_files[x]) data.frame(&quot;Cell&quot;=rownames(y), # moving the cell name into data.frame prevents some errors later y$data) # extracts the genotype matrix from the analyte object }), names(processed_SNV_files)) So one important note is that the variant annotation we used in the manuscript was done with Tapesstri Insights. Which was quite convenient as it put out a 1:1 mapping of SNV to amino acid changes, presumably by having a list of preferred TXIDs for each gene. So I’ve outlined what I think is a decent approach to this here. Importantly, this approach removes variants that are not protein encoding, and thus removes splice variants txdb &lt;- TxDb.Hsapiens.UCSC.hg19.knownGene banned &lt;-read.delim(&quot;./data/banned_list.csv&quot;,sep=&quot;,&quot;) variants &lt;- lapply(SNV,function(x){ experimental_variants &lt;- colnames(x)[ !grepl(&quot;Cell&quot;,colnames(x))&amp; #remove the Cell column !grepl(&quot;^chr&quot;,colnames(x))&amp; #remove control loci !colnames(x)%in%banned[,1]] #remove banned SNVs variants_matrix&lt;-data.frame(experimental_variants, do.call(rbind,strsplit(experimental_variants,split=&quot;\\\\.&quot;))) colnames(variants_matrix) &lt;- c(&quot;SNV&quot;,&quot;gene&quot;,&quot;chr&quot;,&quot;start&quot;,&quot;ref&quot;,&quot;alt&quot;) variants_matrix$ref&lt;-as(variants_matrix$ref, &quot;DNAStringSet&quot;) variants_matrix$alt&lt;-as(variants_matrix$alt, &quot;DNAStringSet&quot;) variant_gRange&lt;-makeGRangesFromDataFrame(variants_matrix, seqnames.field = &quot;chr&quot;, start.field=&quot;start&quot;, end.field=&quot;start&quot;, keep.extra.columns=TRUE) out&lt;- predictCoding(variant_gRange, txdb, seqSource=Hsapiens,varAllele=variant_gRange$alt) out2&lt;-out%&gt;%filter(CONSEQUENCE==&quot;nonsynonymous&quot;)%&gt;% mutate(AA=paste0(gene,&quot;.&quot;,REFAA,PROTEINLOC,VARAA))%&gt;% select(SNV,AA) return(data.frame(out2)%&gt;%distinct(SNV,AA)) }) # Select the correct variants, this is an example. # Probably better off coming up with a list of TXIDs or CDSIDs you want for each gene. variants[[&quot;MSK15&quot;]]&lt;-variants[[&quot;MSK15&quot;]] %&gt;% filter(!AA%in%c(&quot;DNMT3A.R693C&quot;,&quot;DNMT3A.R446Q&quot;)) variants[[&quot;MSK18&quot;]]&lt;-variants[[&quot;MSK18&quot;]] %&gt;% filter(!AA%in%c(&quot;DNMT3A.R693C&quot;)) variants[[&quot;MSK71&quot;]]&lt;-variants[[&quot;MSK71&quot;]] %&gt;% filter(!AA%in%c(&quot;DNMT3A.Y685C&quot;)) variants[[&quot;MSK91&quot;]]&lt;-variants[[&quot;MSK91&quot;]] %&gt;% filter(!AA%in%c(&quot;IDH2.R88Q&quot;,&quot;IDH2.R10Q&quot;)) Now we’ll take this list of variants and subset the genotype matrices and proceed through the following steps: + Remove variants that are mutated in &lt;2 cells + Remove remaining cells with any unknown genotypes + Remove variants that are mutated in &lt;2 cells again now that we have removed cells that were low quality filtered_NGT&lt;-setNames(lapply(names(SNV),function(sample){ setNames(data.frame(SNV[[sample]][,c(&quot;Cell&quot;,as.character(variants[[sample]]$SNV))]), c(&quot;Cell&quot;,variants[[sample]]$AA)) }),names(SNV)) final_NGTs&lt;-setNames(lapply(names(filtered_NGT),function(x){ filtered_NGT[[x]] %&gt;% select_if(~ !is.numeric(.) || sum(.%in%c(1,2))&gt;=2) %&gt;% filter_all(all_vars(.!=3)) %&gt;% select_if(~ !is.numeric(.) || sum(.%in%c(1,2))&gt;=2) }),names(filtered_NGT)) "],["assessing-clonal-abundance.html", "2.5 Assessing clonal abundance", " 2.5 Assessing clonal abundance This will be the last code example that proceeds with our limited sample set. After this, the tutorial will procede with the data used in the manuscript. This analysis will focus only on samples that have greater than one mutation. The general workflow is as follows * Select samples that have at least 2 mutaions * Clone assigment * Tally clonal abundance * Establish a clonal abundance confidence itnerval # Select samples with at least 2 mutations clonal_sample_set &lt;- names(final_NGTs)[do.call(rbind,lapply(final_NGTs,dim))[,2]&gt;2] # Order columns based on computed_VAF, and assign a clone to each cell NGT_to_clone&lt;-lapply(final_NGTs[clonal_sample_set],function(y){ bulk_VAF_order &lt;-names(sort(colSums(y[,-1]),decreasing=TRUE)) y[,c(&quot;Cell&quot;,bulk_VAF_order)] %&gt;%unite(&quot;Clone&quot;,all_of(`bulk_VAF_order`),sep=&quot;_&quot;, remove = FALSE) }) # Tally clones clonal_abundance&lt;- lapply(NGT_to_clone,function(x){ x%&gt;%count(Clone,name=&quot;Count&quot;)%&gt;%arrange(Count) }) # Setup a resampling function to generate multiple clonal abundance tallies resample_fun&lt;-function(data){ x &lt;- data[sample(x=1:nrow(data),replace=TRUE),] return(as.matrix(x%&gt;%count(Clone,name=&quot;Count&quot;)%&gt;%arrange(Count))) } replicates &lt;- 100 # we did 10,000. Keeping it low here for run time. clone_cutoff &lt;- 10 # minimum number of cells in order to retain a clone clonal_abundance_boot_CI &lt;- lapply(names(NGT_to_clone),function(sample_to_test){ test&lt;-replicate(n=replicates,resample_fun(NGT_to_clone[[sample_to_test]]),simplify = &quot;array&quot;) if(class(test)==&quot;list&quot;){ y &lt;- setNames(lapply(test,data.frame),1:replicates) %&gt;% imap(.x = ., ~ set_names(.x, c(&quot;Clone&quot;, .y))) %&gt;% purrr::reduce(full_join, by = &quot;Clone&quot;)%&gt;% mutate_if(names(.)!=&quot;Clone&quot;,as.numeric)%&gt;% mutate_each(funs(replace(., is.na(.), 0))) } if(class(test)==&quot;array&quot;){ y &lt;- setNames(apply(test,3,data.frame),1:replicates) %&gt;% imap(.x = ., ~ set_names(.x, c(&quot;Clone&quot;, .y))) %&gt;% purrr::reduce(full_join, by = &quot;Clone&quot;)%&gt;% mutate_if(names(.)!=&quot;Clone&quot;,as.numeric)%&gt;% mutate_each(funs(replace(., is.na(.), 0))) } z &lt;- data.frame(t(apply(y%&gt;%select(-Clone),1,function(p){ quantile(p,probs=c(0.025,0.975)) })),&quot;Clone&quot;=y$Clone) set &lt;- setNames(data.frame(inner_join(data.frame(clonal_abundance[[sample_to_test]]),z,by=&quot;Clone&quot;)), c(&quot;Clone&quot;,&quot;Count&quot;,&quot;LCI&quot;,&quot;UCI&quot;))%&gt;%filter(LCI&gt;=clone_cutoff) }) names(clonal_abundance_boot_CI) &lt;-names(clonal_abundance) Now that we have a set of clones that we believe reproducibily have at least 10 cells, we remove cells and variants that are no longer represented at sufficient coverage. clone_filtered_NGTs &lt;- setNames(lapply(names(clonal_abundance_boot_CI),function(sample_to_test){ # Determine if there are any clones left to process if(nrow(clonal_abundance_boot_CI[[sample_to_test]])==0) { return(&quot;No clones after boostrapping&quot;) } # Determine if there are any mutations that are no longer found in a stable clone clone_matrix&lt;-as.matrix(do.call(rbind, strsplit(clonal_abundance_boot_CI[[sample_to_test]][,&quot;Clone&quot;],split=&quot;_&quot;))) mode(clone_matrix) &lt;- &quot;numeric&quot; colnames(clone_matrix) &lt;-colnames(NGT_to_clone[[sample_to_test]])[-c(1,2)] variants_to_remove&lt;-names(which(colSums(clone_matrix)==0)) # Check other conditions of interest that might remove sample from further processing if(nrow(clone_matrix)==1) { return(&quot;Only 1 clone left&quot;) }else if(length(setdiff(colnames(clone_matrix),c(variants_to_remove)))&lt;=1){ return(&quot;Removed all but 1 variant&quot;) }else { # Select only clones that survive the bootstrapping, and remove variants that fall out NGT_to_clone_subset &lt;- NGT_to_clone[[sample_to_test]]%&gt;% filter(Clone%in%clonal_abundance_boot_CI[[sample_to_test]]$Clone)%&gt;% select(!all_of(variants_to_remove)) # Create a key for the new and old clone names after removing variants that are no longer present clone_key &lt;- data.frame(&quot;New&quot;=apply(data.frame(clone_matrix)%&gt;%select(!all_of(variants_to_remove)),MARGIN=1, function(x){ paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}), &quot;Old&quot;=apply(data.frame(clone_matrix),MARGIN=1, function(x){ paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)})) # If there are any variants to remove and clones that need to be renamed if(any(clone_key$New!=clone_key$Old)){ NGT_to_clone_subset$Clone &lt;- sapply(NGT_to_clone_subset$Clone,function(x){ clone_key$New[match(x,clone_key$Old)]}) } return(NGT_to_clone_subset) } }),names(clonal_abundance_boot_CI)) One last step I find useful is to explicitly state the genotype of each mutation in each clone. This si useful for the clonotype plots we’ll make later. clonal_architecture &lt;- setNames(lapply(names(clonal_abundance_boot_CI),function(test_sample){ clonal_architecture&lt;-clone_filtered_NGTs[[test_sample]]%&gt;% dplyr::select(!Cell)%&gt;% distinct()%&gt;% pivot_longer(cols=!Clone, names_to=&quot;Mutant&quot;, values_to=&quot;Genotype&quot;) %&gt;% mutate(Genotype=ifelse(Genotype==3,NA, ifelse(Genotype==0,&quot;WT&quot;, ifelse(Genotype==1,&quot;Heterozygous&quot;, ifelse(Genotype==2,&quot;Homozygous&quot;,NA))))) }), names(clonal_abundance_boot_CI)) Lastly, we are going to package everything together into a list format for easy access later. final_sample_summary&lt;-setNames(lapply(names(clonal_architecture),function(sample){ return(list(&quot;Clones&quot;=clonal_abundance_boot_CI[[sample]], &quot;NGT&quot;=clone_filtered_NGTs[[sample]], &quot;Architecture&quot;=clonal_architecture[[sample]])) }),names(clonal_abundance_boot_CI)) saveRDS(final_sample_summary,file=&quot;./analysis/final_sample_summary.rds&quot;) "],["manuscript-analysis.html", "Chapter 3 Manuscript analysis", " Chapter 3 Manuscript analysis These files are going to look a little bit different than the ones we just made as far as protein nomenclature and the order of the columns in the NGT file. But this is the analysis that was used in the paper, and very little else should differ. These files are on GitHub here "],["figure-1-cohort-characterization.html", "3.1 Figure 1: Cohort characterization", " 3.1 Figure 1: Cohort characterization Let’s start by loading in some packages that are recurrently used. Other packages that are only used in one chunk of code are listed appropriately below. library(dplyr) library(tidyr) library(ggplot2) library(tidyselect) Here we will focus on the cohort level analysis, and load in the NGT files before they were filtered for clonality. setwd(&quot;/Users/bowmanr/Projects/scDNA&quot;) final_NGTs&lt;-readRDS(file=&quot;./data/final_NGTs.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) One filter we put in was to exclude samples &lt;100 cells. high_quality_samples&lt;-names(final_NGTs)[sapply(names(final_NGTs),function(x){ nrow(final_NGTs[[x]])&gt;100 })] Next we want a catalogue of all mutations so we can determine how many patients were mutated for each gene and how many different mutations were seen in total for each gene. final_mut_melt&lt;-do.call(rbind,lapply(names(final_NGTs),function(x){ data.frame(&quot;Sample&quot;=x, &quot;Mutation&quot;=colnames(final_NGTs[[x]]), &quot;Gene&quot;=do.call(rbind,strsplit(colnames(final_NGTs[[x]]),split=&quot;[:_]&quot;))[,1]) })) Next pages will go into how we made each of the Figures. 3.1.1 Cohort characteristics (EF1A-D) Now we can start to make the plots that are in Extended Figure 1. Starting with the total number of mutations identified per gene ## Set the levels of the Gene column from most to least prevalent for plotting purposes final_mut_melt$Gene&lt;- factor(final_mut_melt$Gene,levels=names(sort(table(final_mut_melt$Gene), decreasing=TRUE))) gg_mut_count&lt;-ggplot(final_mut_melt,aes(x=Gene))+ geom_bar(stat=&quot;count&quot;)+ theme_classic(base_size = 10)+ ylab(&quot;Count&quot;)+ ggtitle(&quot;Number of mutations&quot;)+ theme(axis.text.x = element_text(angle=45, hjust=1,vjust=1), plot.title=element_text(hjust=0.5))+ scale_y_continuous(expand=c(0,0)) Total number of patients mutated for each gene ## tally of how many mutations per patient melted_mut_mat&lt;- final_mut_melt%&gt;%dplyr::count(Gene, Sample) ## Set the levels of the Gene column from most to least prevalent for plotting purposes melted_mut_mat$Gene&lt;- factor(melted_mut_mat$Gene,levels=names(sort(table(melted_mut_mat$Gene),decreasing=TRUE))) gg_mut_patient&lt;-ggplot(melted_mut_mat,aes(x=Gene))+ geom_bar(stat=&quot;count&quot;)+ theme_classic(base_size =10)+ ylab(&quot;Count&quot;)+ggtitle(&quot;Number of patients with mutation&quot;)+ theme(axis.text.x = element_text(angle=45,hjust=1,vjust=1), plot.title=element_text(hjust=0.5))+ scale_y_continuous(expand=c(0,0)) Number of mutated genes per patient gg_mutated_genes_per_patient&lt;-final_mut_melt%&gt;% distinct(Sample,Gene)%&gt;% group_by(Sample)%&gt;% tally%&gt;% ggplot(aes(x=n))+geom_bar()+ ylab(&quot;Count&quot;)+ xlab(&quot;Number of genes&quot;)+ ggtitle(&quot;Mutant genes per patient&quot;)+ theme_classic(base_size = 10)+ theme(plot.title=element_text(hjust=0.5))+ scale_y_continuous(expand=c(0,0))+ scale_x_continuous(expand=c(0,0),n.breaks=8) Total number of mutations per patient gg_mutations_per_patient&lt;- final_mut_melt%&gt;% group_by(Sample)%&gt;% tally%&gt;% ggplot(aes(x=n))+geom_bar()+ theme_classic(base_size = 10)+ theme(plot.title=element_text(hjust=0.5))+ ylab(&quot;Count&quot;)+ggtitle(&quot;Variants per patient&quot;)+xlab(&quot;Number of variants&quot;)+ scale_y_continuous(expand=c(0,0))+ scale_x_continuous(expand=c(0,0),n.breaks=6) library(cowplot) plot_grid(gg_mut_count,gg_mut_patient, gg_mutated_genes_per_patient,gg_mutations_per_patient, ncol=2,align=&quot;hv&quot;,axis=&quot;ltrb&quot;, labels = &quot;AUTO&quot;) Figure 3.1: Extended Figure 1A-D An extra plot worth noting is below, which plots the number of cells per sample, after we filterd out all of the “3” uniformative genotyped cells. ### Cells per sample data.frame(&quot;Cells&quot;=do.call(rbind,lapply(final_NGTs,nrow)))%&gt;% ggplot(aes(x=Cells))+geom_histogram(binwidth = 100)+ theme_classic(base_size = 10)+ theme(plot.title=element_text(hjust=0.5))+ ylab(&quot;Count&quot;)+ggtitle(&quot;Informative Cells per Sample&quot;)+ scale_y_continuous(expand=c(0,0))+ scale_x_continuous(expand=c(0,0),n.breaks=8) 3.1.2 Mutation Co-occurence Next we want to make the co-occurence matrix on a sample level library(cooccur) ### create matrix for oncoprint mut_mat &lt;- table(melted_mut_mat$Sample,melted_mut_mat$Gene) ### Prepare matrix for co occurence map cooccur_mat &lt;- cooccur(mat=t(mut_mat), type=&quot;spp_site&quot;, only_effects = FALSE,eff_matrix=TRUE, thresh=FALSE, eff_standard=FALSE,spp_names=TRUE)$results ## Denote which interactions are significantly inclusive or exclusive # The &#39;add_row&#39; function generates a new line, but it gets removed later. # This is helpful for setting the order of the gene labels below. cooccur_data_mat &lt;- cooccur_mat%&gt;% mutate(score=ifelse(p_lt&lt;=0.05,-1, ifelse(p_gt&lt;=0.05,1,0))) %&gt;% dplyr::select(sp1_name,sp2_name,score)%&gt;% add_row(sp2_name=setdiff(.$sp1_name,.$sp2_name), sp1_name=setdiff(.$sp2_name,.$sp1_name), score=0) #check out the final that we added so we can remove it later tail(cooccur_data_mat) # Order the genes in a coherent pattern for triangle strucutre of graph. cooccur_data_mat$sp1_name&lt;-factor(cooccur_data_mat$sp1_name, levels=unique(cooccur_data_mat$sp1_name)) cooccur_data_mat$sp2_name&lt;-factor(cooccur_data_mat$sp2_name, levels=rev(levels(cooccur_data_mat$sp1_name))) # Triangle heatmap to compare cohorts grob_corrplot&lt;-ggplot(cooccur_data_mat%&gt;%filter(sp1_name!=&quot;BRAF&quot;),aes(x=sp1_name,y=sp2_name))+ geom_tile(aes(fill = factor(score)), color=&#39;grey90&#39;) + scale_fill_manual(name=&quot;Correlation&quot;, values=c(&quot;-1&quot;=&quot;firebrick3&quot;, &quot;0&quot;=&quot;white&quot;, &quot;1&quot;=&quot;steelblue2&quot;), labels=c(&quot;Mutually Exclusive&quot;, &quot;Not Significant&quot;, &quot;Mutually Inclusive&quot;))+ theme_classic(base_size=10)+ xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1), axis.line = element_blank(), legend.position = c(0.8,1), legend.justification = c(1, 1), legend.direction = &quot;vertical&quot;)+ theme(legend.key.size = unit(0.5,&quot;line&quot;)) grob_corrplot 3.1.3 Oncoprint: Figure 1A Now we are going to make the oncoprint that is in Figure 1A. Check out this example from the ComplexHeatmap package for a better understanding of why things are formatted the way they are. library(pals) # great package with color palettes in R library(ComplexHeatmap) #used for making the oncoprint #Here we will identify whether a variant is an indel, Nonsense or Missense mutation #Next we group samples together and pivot the matrix into wide format fill_values &lt;-setNames(as.list(rep(0,length(levels(final_mut_melt$Gene)))),levels(final_mut_melt$Gene)) mut_mat_wide&lt;-final_mut_melt%&gt;% mutate(Variant_Class=ifelse(grepl(&quot;fs\\\\*|INS_|ins|ext|del&quot;,.$Mutation),&quot;Indel&quot;, ifelse(grepl(&quot;\\\\*$&quot;,.$Mutation),&quot;Nonsense&quot;,&quot;Missense&quot;)))%&gt;% # mutate_at(c(&quot;Gene&quot;,&quot;Variant_Class&quot;,&quot;Sample&quot;),as.character())%&gt;% group_by(Sample,Gene)%&gt;% summarize(&quot;Variants&quot;=list(Variant_Class))%&gt;% pivot_wider(id_cols=Sample, names_from = Gene, values_from = Variants, # values_fn = list(Variant_Class=list), values_fill = list(Variant_Class=&quot;&quot;)) %&gt;% #ungroup(Sample,Gene)%&gt;% data.frame() # At this point, each column is actually a list, and variants are represnted as a list within a list. # So we want to unpack it a bit, and turn those variant lists in a ; separated vector mut_mat_wide_storage &lt;- list() for(i in 2:ncol(mut_mat_wide)){ # start at 2 to ignore the first column of sample names mut_mat_wide_storage[[i]]&lt;- do.call(rbind,lapply(mut_mat_wide[,i],function(x){ #if(x==&quot;&quot;){ # return(x) # } else if(is.null(x)){ return(&quot;&quot;) } else { paste(x,sep=&quot;;&quot;,collapse=&quot;;&quot;) } } )) } ## The rest of this just turns this back into a matrix in the format suggested by ComplexHeatmap mut_mat_wide_storage[[1]] &lt;- as.character(mut_mat_wide[,&quot;Sample&quot;]) final_mat &lt;- do.call(cbind,mut_mat_wide_storage) colnames(final_mat) &lt;- colnames(mut_mat_wide) rownames(final_mat) &lt;- final_mat[,1] final_mat &lt;- t(final_mat[,-1]) #Now we set up the color schemes for the variants on each row variant_type_colors = c(&quot;Indel&quot; = &quot;darkorchid2&quot;, &quot;Nonsense&quot; = &quot;black&quot;, &quot;Missense&quot; = &quot;darkgreen&quot;) alter_functions = list( background = function(x, y, w, h) { grid.rect(x, y, w, h-unit(0.25, &quot;mm&quot;), gp = gpar(fill = &quot;#CCCCCC&quot;, col = NA)) }, Indel = function(x, y, w, h) { grid.rect(x, y, w-unit(0.5, &quot;mm&quot;), h-unit(0.5, &quot;mm&quot;), gp = gpar(fill = variant_type_colors[&quot;Indel&quot;], col = NA)) }, Nonsense = function(x, y, w, h) { grid.rect(x, y, w-unit(0.5, &quot;mm&quot;), h-unit(0.5, &quot;mm&quot;), gp = gpar(fill = variant_type_colors[&quot;Nonsense&quot;], col = NA)) }, Missense = function(x, y, w, h) { grid.rect(x, y, w-unit(0.5, &quot;mm&quot;), h*0.33, gp = gpar(fill = variant_type_colors[&quot;Missense&quot;], col = NA)) } ) # Establish colors for each disease state and diagnosis color_set &lt;- list(&quot;Dx&quot; = setNames(okabe(n=length(unique(as.character(pheno[,&quot;Dx&quot;])))), c( &quot;CH&quot;,&quot;MDS&quot;,&quot;MPN&quot;, &quot;AML&quot;, &quot;sAML&quot; ,&quot;tAML&quot;,&quot;Other&quot;) ), &quot;Disease.Status&quot; = setNames(tol(n=(length(unique(as.character(pheno[,&quot;Disease.Status&quot;]))))), c(&quot;Newly Diagnosed&quot;,&quot;Relapse/Refractory&quot;,&quot;Newly Transformed&quot;, &quot;Persistent&quot;,&quot;Chronic Stage&quot;, &quot;Other&quot;))) # Format the annotations at the top of the oncoprint top_annotation &lt;- HeatmapAnnotation(cbar = anno_oncoprint_barplot(), df = pheno[,c(&quot;Dx&quot;,&quot;Disease.Status&quot;)], col = color_set, annotation_name_side = &quot;left&quot;) # Indicate what should be included in the legend heatmap_legend_param &lt;- list(title = &quot;Alternations&quot;, at = c(&quot;Indel&quot;, &quot;Nonsense&quot;, &quot;Missense&quot;), labels = c(&quot;Indel&quot;, &quot;Nonsense&quot;, &quot;Missense&quot;)) # Make the oncoprint oncoPrint(final_mat, alter_fun = alter_functions, col = variant_type_colors, top_annotation = top_annotation, heatmap_legend_param = heatmap_legend_param) 3.1.4 Sample clonality: Figure 1C,E Figure 2A,B Now we focused on patient samples that were included in the clonality analysis. This the filtered set o f patients that had &gt;100 cells, more than 1 mutation, and more than 1 clone following bootstrapping and estalbishing 95% confidence inervals &gt; 10 cells. final_sample_summary&lt;-readRDS(file=&quot;./data/final_sample_summary.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) Next we are going to build a data frame indicating the mutation status of various patients with regard to epigenetic modifiers (DNMT3a,TET2, ASXL1, IDH1/2, DTAI) and signalling genes (FLT3, vs JAK2 vs NRAS/KRAS) library(magrittr) # for %&lt;&gt;% #Tabulate presence/absence of a mutation mutants_in_each_sample&lt;-do.call(rbind,lapply(names(final_sample_summary),function(x){ y&lt;-colnames(final_sample_summary[[x]]$NGT) z &lt;- list() z$Sample &lt;- x z$DNMT3A &lt;- ifelse(any(grepl(&quot;DNMT3A&quot;,y)),1,0) z$TET2 &lt;- ifelse(any(grepl(&quot;TET2&quot;,y)),1,0) z$ASXL1 &lt;- ifelse(any(grepl(&quot;ASXL1&quot;,y)),1,0) z$IDH &lt;- ifelse(any(grepl(&quot;IDH&quot;,y)),1,0) z$FLT3 &lt;- ifelse(any(grepl(&quot;FLT3&quot;,y)),1,0) z$KIT &lt;- ifelse(any(grepl(&quot;KIT&quot;,y)),1,0) # n=1 sample, we put it in the &quot;signalling category&quot; z$RAS &lt;- ifelse(any(grepl(&quot;RAS&quot;,y)),1,0) z$JAK2 &lt;- ifelse(any(grepl(&quot;JAK2&quot;,y)),1,0) z$PTPN11 &lt;- ifelse(any(grepl(&quot;PTPN11&quot;,y)),1,0) data.frame(t(do.call(rbind,z))) })) # Bin into groups based on mutations and disease type mutants_in_each_sample%&lt;&gt;%mutate(Group=case_when( (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;(RAS==0&amp;FLT3==0)~&#39;DTAI&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;((RAS==1&amp;FLT3==0)| (PTPN11==1&amp;FLT3==0))~&#39;DTAI-RAS&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;(RAS==0&amp;FLT3==1)~&#39;DTAI-FLT3&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;((RAS==1&amp;FLT3==1)| (PTPN11==1&amp;FLT3==1))~&#39;DTAI-FLT3-RAS&#39;, (TET2==0&amp;DNMT3A==0&amp;IDH==0&amp;ASXL1==0)&amp;(RAS==1|FLT3==1|JAK2==1|KIT==1)~&#39;Signaling&#39;))%&gt;% left_join(pheno,by=&quot;Sample&quot;)%&gt;% mutate(Final_group=case_when( grepl(&quot;AML|Other&quot;,Dx)~Group, !grepl(&quot;AML|Other&quot;,Dx)~Dx )) # Order the groups to match how we have them in the paper mutants_in_each_sample$Final_group &lt;- factor(mutants_in_each_sample$Final_group, levels=c(&quot;CH&quot;,&quot;MPN&quot;,&quot;Signaling&quot;,&quot;DTAI&quot;, &quot;DTAI-RAS&quot;,&quot;DTAI-FLT3&quot;,&quot;DTAI-FLT3-RAS&quot;)) Next we want to calculate a few metrics for each patient sample. library(vegan) clonal_level_info&lt;-data.frame(do.call(rbind,lapply(names(final_sample_summary),function(y){ x &lt;- final_sample_summary[[y]]$Clones data.frame(&quot;Sample&quot;=y, &quot;Shannon&quot;=vegan::diversity(x[,1],index=&quot;shannon&quot;), &quot;Number_of_clones&quot;=length(x[,1]), &quot;Number_of_mutations&quot;=ncol(final_sample_summary[[y]]$NGT), &quot;Number_of_mutations_in_dominant_clone&quot;=sum(as.numeric(do.call(rbind, strsplit(as.character(x[nrow(x),2]),split=&quot;_&quot;)))), &quot;Dominant_clone_size&quot;=max(x[,1]/sum(x[,1]))) #, }))) Now we’ll merge the data frames together and plot some of the data found in Figure 1 and Figure 2 # Combine the data frame test&lt;-mutants_in_each_sample%&gt;%inner_join(clonal_level_info) # Number of mutations gg_number_of_mutations&lt;-ggplot(test%&gt;%group_by(Final_group)%&gt;% summarise(mean=mean(Number_of_mutations), sd = sd(Number_of_mutations), sem = sd(Number_of_mutations)/ sqrt(length(Number_of_mutations))), aes(x=Final_group,y=mean,fill=Final_group))+ geom_bar(stat=&quot;identity&quot;,color=&quot;black&quot;)+ geom_errorbar(aes(ymin = mean-sem, ymax = mean+sem),width=0.5,lwd=0.5)+ theme_classic(base_size = 8)+ ylab(&quot;Number of mutations&quot;)+xlab(&quot;&quot;)+ggtitle(&quot;&quot;)+ scale_y_continuous(limits = c(0,9), expand = c(0, 0)) + theme(axis.text.x = element_text(angle=30,hjust=1)) + scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Reds&quot;,aesthetics = &quot;fill&quot;,guide=FALSE) # Number of clones gg_number_of_clones&lt;-ggplot(test,aes(y=Number_of_clones,x=Final_group,fill=Final_group))+ geom_boxplot(outlier.shape = NA)+ geom_jitter(width = 0.1,size=0.5)+ theme_classic(base_size = 8)+ ylab(&quot;Number of clones&quot;)+ xlab(&quot;&quot;)+ theme(axis.text.x = element_text(angle=30,hjust=1)) + scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Reds&quot;,aesthetics = &quot;fill&quot;,guide=FALSE) plot_grid(gg_number_of_mutations,gg_number_of_clones,ncol=2,align=&quot;hv&quot;,axis=&quot;ltrb&quot;,labels=c(&quot;C&quot;,&quot;E&quot;)) Figure 3.2: Miles et al: Figure 1C,E Compute statistics for the different group comparisons. We used a Benjamini &amp; Hochberg FDR for multiple test correction with a significance cutoff of 0.1. library(reshape2) #for melt, I need to come up with a better way to do this, if anyone has ideas let me know! pvalues_Number_of_clones&lt;-test%&gt;%{melt(pairwise.t.test(.$Number_of_clones,g=.$Final_group, data=.,p.adjust.method=&quot;fdr&quot;)$p.value)}%&gt;% filter(!is.na(value))%&gt;%filter(value&lt;0.1) pvalues_Number_of_mutations&lt;-test%&gt;%{melt(pairwise.t.test(.$Number_of_mutations,g=.$Final_group, data=.,p.adjust.method=&quot;fdr&quot;)$p.value)}%&gt;% filter(!is.na(value))%&gt;%filter(value&lt;0.1) Table 3.1: Number of Clones Group 1 Group 2 FDR DTAI-RAS CH 0.0466140 DTAI-FLT3 CH 0.0001112 DTAI-FLT3-RAS CH 0.0245701 DTAI-RAS MPN 0.0899428 DTAI-FLT3 MPN 0.0001654 DTAI-FLT3-RAS MPN 0.0459698 DTAI-FLT3 Signaling 0.0157077 DTAI-FLT3 DTAI 0.0001112 DTAI-FLT3-RAS DTAI 0.0637393 DTAI-FLT3 DTAI-RAS 0.0105738 Table 3.1: Number of Mutations Group 1 Group 2 FDR Signaling CH 0.0171093 DTAI-RAS CH 0.0763530 DTAI-FLT3 CH 0.0000064 DTAI-FLT3-RAS CH 0.0040371 Signaling MPN 0.0729728 DTAI-FLT3 MPN 0.0000448 DTAI-FLT3-RAS MPN 0.0171093 DTAI Signaling 0.0017335 DTAI-FLT3 Signaling 0.0249373 DTAI-RAS DTAI 0.0058893 DTAI-FLT3 DTAI 0.0000000 DTAI-FLT3-RAS DTAI 0.0003139 DTAI-FLT3 DTAI-RAS 0.0000812 DTAI-FLT3-RAS DTAI-RAS 0.0658341 Now for Figure 2: # Shannon diversity index gg_shannon&lt;-ggplot(test,aes(y=Shannon,x=Final_group,fill=Final_group))+ geom_boxplot(outlier.shape = NA)+ geom_jitter(width = 0.1,size=0.5)+ theme_classic(base_size = 8)+ ylab(&quot;Shannon diveristy index&quot;)+ xlab(&quot;&quot;)+ theme(axis.text.x = element_text(angle=30,hjust=1)) + scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Reds&quot;,aesthetics = &quot;fill&quot;,guide=FALSE) # Number of mutations in each cohort gg_Number_of_mutations_in_Dclone&lt;-ggplot(test%&gt;%group_by(Final_group)%&gt;% summarise(mean=mean(Number_of_mutations_in_dominant_clone), sd = sd(Number_of_mutations_in_dominant_clone), sem = sd(Number_of_mutations_in_dominant_clone)/ sqrt(length(Number_of_mutations_in_dominant_clone))), aes(x=Final_group,y=mean,fill=Final_group))+ geom_bar(stat=&quot;identity&quot;,color=&quot;black&quot;)+ geom_errorbar(aes(ymin = mean-sem, ymax = mean+sem),width=0.5,lwd=0.5)+ theme_classic(base_size = 8)+ ylab(&quot;Number of mutations \\n in dominant clone&quot;)+xlab(&quot;&quot;)+ggtitle(&quot;&quot;)+ scale_y_continuous(limits = c(0,4.5), expand = c(0, 0)) + theme(axis.text.x = element_text(angle=30,hjust=1)) + scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Reds&quot;, aesthetics = &quot;fill&quot;,guide=FALSE) plot_grid(gg_shannon,gg_Number_of_mutations_in_Dclone,ncol=2,align=&quot;hv&quot;,axis=&quot;ltrb&quot;,labels=c(&quot;A&quot;,&quot;B&quot;)) Figure 3.3: Miles et al: Figure 2A-B pvalues_Shannon&lt;-test%&gt;%{melt(pairwise.t.test(.$Shannon,g=.$Final_group, data=.,p.adjust.method=&quot;fdr&quot;)$p.value)}%&gt;% filter(!is.na(value))%&gt;%filter(value&lt;0.1) pvalues_Number_of_mutations_in_dominant_clone&lt;-test%&gt;%{melt(pairwise.t.test( .$Number_of_mutations_in_dominant_clone, g=.$Final_group, data=.,p.adjust.method=&quot;fdr&quot;)$p.value)}%&gt;% filter(!is.na(value))%&gt;%filter(value&lt;0.1) Table 3.2: Shannon diversity index Group 1 Group 2 FDR Signaling CH 0.0675230 DTAI-RAS CH 0.0048421 DTAI-FLT3 CH 0.0000925 DTAI-FLT3-RAS CH 0.0082978 DTAI-RAS MPN 0.0327734 DTAI-FLT3 MPN 0.0006562 DTAI-FLT3-RAS MPN 0.0342246 DTAI-FLT3 Signaling 0.0266874 DTAI-RAS DTAI 0.0153873 DTAI-FLT3 DTAI 0.0000925 DTAI-FLT3-RAS DTAI 0.0327734 DTAI-FLT3 DTAI-RAS 0.0504716 Table 3.2: Dominant clone mutations Group 1 Group 2 FDR MPN CH 0.0068538 DTAI CH 0.0003515 DTAI-RAS CH 0.0003515 DTAI-FLT3 CH 0.0000133 DTAI-FLT3-RAS CH 0.0008256 Signaling MPN 0.0620536 DTAI-FLT3 MPN 0.0620536 DTAI Signaling 0.0084549 DTAI-RAS Signaling 0.0084549 DTAI-FLT3 Signaling 0.0003515 DTAI-FLT3-RAS Signaling 0.0087669 DTAI-FLT3 DTAI 0.0602450 DTAI-FLT3 DTAI-RAS 0.0703147 A few interesting points in Extended Figure 3 # Dominant clone size gg_dominant_clone_size&lt;-ggplot(test, aes(y=Dominant_clone_size,x=Final_group,fill=Final_group))+ geom_boxplot(outlier.shape = NA)+ geom_jitter(width = 0.1,size=0.5)+ theme_classic(base_size = 8)+ ylab(&quot;Fraction of sample \\n in dominant clone&quot;)+ xlab(&quot;&quot;)+ theme(axis.text.x = element_text(angle=30,hjust=1)) + scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Reds&quot;,aesthetics = &quot;fill&quot;,guide=FALSE) # determine the number of mutants alleles in each clone clone_size_by_genetic_density&lt;- do.call(rbind,lapply(final_sample_summary,function(x){ possible_clones_subset &lt;-x$Clones%&gt;%filter(Clone%in% x$Clones[,&quot;Clone&quot;] ) clones&lt;-possible_clones_subset[,&quot;Clone&quot;] dedup&lt;-x$NGT[!duplicated(x$NGT)&amp;x$NGT[,&quot;Clone&quot;]%in%clones,] set_mat&lt;-full_join(possible_clones_subset[,1:2],dedup) counts &lt;-set_mat[,&quot;Count&quot;] weights&lt;-set_mat[,&quot;Count&quot;]/sum(set_mat[,&quot;Count&quot;]) genetic_complexity &lt;- rowSums(set_mat[,-c(1:2)]) return(data.frame(&quot;Clone_size&quot;=weights, &quot;Genetic_density&quot;=genetic_complexity)) })) gg_clone_size_by_genetic_density&lt;-ggplot(clone_size_by_genetic_density, aes(y=Clone_size,x=factor(Genetic_density), fill=factor(Genetic_density)))+ geom_jitter(width = 0.1,size=0.5)+ geom_boxplot(outlier.shape = NA)+ theme_bw(base_size = 8)+ ylab(&quot;Fraction of sample in clone&quot;)+ xlab(&quot;Number of mutant alleles&quot;)+ scale_fill_brewer(type=&quot;seq&quot;,palette = &quot;Greens&quot;, aesthetics = &quot;fill&quot;,guide=FALSE) plot_grid(gg_dominant_clone_size,gg_clone_size_by_genetic_density,align=&quot;hv&quot;,axis=&quot;tb&quot;,ncol=2,labels=c(&quot;A&quot;,&quot;B&quot;)) Figure 3.4: Miles et al: Extended Figure 3A-B pvalues_Dominant_clone_size&lt;-test%&gt;%{melt(pairwise.t.test(.$Dominant_clone_size,g=.$Final_group, data=.,p.adjust.method=&quot;fdr&quot;)$p.value)}%&gt;% filter(!is.na(value))%&gt;%filter(value&lt;0.1) Table 3.3: Dominant clone size Group 1 Group 2 FDR DTAI-RAS CH 0.0356791 DTAI-FLT3 CH 0.0123253 DTAI-RAS MPN 0.0749752 DTAI-FLT3 MPN 0.0168044 DTAI-RAS DTAI 0.0168044 DTAI-FLT3 DTAI 0.0081647 3.1.5 Clonograph: Figure 1D This is probably our favorite way of looking at the data. library(RColorBrewer) final_sample_summary&lt;-readRDS(file=&quot;./data/final_sample_summary.rds&quot;) sample &lt;-&quot;MSK8&quot; sample_list &lt;-final_sample_summary # Extract out the sample of interest clonal_abundance &lt;-sample_list[[sample]]$Clones clonal_architecture &lt;-sample_list[[sample]]$Architecture # Ensure the order of the clone abundance and clone architecture are the same. clonal_architecture$Clone &lt;- factor(clonal_architecture$Clone, levels=rev(clonal_abundance$Clone)) clonal_abundance$Clone &lt;- factor(clonal_abundance$Clone, levels=levels(clonal_architecture$Clone)) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data=clonal_abundance, aes(x=Clone, y=Count,fill=Count)) + geom_col()+ theme_classic(base_size=7)+ scale_y_continuous(expand=c(0.01,0))+ #ylim() + ylab(&quot;Cell Count&quot;)+ geom_errorbar(aes(ymin = LCI, ymax = UCI), width = 0.2)+ scale_fill_distiller(name = &quot;Value&quot;, palette = &quot;Reds&quot;, direction = 1) + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x =element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(0,0,0,0),&quot;cm&quot;)) # Generate mutation heatmap gg_heatmap &lt;- ggplot(data=clonal_architecture, aes(x=Clone, y=Mutant, fill=Genotype))+ geom_tile() + scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),name=&quot;Genotype&quot;)+ theme_classic(base_size=7) + ylab(&quot;Mutation&quot;)+ scale_y_discrete(limits = rev(levels(clonal_architecture$Mutant)))+ theme(legend.position = &quot;right&quot;, legend.direction = &quot;vertical&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,0,0,0),&quot;cm&quot;)) # Put it all together plot_grid(gg_clonal_barplot,gg_heatmap,ncol=1,align=&quot;v&quot;,axis=&quot;lr&quot;,rel_heights = c(1,0.75)) Figure 3.5: Miles et al. Figure 1D "],["figure-2-clonality.html", "3.2 Figure 2: Clonality", " 3.2 Figure 2: Clonality We next wanted to determine if a given gene is likely to be found in the dominant clone or only ib subclones. Of course, nearly all mutations found in the dominant clone were also found in subclones. We attempted to find mutations that were exclusively found in the dominant clone, but did not observe any. This is likely complicated by the fact that many subclones are not the most “genetically dense” clone as explored in Figure 3 of the manuscript. We decided to address that with the markov models described elsewhere, and instead classified a mutation on whether it was present present or absent in the dominant clone. library(tidyr) library(dplyr) library(RColorBrewer) library(ggplot2) library(pals) library(cowplot) setwd(&quot;/Users/bowmanr/Projects/scDNA&quot;) final_sample_summary&lt;-readRDS(file=&quot;/Users/bowmanr/Projects/scDNA/data/final_sample_summary.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) clone_size_by_gene&lt;- do.call(rbind,lapply(names(final_sample_summary),function(x){ # select the clones clones&lt;-final_sample_summary[[x]]$Clones%&gt;% dplyr::select(Clone) # Compute the relative clone size Clone_size&lt;-final_sample_summary[[x]]$Clones%&gt;%transmute(Clone_size=Count/sum(Count))%&gt;%pull(Clone_size) names(Clone_size) &lt;- clones[,&quot;Clone&quot;] # Extract the mutations mutations &lt;- colnames(final_sample_summary[[x]]$NGT%&gt;% dplyr::select(!Clone)) # Identify the dominant clone, which is the last one in this data frame dominant_clone &lt;- clones[nrow(clones),] # Compute the bulk VAF for each mutation VAFs &lt;- final_sample_summary[[x]]$NGT%&gt;% dplyr::select(`mutations`)%&gt;% summarise_all(funs(mean(.)/2)) # Separate the clone into a deduplicated NGT matrix mut_mat&lt;-final_sample_summary[[x]]$Clones%&gt;% dplyr::select(Clone)%&gt;% separate(col=Clone,into=mutations,sep=&quot;_&quot;) # Create a composite data frame and turn it into long form data.frame(clones,Clone_size,mut_mat,&quot;Sample&quot;=x)%&gt;% pivot_longer(cols=all_of(mutations),names_to=&quot;Variant&quot;, values_to=&quot;Genotype&quot;)%&gt;% filter(Genotype!=0)%&gt;% # remove WT entries separate(col=Variant, into=&quot;Gene&quot;,extra=&quot;drop&quot;,sep=&quot;\\\\.|_&quot;,remove=FALSE)%&gt;% # For later useage in plotting group_by(Variant)%&gt;% filter(Clone_size==max(Clone_size))%&gt;% #identify largest clone mutate(Clonality=case_when( Clone==`dominant_clone`~&quot;Dominant&quot;, Clone!=`dominant_clone`~&quot;Subclone&quot;))%&gt;% #label clones inner_join(data.frame(&quot;VAF&quot;=t(VAFs), &quot;Variant&quot;=names(VAFs))) # merge with bulk VAF info })) # Tally the number of times a gene is in the dominant and subclone tally_set&lt;-data.frame(table(clone_size_by_gene$Gene, clone_size_by_gene$Clonality))%&gt;% pivot_wider(names_from=Var2,values_from=Freq)%&gt;% mutate(Ratio=Dominant/(Subclone+Dominant))%&gt;% #calculate the dominant ratio arrange(Ratio) # For plotting purposes establish order of the y axis clone_size_by_gene$Gene &lt;- factor(clone_size_by_gene$Gene, levels=tally_set$Var1) # Linde and I spent too much time picking the exact shade of red we wanted for this paper.... color_red&lt;-brewer.pal(5,&quot;Reds&quot;)[5] # For plotting purposes establish order of stacked bars clone_size_by_gene$Clonality&lt;-factor(clone_size_by_gene$Clonality,levels=c(&quot;Subclone&quot;,&quot;Dominant&quot;)) #plot the data ggA&lt;-ggplot(tally(clone_size_by_gene%&gt;%group_by(Gene,Clonality)), aes(x=factor(Gene),fill=Clonality,y=n,label=n))+ guides(fill=FALSE,color=FALSE)+ scale_y_continuous( expand = c(0, 0.0))+ #removes white space near the axis of the bars geom_bar(stat=&quot;identity&quot;,position=&quot;fill&quot;)+ xlab(&quot;&quot;)+coord_flip()+ scale_fill_manual(values=c(&quot;Dominant&quot;=color_red, &quot;Subclone&quot;=&quot;grey80&quot;))+ ylab(&quot;Fraction of mutant clones \\n with mutation in dominant clone&quot;)+ theme_bw(base_size=8)+theme(legend.position = &quot;bottom&quot;) ggB&lt;-ggplot(clone_size_by_gene, aes(y=Clone_size, x=Gene, fill=Gene)) + geom_boxplot(alpha = 0.5,outlier.shape = NA)+ geom_point(aes(color=Clonality,group=Clonality), position = position_jitterdodge(), size=0.3)+ scale_fill_manual(values=tol.rainbow(n=length(levels(clone_size_by_gene$Gene))))+ scale_color_manual(values=c(&quot;Dominant&quot;=color_red, &quot;Subclone&quot;=&quot;grey20&quot;))+ coord_flip()+ theme_bw(base_size=8)+guides(fill=FALSE,color=FALSE)+ theme(axis.text.y = element_blank(), axis.ticks.y = element_blank(), axis.title.y = element_blank())+ scale_y_continuous(limits = c(0,1), expand = c(0, 0.05)) + ylab(&quot;Fraction of cells \\n in largest mutant clone&quot;)+ theme(legend.position = &quot;bottom&quot;) spacer &lt;- plot_grid(NULL) # plot looks better with a little spacer plot_grid(ggA,spacer,ggB,align=&quot;h&quot;,axis=&quot;tb&quot;, ncol=3,rel_widths=c(1,0.05,1)) Figure 3.6: Miles et al. Figure 2C 3.2.1 Clonality in disease states We can look at this in a little more resolution on individual genes across disease course. library(magrittr) # Incorporate Diagnosis and disease state clone_size_by_gene_Dx&lt;-inner_join(clone_size_by_gene,pheno) # We focused on a subset of genes genes_of_interest &lt;- c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;, &quot;JAK2&quot;,&quot;NRAS&quot;,&quot;KRAS&quot;,&quot;FLT3&quot;,&quot;NPM1&quot;) # We had an interest in DNMT3A R882 point mutants, so we can extract those out clone_size_by_gene_Dx%&lt;&gt;%mutate(Gene=case_when( grepl(&quot;DNMT3A.p.R882&quot;,Variant)~&quot;DNMT3A.p.R882&quot;, TRUE~as.character(Gene))) clone_size_by_gene_Dx$Dx &lt;- factor(clone_size_by_gene_Dx$Dx, levels=c(&quot;CH&quot;,&quot;MPN&quot;,&quot;Other&quot;,&quot;sAML&quot;,&quot;tAML&quot;,&quot;AML&quot;)) mutation_dominance_by_dx&lt;-ggplot(tally(clone_size_by_gene_Dx%&gt;% filter(Gene%in%c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;, &quot;DNMT3A.p.R882&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;))%&gt;% group_by(Gene,Dx,Clonality)) , aes(x=Dx,fill=Clonality,y=n)) + facet_wrap(~factor(Gene, levels=c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;, &quot;DNMT3A.p.R882&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;)),ncol=3)+ geom_col(position=&quot;fill&quot;)+ xlab(&quot;&quot;)+ scale_fill_manual(values=c(&quot;Dominant&quot;=color_red, &quot;Subclone&quot;=&quot;grey80&quot;))+ ylab(&quot;Number of samples&quot;)+ theme_bw(base_size=10)+ theme(legend.position = &quot;right&quot;, axis.text.x =element_text(angle=30,hjust=1)) mutation_dominance_by_dx Figure 3.7: Clonality by Diagnosis 3.2.2 Clonality in co-mutational groups We can also look at it across the DTAI /RAS/FLT3 groups we defined in the paper. Here includes a little code from earlier in the tutorial to set up those groups again mutants_in_each_sample&lt;-do.call(rbind,lapply(names(final_sample_summary),function(x){ y&lt;-colnames(final_sample_summary[[x]]$NGT) z &lt;- list() z$Sample &lt;- x z$DNMT3A &lt;- ifelse(any(grepl(&quot;DNMT3A&quot;,y)),1,0) z$TET2 &lt;- ifelse(any(grepl(&quot;TET2&quot;,y)),1,0) z$ASXL1 &lt;- ifelse(any(grepl(&quot;ASXL1&quot;,y)),1,0) z$IDH &lt;- ifelse(any(grepl(&quot;IDH&quot;,y)),1,0) z$FLT3 &lt;- ifelse(any(grepl(&quot;FLT3&quot;,y)),1,0) z$KIT &lt;- ifelse(any(grepl(&quot;KIT&quot;,y)),1,0) # n=1 sample, we put it in the &quot;signalling category&quot; z$RAS &lt;- ifelse(any(grepl(&quot;RAS&quot;,y)),1,0) z$JAK2 &lt;- ifelse(any(grepl(&quot;JAK2&quot;,y)),1,0) z$PTPN11 &lt;- ifelse(any(grepl(&quot;PTPN11&quot;,y)),1,0) data.frame(t(do.call(rbind,z))) })) # Bin into groups based on mutations and disease type mutants_in_each_sample%&lt;&gt;%mutate(Group=case_when( (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;(RAS==0&amp;FLT3==0)~&#39;DTAI&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;((RAS==1&amp;FLT3==0)| (PTPN11==1&amp;FLT3==0))~&#39;DTAI-RAS&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;(RAS==0&amp;FLT3==1)~&#39;DTAI-FLT3&#39;, (TET2==1|DNMT3A==1|IDH==1|ASXL1==1)&amp;((RAS==1&amp;FLT3==1)| (PTPN11==1&amp;FLT3==1))~&#39;DTAI-FLT3-RAS&#39;, (TET2==0&amp;DNMT3A==0&amp;IDH==0&amp;ASXL1==0)&amp;(RAS==1|FLT3==1|JAK2==1|KIT==1)~&#39;Signaling&#39;))%&gt;% left_join(pheno,by=&quot;Sample&quot;)%&gt;% mutate(Final_group=case_when( grepl(&quot;AML|Other&quot;,Dx)~Group, !grepl(&quot;AML|Other&quot;,Dx)~Dx )) # Order the groups to match how we have them in the paper mutants_in_each_sample$Final_group &lt;- factor(mutants_in_each_sample$Final_group, levels=c(&quot;CH&quot;,&quot;MPN&quot;,&quot;Signaling&quot;,&quot;DTAI&quot;, &quot;DTAI-RAS&quot;,&quot;DTAI-FLT3&quot;,&quot;DTAI-FLT3-RAS&quot;)) # Now merge this with our new data frame defined above clone_size_by_gene_DTAI&lt;-left_join(clone_size_by_gene_Dx,mutants_in_each_sample,by=&quot;Sample&quot;) mutation_dominance_by_DTAI&lt;-ggplot(tally(clone_size_by_gene_DTAI%&gt;% filter(Gene%in%c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;, &quot;DNMT3A.p.R882&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;))%&gt;% group_by(Gene,Final_group,Clonality)) , aes(x=Final_group,fill=Clonality,y=n)) + facet_wrap(~factor(Gene, levels=c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;, &quot;DNMT3A.p.R882&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;)),ncol=3)+ geom_col()+ xlab(&quot;&quot;)+ scale_fill_manual(values=c(&quot;Dominant&quot;=color_red, &quot;Subclone&quot;=&quot;grey80&quot;))+ ylab(&quot;Number of samples&quot;)+ theme_bw(base_size=10)+ theme(legend.position = &quot;right&quot;, axis.text.x =element_text(angle=30,hjust=1)) mutation_dominance_by_DTAI Figure 3.8: Miles et al Extended Figure 3C 3.2.3 Clonality assocation with VAF We can also look at the VAF of each gene and see if that is associated with dominant vs subclone status for each state of disease, or the grouping we setup in the main figure library(ggbeeswarm) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) data_to_plot&lt;-inner_join(clone_size_by_gene,pheno)%&gt;% filter(as.character(Gene)%in%genes_of_interest &amp; !Dx%in%c(&quot;CH&quot;))%&gt;% group_by(Gene,Clonality) summarized_data &lt;-data_to_plot%&gt;%summarise(mean=mean(VAF), sd = sd(VAF), sem = sd(VAF)/sqrt(length(VAF))) clonality_VAF&lt;-ggplot(data_to_plot,aes(x=Clonality,y=VAF,color=Clonality))+ facet_wrap(~factor(Gene,levels=genes_of_interest), scale=&quot;free_x&quot;,ncol=5)+ ggbeeswarm::geom_beeswarm()+ geom_errorbar(data=summarized_data,aes(x=Clonality, y=mean, ymin=mean-sem, ymax=mean+sem), color=&quot;black&quot;)+ scale_color_manual(values=c(&quot;Dominant&quot;=color_red, &quot;Subclone&quot;=&quot;grey50&quot;))+ xlab(&quot;&quot;)+ ylab(&quot;Computed VAF&quot;)+ theme_classic()+guides(fill=FALSE)+ theme(axis.ticks.x = element_blank(), axis.text.x = element_blank())+ scale_y_continuous(limits=c(0,1.1), breaks=c(0,.25,.5,.75,1), labels=c(&quot;0&quot;,&quot;0.25&quot;,&quot;0.50&quot;,&quot;0.75&quot;,&quot;1.0&quot;)) clonality_VAF Figure 3.9: Miles et al Extended Figure 3D Statistics below library(broom) clonality_VAF_pvalues&lt;-data.frame(data_to_plot)%&gt;% filter(as.character(Clonality)%in%c(&quot;Dominant&quot;,&quot;Subclone&quot;)&amp; Gene!=&quot;IDH2&quot;)%&gt;% group_by(Gene)%&gt;% dplyr::select(VAF,Clonality)%&gt;% do(tidy(t.test(VAF ~ Clonality, data = .)))%&gt;% dplyr::select(Gene,Dominant_VAF=estimate2, Subclone_VAF=estimate1, p.value)%&gt;% mutate_if(is.numeric, funs(as.character(signif(., 3)))) Gene Dominant_VAF Subclone_VAF p.value KRAS 0.387 0.0601 0.00353 FLT3 0.313 0.0567 7.9e-05 NRAS 0.41 0.0507 1.2e-05 TET2 0.546 0.0756 9.37e-17 ASXL1 0.445 0.109 3.43e-05 DNMT3A 0.481 0.124 1.06e-09 JAK2 0.725 0.0936 2.05e-07 IDH1 0.471 0.0673 0.000209 NPM1 0.465 0.278 0.0907 3.2.4 Co-mutation and clonality Some of our motivations for this section were: 1) Are epigenetic mutations found in the same cell, if so, are these cells the dominant clone? 2) Are there Tet2 IDH in the same sample, and if so same cell? 3) Are there signaling in the same sample, and if so same cell? We start off here by laoding the packages of interest, including two new ones “UpSetR” and “tibble.” UpSetR is necessary for some of the barplots we make, while “tibble” is useful for the add_column function. options(stringsAsFactors = FALSE) library(UpSetR) library(tidyr) library(dplyr) library(RColorBrewer) library(ggplot2) library(pals) library(cowplot) library(tibble) setwd(&quot;/Users/bowmanr/Projects/scDNA&quot;) final_sample_summary&lt;-readRDS(file=&quot;./data/final_sample_summary.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) Our eventual goal is make an UpSet plot looking at the overlap of the different epigenetic events. We would like to demarcate on this plot whether the different epigenetic hits are in the same clone, with a specific focus on the dominant clone. We’ll start off by determing for each sample whether there is a mutation for the indicated genes. sample_mutations&lt;-do.call(rbind,lapply(names(final_sample_summary),function(sample){ data.frame(&quot;Sample&quot;=sample, &quot;DNMT3A&quot;=ifelse(any(grepl(&quot;DNMT3A&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;TET2&quot;=ifelse(any(grepl(&quot;TET2&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;IDH2&quot;=ifelse(any(grepl(&quot;IDH2&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;IDH1&quot;=ifelse(any(grepl(&quot;IDH1&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;ASXL1&quot;=ifelse(any(grepl(&quot;ASXL1&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;FLT3&quot;=ifelse(any(grepl(&quot;FLT3&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;JAK2&quot;=ifelse(any(grepl(&quot;JAK2&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;NRAS&quot;=ifelse(any(grepl(&quot;NRAS&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;KRAS&quot;=ifelse(any(grepl(&quot;KRAS&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0), &quot;PTPN11&quot;=ifelse(any(grepl(&quot;PTPN11&quot;,colnames(final_sample_summary[[sample]]$NGT))),1,0) ) })) We will next proceed with this same process on a clone level. select &lt;- dplyr::select clone_mutations&lt;-do.call(rbind,lapply(names(final_sample_summary),function(sample){ # select the clones clones&lt;-final_sample_summary[[sample]]$Clones%&gt;%select(Clone) # Extract the mutations mutations &lt;- colnames(final_sample_summary[[sample]]$NGT%&gt;%select(!Clone)) # Separate clones into mutations, identify the mutations in the dominant clone. # I&#39;m sure there is a more efficient way to do this, but this is what I have. # This might seem a little redundant with the group ungroup and regroup, but the idea # is we want to calculate the relative size of each clone in the context of the whole sample # then identify and remove the WT clone in the rare event it is the dominant clone, or the largest subclone. # In order to then mark the clones as dominant or subclone, we have to ungroup in order to use the context of the whole sample. # Lastly, we group again on the Clones and check whether each clone is mutant for the genes of interest. # We next remove excess columns representing genes and variants and finally remove duplicate rows. # Previosuly each line of this data frame was a variant, and now it is a clone. out&lt;-final_sample_summary[[sample]]$Clones%&gt;% mutate(Clone_size=Count/sum(Count))%&gt;% dplyr::select(Clone,Clone_size)%&gt;% separate(col=Clone, into=mutations,sep=&quot;_&quot;, remove=FALSE)%&gt;% pivot_longer(cols=mutations, names_to=&quot;Variant&quot;, values_to=&quot;Genotype&quot;)%&gt;% add_column(Sample=`sample`)%&gt;% group_by(Clone)%&gt;% mutate(WT=ifelse(all(Genotype==0),1,0))%&gt;% filter(WT==0)%&gt;% filter(Genotype!=0)%&gt;% ungroup()%&gt;% mutate(Clonality=ifelse(Clone_size==max(Clone_size), &quot;Dominant&quot;,&quot;Subclone&quot;))%&gt;% group_by(Clone)%&gt;% mutate(Gene=do.call(rbind,strsplit(Variant,&quot;[\\\\._]&quot;))[,1])%&gt;% mutate(DNMT3A=ifelse(any(Gene%in%&quot;DNMT3A&quot;),1,0), TET2=ifelse(any(Gene%in%&quot;TET2&quot;),1,0), ASXL1=ifelse(any(Gene%in%&quot;ASXL1&quot;),1,0), IDH1=ifelse(any(Gene%in%&quot;IDH1&quot;),1,0), IDH2=ifelse(any(Gene%in%&quot;IDH2&quot;),1,0), FLT3=ifelse(any(Gene%in%&quot;FLT3&quot;),1,0), NRAS=ifelse(any(Gene%in%&quot;NRAS&quot;),1,0), KRAS=ifelse(any(Gene%in%&quot;KRAS&quot;),1,0), PTPN11=ifelse(any(Gene%in%&quot;PTPN11&quot;),1,0), JAK2=ifelse(any(Gene%in%&quot;JAK2&quot;),1,0))%&gt;% ungroup()%&gt;% dplyr::select(!c(Variant,Genotype,Gene))%&gt;% distinct() })) Now to check to see if the mutations found in the sample are in the dominant clone. The UpSetR package is great, the queries part was a little non intuitive for me at first glance, however Vignette cleared it up and is worth a read. # Identify genes of interest DTAI_genes&lt;- c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;IDH2&quot;,&quot;IDH1&quot;,&quot;ASXL1&quot;) # Subset data.frame above to only the dominant clones dominant_clone_mutations &lt;- clone_mutations%&gt;%filter(Clonality==&quot;Dominant&quot;) # For each sample, determine if the dominant clone sample_mutations$Match&lt;-ifelse(sapply(sample_mutations$Sample,function(sample) { all(sample_mutations%&gt;% filter(Sample==sample)%&gt;% select(all_of(DTAI_genes))== dominant_clone_mutations%&gt;% filter(Sample==sample)%&gt;% select(all_of(DTAI_genes))) }) ,&quot;Match&quot;,&quot;Absent&quot;) # Join this match with the phenotype data to pick a disease state of interest test_set&lt;-left_join(sample_mutations,pheno,by=&quot;Sample&quot;) # Necessary little function to Myfunc &lt;- function(row,feature) { data &lt;- (row[feature]==&quot;Match&quot;) } # Slight difference from BioRxiv paper due to a misclassification of one TET2 mutant CMML sample as AML. AML&lt;-upset(test_set%&gt;%filter(grepl(&quot;AML&quot;,Dx)), sets=DTAI_genes, order.by = c(&quot;degree&quot;), main.bar.color = &quot;grey60&quot;,decreasing=FALSE, mainbar.y.label = &quot;Number of samples&quot;, sets.x.label = &quot;Number of \\n mutant samples&quot;, text.scale=1.25, shade.alpha = 0.75, show.numbers=FALSE, mb.ratio = c(0.6, 0.4), queries=list(list(query = Myfunc, params = list(&quot;Match&quot;), color = brewer.pal(5,&quot;Reds&quot;)[5], active = TRUE ))) AML Figure 3.10: Miles et al Figure 2D And now for CH only CH&lt;-upset(test_set%&gt;%filter(Dx==&quot;CH&quot;), sets=DTAI_genes,order.by = c(&quot;degree&quot;), main.bar.color = &quot;grey60&quot;,decreasing=FALSE, mainbar.y.label = &quot;Number of samples&quot;, sets.x.label = &quot;Number of \\n mutant samples&quot;, text.scale=1.25, shade.alpha = 0.75, show.numbers=FALSE, queries=list(list(query = Myfunc, params = list(&quot;Match&quot;), color = brewer.pal(5,&quot;Reds&quot;)[5], active = TRUE ))) CH Figure 3.11: Miles et al, Extended Figure 3F The above plots looks nice and are worth looking at for a host of genes. The signalling effectors are quite interesting. In this setting you can see that when a sample harbors multiple signaling effectors, they are rarely in the dominant clone, unlike the epigenetic mutations above. If you want to edit this to evaluate a gene of interest, you need to go back to the beginning here and add the columns back into the “sample_mutations” and “dominant_clone_mutations” variables. # Identify genes of interest genes&lt;- c(&quot;FLT3&quot;,&quot;NRAS&quot;,&quot;JAK2&quot;,&quot;KRAS&quot;,&quot;PTPN11&quot;) # Subset data.frame above to only the dominant clones dominant_clone_mutations &lt;- clone_mutations%&gt;%filter(Clonality==&quot;Dominant&quot;) # For each sample, determine if the dominant clone sample_mutations$Match&lt;-ifelse(sapply(sample_mutations$Sample,function(sample) { all(sample_mutations%&gt;% filter(Sample==sample)%&gt;% select(all_of(genes))== dominant_clone_mutations%&gt;% filter(Sample==sample)%&gt;% select(all_of(genes))) }) ,&quot;Match&quot;,&quot;Absent&quot;) # Join this match with the phenotype data to pick a disease state of interest test_set&lt;-left_join(sample_mutations,pheno,by=&quot;Sample&quot;) # Necessary little function to Myfunc &lt;- function(row,feature) { data &lt;- (row[feature]==&quot;Match&quot;) } # Slight difference from BioRxiv paper due to a misclassification of one TET2 mutant CMML sample as AML. AML_signaling_genes&lt;-upset(test_set%&gt;%filter(grepl(&quot;AML&quot;,Dx)), sets=genes, order.by = c(&quot;degree&quot;), main.bar.color = &quot;grey60&quot;,decreasing=FALSE, mainbar.y.label = &quot;Number of samples&quot;, sets.x.label = &quot;Number of \\n mutant samples&quot;, text.scale=1.25, shade.alpha = 0.75, show.numbers=FALSE, mb.ratio = c(0.6, 0.4), queries=list(list(query = Myfunc, params = list(&quot;Match&quot;), color = brewer.pal(5,&quot;Reds&quot;)[5], active = TRUE ))) AML_signaling_genes Figure 3.12: Not shown in Miles et We wanted to visualize this data another way, and gain more resolution into multi-mutant subclones. In order to do this we generated graph structures using the igraph package. We decided to focus specifically on mutli mutant DTAI or multi mutant signaling AMLs. library(igraph) # identify sample with at least 2 DTAI mutationss multi_DTAI&lt;-test_set%&gt;%filter(grepl(&quot;AML&quot;,Dx))%&gt;% filter((ASXL1+DNMT3A+TET2+IDH1+IDH2)&gt;=2)%&gt;% distinct(Sample)%&gt;%pull(Sample) # Identify dominant clones DTAI_dominant_clones&lt;-clone_mutations%&gt;%filter(Sample%in%multi_DTAI)%&gt;% filter(Clonality==&quot;Dominant&quot;)%&gt;% select(Clone,Clone_size,Sample,DNMT3A,TET2,ASXL1,IDH1,IDH2)%&gt;% pivot_longer(cols=c(DNMT3A,TET2,ASXL1,IDH1,IDH2), names_to=&quot;Gene&quot;,values_to=&quot;Mutated&quot;)%&gt;% filter(Mutated==1) # Now we want to know which variants are in the dominant clone, and the size of that clone. # I&#39;m sure there is a nice way to do this in dplyr, grouping on sample, but I couldn&#39;t figure it out # so we will use lapply. genes_in_each_dominant_clone&lt;- do.call(rbind,setNames(lapply(multi_DTAI,function(x){ # Extract the genes dominant_variants&lt;- DTAI_dominant_clones%&gt;%filter(Sample==x)%&gt;%pull(Gene) # Extract the clone size dominant_clone_size&lt;- DTAI_dominant_clones%&gt;%filter(Sample==x)%&gt;%pull(Clone_size) # if there are more than two DTAI variants in the dominant clone make a combinatorial edgelist if(length(dominant_variants)&gt;=2){ return(setNames(data.frame(t(combn(dominant_variants,2)),dominant_clone_size,&quot;Dominant&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} # if there is only 1 mutant in the dominant clone, list it for now so we can count the mutation, # but we will eventually filter it out else if(length(dominant_variants)==1){ return(setNames(data.frame(t(c(dominant_variants,dominant_variants)),dominant_clone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} # if no DTAI mutants in the dominant clone, ignore. else if(length(dominant_variants)==0){ NULL } }),multi_DTAI))%&gt;%distinct() # Now we will go for a similar process with subclones. DTAI_sub_clones&lt;-clone_mutations%&gt;%filter(Sample%in%multi_DTAI)%&gt;% filter(Clonality!=&quot;Dominant&quot;)%&gt;% select(Clone,Clone_size,Sample,DNMT3A,TET2,ASXL1,IDH1,IDH2)%&gt;% pivot_longer(cols=c(DNMT3A,TET2,ASXL1,IDH1,IDH2), names_to=&quot;Gene&quot;,values_to=&quot;Mutated&quot;)%&gt;% filter(Mutated==1)%&gt;% # This is how we specifically select multi mutant subclone group_by(Clone,Sample)%&gt;% add_tally()%&gt;%filter(n&gt;1)%&gt;% ungroup() # Same process as above, but note that we decided to only plot the largest multi mutant clone. # Try getting rid of this and seeing how it looks. genes_in_each_subclone &lt;- do.call(rbind,setNames(lapply(multi_DTAI,function(x){ subclone_variants &lt;- DTAI_sub_clones%&gt;%filter(Sample==x)%&gt;% filter(Clone_size==max(Clone_size))%&gt;% pull(Gene) subclone_size &lt;- DTAI_sub_clones%&gt;%filter(Sample==x)%&gt;% filter(Clone_size==max(Clone_size))%&gt;% pull(Clone_size) if(length(subclone_variants)&gt;=2){ return(setNames(data.frame(t(combn(rev(subclone_variants),2)),subclone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(subclone_variants)==1){ return(setNames(data.frame(t(c(subclone_variants,subclone_variants)),subclone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(subclone_variants)==0){ NULL } }),multi_DTAI))%&gt;%distinct() # Now bind these two dataframe together final_set&lt;- rbind(genes_in_each_dominant_clone,genes_in_each_subclone) # And remove the edges that are self referencing. We preserve the input variable so we can represent # the vertex size in relation to total mutation burden in this subset of patients. final_set_filtered &lt;-final_set%&gt;%filter(to!=from) graph&lt;-graph_from_data_frame(final_set_filtered,directed=F)%&gt;% set_edge_attr(&quot;weight&quot;, value = as.numeric(final_set_filtered%&gt;%pull(size))*3) %&gt;% set_edge_attr(&quot;color&quot;, value = ifelse(final_set_filtered%&gt;% pull(Clonality)==&quot;Dominant&quot;, brewer.pal(5,&quot;Reds&quot;)[5],&quot;grey20&quot;)) mutant_counts&lt;-table(c(as.character(final_set$to),as.character(final_set$from)))[names(V(graph))] scaled_mutant_counts &lt;-mutant_counts/sum(mutant_counts)*50 radian.rescale &lt;- function(x, start=0, direction=1) { c.rotate &lt;- function(x) (x + start) %% (2 * pi) * direction c.rotate(scales::rescale(x, c(0, 2 * pi), range(x))) } lab.locs &lt;- radian.rescale(x=1:5, direction=-1, start=5) lab.locs[3]&lt;- -2.5 The permute function below, and the indexing of the vertex.size is only to preserve the order that is present in the manuscript. When I recoded everything, the order of the mutations changed in the data frame and inverted the graph. reordered_graph&lt;-igraph::permute(graph,c(4,3,2,1,5)) plot.igraph(reordered_graph, edge.width = E(reordered_graph)$weight, vertex.color=brewer.pal(5,&quot;Reds&quot;)[5], vertex.frame.color=brewer.pal(5,&quot;Reds&quot;)[5], vertex.size=scaled_mutant_counts[names(V(reordered_graph))], vertex.label.family=&quot;Helvetica&quot;, vertex.label.color=&quot;black&quot;, vertex.label.degree=lab.locs, vertex.label.dist=c(3,4,3,7,3), layout=layout_in_circle) Figure 3.13: Miles et al Figure 2E Now for the signalling genes. Everything is the exactly the same as above, so I’ve skipped commenting it unless where necessary. The graph looks a little different here than the BioRxiv manuscript due to a sample diagnosis being incorrect previously. multi_signaling&lt;-test_set%&gt;%filter(grepl(&quot;AML&quot;,Dx))%&gt;% filter((FLT3+JAK2+NRAS+KRAS+PTPN11)&gt;=2)%&gt;% distinct(Sample)%&gt;%pull(Sample) signaling_dominant_clones&lt;-clone_mutations%&gt;%filter(Sample%in%multi_signaling)%&gt;% filter(Clonality==&quot;Dominant&quot;)%&gt;% select(Clone_size,Sample,FLT3,JAK2,NRAS,KRAS,PTPN11)%&gt;% pivot_longer(cols=c(FLT3,JAK2,NRAS,KRAS,PTPN11), names_to=&quot;Gene&quot;,values_to=&quot;Mutated&quot;)%&gt;% filter(Mutated==1) genes_in_each_dominant_clone&lt;- do.call(rbind,setNames(lapply(multi_signaling,function(x){ dominant_variants&lt;- signaling_dominant_clones%&gt;%filter(Sample==x)%&gt;%pull(Gene) dominant_clone_size&lt;- signaling_dominant_clones%&gt;%filter(Sample==x)%&gt;%pull(Clone_size) if(length(dominant_variants)&gt;=2){ return(setNames(data.frame(t(combn((dominant_variants),2)),dominant_clone_size,&quot;Dominant&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(dominant_variants)==1){ return(setNames(data.frame(t(c(dominant_variants,dominant_variants)),dominant_clone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(dominant_variants)==0){ NULL } }),multi_signaling))%&gt;%distinct() signaling_sub_clones&lt;-clone_mutations%&gt;%filter(Sample%in%multi_signaling)%&gt;% filter(Clonality!=&quot;Dominant&quot;)%&gt;% select(Clone,Clone_size,Sample,FLT3,JAK2,NRAS,KRAS,PTPN11)%&gt;% pivot_longer(cols=c(FLT3,JAK2,NRAS,KRAS,PTPN11), names_to=&quot;Gene&quot;,values_to=&quot;Mutated&quot;)%&gt;% filter(Mutated==1)%&gt;% group_by(Clone,Sample)%&gt;% add_tally()%&gt;%filter(n&gt;1)%&gt;% ungroup() genes_in_each_subclone&lt;- do.call(rbind,setNames(lapply(multi_signaling,function(x){ subclone_variants&lt;- signaling_sub_clones%&gt;%filter(Sample==x)%&gt;% filter(Clone_size==max(Clone_size))%&gt;%pull(Gene) subclone_size&lt;- signaling_sub_clones%&gt;%filter(Sample==x)%&gt;% filter(Clone_size==max(Clone_size))%&gt;%pull(Clone_size) if(length(subclone_variants)&gt;=2){ return(setNames(data.frame(t(combn((subclone_variants),2)),subclone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(subclone_variants)==1){ return(setNames(data.frame(t(c(subclone_variants,subclone_variants)),subclone_size,&quot;Subclone&quot;),c(&quot;to&quot;,&quot;from&quot;,&quot;size&quot;,&quot;Clonality&quot;)))} else if(length(subclone_variants)==0){ NULL } }),multi_signaling))%&gt;%distinct() ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf ## Warning in max(Clone_size): no non-missing arguments to max; returning -Inf final_set&lt;- rbind(genes_in_each_dominant_clone,genes_in_each_subclone) final_set_filtered &lt;-final_set%&gt;%filter(to!=from) graph&lt;-graph_from_data_frame(final_set_filtered,directed=F)%&gt;% set_edge_attr(&quot;weight&quot;, value = as.numeric(final_set_filtered%&gt;%pull(size))*3) %&gt;% set_edge_attr(&quot;color&quot;, value = ifelse(final_set_filtered%&gt;% pull(Clonality)==&quot;Dominant&quot;, brewer.pal(5,&quot;Reds&quot;)[5],&quot;grey20&quot;)) mutant_counts&lt;-table(c(as.character(final_set$to),as.character(final_set$from)))[names(V(graph))] scaled_mutant_counts &lt;-mutant_counts/sum(mutant_counts)*50 radian.rescale &lt;- function(x, start=0, direction=1) { c.rotate &lt;- function(x) (x + start) %% (2 * pi) * direction c.rotate(scales::rescale(x, c(0, 2 * pi), range(x))) } lab.locs &lt;- radian.rescale(x=1:5, direction=-1, start=5) lab.locs[3]&lt;- -2.5 reordered_graph&lt;-igraph::permute(graph,c(5,2,4,1,3)) plot.igraph(reordered_graph, edge.width = E(reordered_graph)$weight, vertex.color=brewer.pal(5,&quot;Reds&quot;)[5], vertex.frame.color=brewer.pal(5,&quot;Reds&quot;)[5], vertex.size=scaled_mutant_counts[names(V(reordered_graph))], vertex.label.family=&quot;Helvetica&quot;, vertex.label.color=&quot;black&quot;, vertex.label.degree=lab.locs, vertex.label.dist=c(3,4,3,7,3), layout=layout_in_circle) For the last part, we wanted to dial in on DNMT3A and IDH mutant leukemias to see if there were distinct co mutants between DNMT3A, IDH1, IDH2 and combinatorial mutant samples. This plot is interesting, and we looked at it many different ways including on the sample level as depicted in the preprint, and on the completely clonal level below. I’ll show the sample level as well to demonstrate the difference in data. # Add a column for whether a clone contains 2 signaling mutations (as demonstrated above) clone_mutations_added&lt;-clone_mutations%&gt;%inner_join(pheno,by=&quot;Sample&quot;)%&gt;% rowwise()%&gt;% add_column(signal2=ifelse(c(.$FLT3+.$JAK2+.$NRAS+.$KRAS+.$PTPN11)&gt;=2,1,0))%&gt;% ungroup() gene_sets&lt;-list(&quot;DNMT3A&quot;=&quot;DNMT3A&quot;, &quot;DNMT3A IDH1&quot;=c(&quot;DNMT3A&quot;,&quot;IDH1&quot;), &quot;DNMT3A IDH2&quot;=c(&quot;DNMT3A&quot;,&quot;IDH2&quot;), &quot;IDH1&quot;=&quot;IDH1&quot;, &quot;IDH2&quot;=&quot;IDH2&quot;) comutant_status&lt;-do.call(rbind,setNames(lapply(gene_sets, function(genes){ epi_to_exclude &lt;- setdiff(c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;),genes) clone_subset&lt;- clone_mutations_added%&gt;%filter(Dx==&quot;AML&quot;)%&gt;% filter_at(vars(all_of(epi_to_exclude)),all_vars(.==0))%&gt;% filter_at(vars(all_of(genes)), all_vars(.==1))%&gt;% select(c(Sample,all_of(genes),FLT3,JAK2,NRAS,KRAS,PTPN11,signal2)) data.frame(&quot;Group&quot; =paste(genes,sep=&quot; &quot;,collapse = &quot; &quot;), &quot;Total&quot; =clone_subset%&gt;%add_tally(name=&quot;Count&quot;)%&gt;%pull(Count), &quot;FLT3&quot; =clone_subset%&gt;%filter(signal2==0)%&gt;%tally(FLT3) %&gt;%pull(n), &quot;PTPN11&quot; =clone_subset%&gt;%filter(signal2==0)%&gt;%tally(PTPN11)%&gt;%pull(n), &quot;JAK2&quot; =clone_subset%&gt;%filter(signal2==0)%&gt;%tally(JAK2) %&gt;%pull(n), &quot;KRAS&quot; =clone_subset%&gt;%filter(signal2==0)%&gt;%tally(KRAS) %&gt;%pull(n), &quot;NRAS&quot; =clone_subset%&gt;%filter(signal2==0)%&gt;%tally(NRAS) %&gt;%pull(n), &quot;Multiple mutants&quot;=clone_subset%&gt;%tally(signal2)%&gt;%pull(n), &quot;None&quot; =clone_subset%&gt;% add_column(None=ifelse(c(.$FLT3+.$JAK2+ .$NRAS+.$KRAS+ .$PTPN11)==0,1,0))%&gt;% tally(None)%&gt;%pull(n)) }),names(gene_sets))) final&lt;-comutant_status%&gt;% dplyr::select(!Total)%&gt;% pivot_longer(cols=c(FLT3,PTPN11,JAK2,KRAS, NRAS,Multiple.mutants,None), names_to=&quot;Mutation&quot;, values_to=&quot;Count&quot;) final$Mutation &lt;- gsub(&quot;Multiple.mutants&quot;,&quot;Multiple mutants&quot;,final$Mutation) final$Mutation &lt;- factor(final$Mutation, levels=rev(c(&quot;JAK2&quot;,&quot;PTPN11&quot;,&quot;NRAS&quot;,&quot;KRAS&quot;,&quot;FLT3&quot;,&quot;Multiple mutants&quot;,&quot;None&quot;))) final$Group &lt;- factor(final$Group, levels=rev(c(&quot;IDH1&quot;,&quot;DNMT3A IDH1&quot;,&quot;DNMT3A&quot;,&quot;DNMT3A IDH2&quot;,&quot;IDH2&quot;))) color_set&lt;-rev(brewer.pal(9,&quot;Set1&quot;)[c(1,8,2,3,4,5,9)]) gg_co_mutants&lt;-ggplot(final, aes(x=Group,fill=Mutation,y=Count))+ geom_col(position=&quot;fill&quot;)+theme_classic(base_size=12)+ ylab(&quot;Fraction of clones&quot;)+ xlab(&quot;&quot;)+coord_flip()+ scale_y_continuous(expand=c(0,0))+ ggtitle(&quot;Clone level data&quot;)+ theme(plot.title = element_text(hjust=0.5))+ scale_fill_manual(values=color_set,&quot;Co mutation&quot;, guide = guide_legend(reverse = TRUE)) Now the same thing below but starting with the sample based mutation matrix we used for the UpSet plots. # Add a column for whether a clone contains 2 signaling mutations (as demonstrated above) sample_mutations_added&lt;-sample_mutations%&gt;% inner_join(pheno,by=&quot;Sample&quot;)%&gt;% rowwise()%&gt;% add_column(signal2=ifelse(c(.$FLT3+.$JAK2+ .$NRAS+.$KRAS+.$PTPN11)&gt;=2,1,0))%&gt;% ungroup() gene_sets&lt;-list(&quot;DNMT3A&quot;=&quot;DNMT3A&quot;, &quot;DNMT3A IDH1&quot;=c(&quot;DNMT3A&quot;,&quot;IDH1&quot;), &quot;DNMT3A IDH2&quot;=c(&quot;DNMT3A&quot;,&quot;IDH2&quot;), &quot;IDH1&quot;=&quot;IDH1&quot;, &quot;IDH2&quot;=&quot;IDH2&quot;) comutant_sample_status&lt;-do.call(rbind,setNames(lapply(gene_sets, function(genes){ epi_to_exclude &lt;- setdiff(c(&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;ASXL1&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;),genes) sample_subset&lt;- sample_mutations_added%&gt;% filter(Dx==&quot;AML&quot;)%&gt;% filter_at(vars(all_of(epi_to_exclude)),all_vars(.==0))%&gt;% filter_at(vars(all_of(genes)), all_vars(.==1))%&gt;% select(c(Sample,all_of(genes),FLT3,JAK2,NRAS, KRAS,PTPN11,signal2)) data.frame(&quot;Group&quot; =paste(genes,sep=&quot; &quot;,collapse = &quot; &quot;), &quot;Total&quot; =sample_subset%&gt;%add_tally(name=&quot;Count&quot;)%&gt;%pull(Count), &quot;FLT3&quot; =sample_subset%&gt;%filter(signal2==0)%&gt;%tally(FLT3) %&gt;%pull(n), &quot;PTPN11&quot; =sample_subset%&gt;%filter(signal2==0)%&gt;%tally(PTPN11)%&gt;%pull(n), &quot;JAK2&quot; =sample_subset%&gt;%filter(signal2==0)%&gt;%tally(JAK2) %&gt;%pull(n), &quot;KRAS&quot; =sample_subset%&gt;%filter(signal2==0)%&gt;%tally(KRAS) %&gt;%pull(n), &quot;NRAS&quot; =sample_subset%&gt;%filter(signal2==0)%&gt;%tally(NRAS) %&gt;%pull(n), &quot;Multiple mutants&quot;=sample_subset%&gt;%tally(signal2)%&gt;%pull(n), &quot;None&quot; =sample_subset%&gt;% add_column(None=ifelse(c(.$FLT3+.$JAK2+ .$NRAS+.$KRAS+ .$PTPN11)==0,1,0))%&gt;% tally(None)%&gt;%pull(n)) }),names(gene_sets))) final&lt;-comutant_sample_status%&gt;%select(!Total)%&gt;% pivot_longer(cols=c(FLT3,PTPN11,JAK2,KRAS,NRAS,Multiple.mutants,None), names_to=&quot;Mutation&quot;, values_to=&quot;Count&quot;) final$Mutation &lt;- gsub(&quot;Multiple.mutants&quot;,&quot;Multiple mutants&quot;,final$Mutation) final$Mutation &lt;- factor(final$Mutation, levels=rev(c(&quot;JAK2&quot;,&quot;PTPN11&quot;,&quot;NRAS&quot;,&quot;KRAS&quot;,&quot;FLT3&quot;,&quot;Multiple mutants&quot;,&quot;None&quot;))) final$Group &lt;- factor(final$Group, levels=rev(c(&quot;IDH1&quot;,&quot;DNMT3A IDH1&quot;,&quot;DNMT3A&quot;,&quot;DNMT3A IDH2&quot;,&quot;IDH2&quot;))) color_set&lt;-rev(brewer.pal(9,&quot;Set1&quot;)[c(1,8,2,3,4,5,9)]) gg_co_mutants_sample&lt;-ggplot(final, aes(x=Group,fill=Mutation,y=Count))+ geom_col(position=&quot;fill&quot;)+theme_classic(base_size=12)+ ylab(&quot;Fraction of Samples&quot;)+ xlab(&quot;&quot;)+coord_flip()+ scale_y_continuous(expand=c(0,0))+ ggtitle(&quot;Sample level data&quot;)+ theme(plot.title = element_text(hjust=0.5))+ scale_fill_manual(values=color_set,&quot;Co mutation&quot;, guide = guide_legend(reverse = TRUE)) plot_grid(gg_co_mutants,gg_co_mutants_sample,ncol=1) Figure 3.14: Miles et al Figure 2G This is one of the very last pieces we wanted to address. As you can see, we observe an ability of epigenetic modifications to synergize and persist in the dominant clone, while signaling mutations appear to be mututally exclusive. We wanted to determine clones that harbor 2+ epigenetic modifiers were larger than clones that harbored 2+ siganling mutations. To investigate the clone size directly, we focused on a subset of samples that were mutated for both DNMT3A and IDH1/2 as well as harboring multiple mutations in RAS/FLT3/PTPN11. detach(&quot;package:plyranges&quot;) # Run back the patients we looked at in the network plots patients_of_interest &lt;- sample_mutations_added%&gt;%filter(DNMT3A==1&amp;signal2==1&amp; (IDH1==1|IDH2==1))%&gt;% pull(Sample) dual_mutation_fractions&lt;-do.call(rbind,setNames(lapply(patients_of_interest,function(sample){ # Extract the genotype matrix for each patient NGT&lt;-final_sample_summary[[sample]]$NGT%&gt;%select(!Clone) # Simplfy the matrix to mutant vs non mutant cells. NGT[NGT&gt;0] &lt;-1 # Extract the mutations of interest data.frame(&quot;Sample&quot;=sample, &quot;Epigenetic&quot;=NGT%&gt;%select_if(grepl(&quot;DNMT3A|IDH&quot;,names(.)))%&gt;% mutate(dual_epi=rowSums(.))%&gt;% dplyr::summarise(Epigenetic=sum(dual_epi&gt;=2)/n()), &quot;Signaling&quot;=NGT%&gt;%select_if(grepl(&quot;FLT3|RAS|JAK2|PTPN11&quot;,names(.)))%&gt;% mutate(dual_signaling=rowSums(.))%&gt;% dplyr::summarise(Signaling=sum(dual_signaling&gt;=2)/n())) }),patients_of_interest)) # Plot the data gg_fraction_comutated_cells&lt;-ggplot(dual_mutation_fractions%&gt;%pivot_longer(cols=!Sample, names_to=&quot;Group&quot;, values_to = &quot;Fraction&quot;), aes(x=Group,y=Fraction,fill=Group))+ geom_boxplot()+ geom_jitter(width=0.1)+ theme_classic(base_size=12)+ scale_fill_brewer(type=&quot;qual&quot;,palette = &quot;Set1&quot;,&quot;Mutation pairs&quot;)+ xlab(&quot;&quot;)+ylab(&quot;Fraction of co-mutated cells&quot;) gg_fraction_comutated_cells Figure 3.15: Miles et al Extended Figure 3G ### need to clean this up with tidy at some point dual_mutation_fractions_melted&lt;-dual_mutation_fractions%&gt;%pivot_longer(cols=!Sample, names_to=&quot;Group&quot;, values_to = &quot;Fraction&quot;) t.test(dual_mutation_fractions_melted$Fraction~factor(dual_mutation_fractions_melted$Group)) ## ## Welch Two Sample t-test ## ## data: dual_mutation_fractions_melted$Fraction by factor(dual_mutation_fractions_melted$Group) ## t = 4.665, df = 6.132, p-value = 0.003259 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.3011350 0.9583285 ## sample estimates: ## mean in group Epigenetic mean in group Signaling ## 0.9016239 0.2718921 "],["figure-3-genetic-trajectory-analysis.html", "Chapter 4 Figure 3: Genetic Trajectory analysis ", " Chapter 4 Figure 3: Genetic Trajectory analysis "],["introductory-text-and-philisophy-of-approach.html", "4.1 Introductory text and philisophy of approach:", " 4.1 Introductory text and philisophy of approach: library(dplyr) library(tidyr) library(reshape2) library(ReinforcementLearning) options(stringsAsFactors = FALSE) setwd(&quot;/Users/bowmanr/Projects/scDNA&quot;) final_sample_summary&lt;-readRDS(file=&quot;./data/final_sample_summary.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) DTAI_genes &lt;- c(&quot;ASXL1&quot;,&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;) DTAI_samples&lt;-names(final_sample_summary)[do.call(c,lapply(names(final_sample_summary),function(sample){ any(grepl(paste(DTAI_genes,sep=&quot;|&quot;,collapse=&quot;|&quot;),colnames(final_sample_summary[[sample]]$NGT))) }))] DTAI_AML_samples &lt;- pheno%&gt;% filter(Sample%in%DTAI_samples&amp;grepl(&quot;AML&quot;,Dx))%&gt;% pull(Sample) "],["functions-for-reward-matrix-and-querying-initating-mutations.html", "4.2 Functions for reward matrix and querying initating mutations", " 4.2 Functions for reward matrix and querying initating mutations Function to create reward matrix create_reward_matrix&lt;-function(Known_mat,weights){ num_type &lt;- 2 num_mutations &lt;- nrow(Known_mat); mutant_names &lt;- Known_mat$Genes num_clones &lt;- ncol(Known_mat) num_states &lt;- num_type^num_mutations possible_mut_list&lt;- unlist(apply(as.matrix(Known_mat),1,function(x){list(0:max(unique(as.numeric(x[-1])))) }),recursive = FALSE) states&lt;-data.frame(expand.grid(possible_mut_list)) state_interactions&lt;-data.frame(expand.grid(apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}), apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}))) state_interactions$possible&lt;-ifelse(apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) sum(abs(A-B))&lt;=1 }),0,NA) state_interactions$action&lt;-apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) if(!is.na(x[&quot;possible&quot;])){ if(sum(abs(B-A))==0){ return(&quot;stay&quot;) } else{ return(mutant_names[which((B-A)==1)]) } } }) dat&lt;-setNames(state_interactions%&gt;%filter(action%in%c(mutant_names,&quot;stay&quot;)), c(&quot;State&quot;,&quot;NextState&quot;,&quot;Reward&quot;,&quot;Action&quot;))[,c(1,4,2,3)] dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$NextState%in%names(weights),weights[x$NextState],x$Reward) })) dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$Action%in%&quot;stay&quot;,0,x$Reward) })) dat$State &lt;- as.character(dat$State) dat$NextState &lt;- as.character(dat$NextState) dat$Action &lt;- as.character(dat$Action) control &lt;- list(alpha = 0.8, gamma = 0.9) model &lt;- ReinforcementLearning(data = dat, s = &quot;State&quot;, a = &quot;Action&quot;, r = &quot;Reward&quot;, s_new = &quot;NextState&quot;, iter = 1,control=control) x&lt;- model$Q rownames(x) &lt;- substring(rownames(x),1) Q_mat &lt;- setNames(melt(x),c(&quot;State&quot;,&quot;Action&quot;,&quot;Q&quot;)) set&lt;-inner_join(dat,Q_mat,by=c(&quot;State&quot;,&quot;Action&quot;)) set$Valid &lt;- TRUE return(set) } Function for retraining with reinforcement learning create_reward_matrix_retrain&lt;-function(Known_mat,weights){ num_type &lt;- 2 num_mutations &lt;- nrow(Known_mat); mutant_names &lt;- Known_mat$Genes num_clones &lt;- ncol(Known_mat) num_states &lt;- num_type^num_mutations possible_mut_list&lt;- unlist(apply(as.matrix(Known_mat),1,function(x){list(0:max(unique(as.numeric(x[-1])))) }),recursive = FALSE) states&lt;-data.frame(expand.grid(possible_mut_list)) state_interactions&lt;-data.frame(expand.grid(apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}), apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}))) state_interactions$possible&lt;-ifelse(apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) sum(abs(A-B))&lt;=1 }),0,NA) state_interactions$action&lt;-apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) if(!is.na(x[&quot;possible&quot;])){ if(sum(abs(B-A))==0){ return(&quot;stay&quot;) } else{ return(mutant_names[which((B-A)==1)]) } } }) dat&lt;-setNames(state_interactions%&gt;%filter(action%in%c(mutant_names,&quot;stay&quot;)), c(&quot;State&quot;,&quot;NextState&quot;,&quot;Reward&quot;,&quot;Action&quot;))[,c(1,4,2,3)] dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$NextState%in%names(weights),weights[x$NextState],x$Reward) })) dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$Action%in%&quot;stay&quot;,0,x$Reward) })) dat$State &lt;- as.character(dat$State) dat$NextState &lt;- as.character(dat$NextState) dat$Action &lt;- as.character(dat$Action) control &lt;- list(alpha = 0.8, gamma = 0.9) model1 &lt;- ReinforcementLearning(data = dat, s = &quot;State&quot;, a = &quot;Action&quot;, r = &quot;Reward&quot;, s_new = &quot;NextState&quot;, iter = 1,control=control) model &lt;- ReinforcementLearning(data = dat, s = &quot;State&quot;, a = &quot;Action&quot;, r = &quot;Reward&quot;, s_new = &quot;NextState&quot;, iter = 1000,control=list(alpha = 0.8, gamma = 0.9,epsilon=0.4),model=model1) x&lt;- model$Q rownames(x) &lt;- substring(rownames(x),1) Q_mat &lt;- setNames(melt(x),c(&quot;State&quot;,&quot;Action&quot;,&quot;Q&quot;)) set&lt;-inner_join(dat,Q_mat,by=c(&quot;State&quot;,&quot;Action&quot;)) set$Valid &lt;- TRUE return(set) } Query initiating mutations function query_initiating_mutations&lt;-function(graph_results_test){ graph_results_test&lt;- graph_results[[sample]] start_index&lt;-paste(rep(0,length(strsplit(graph_results_test$State[1],split=&quot;_&quot;)[[1]])),sep=&quot;_&quot;,collapse=&quot;_&quot;) possible_starting_actions&lt;-graph_results_test%&gt;%filter(State==start_index&amp;Action!=&quot;stay&quot;)%&gt;%pull(Action) final_results&lt;-list() initating_action_count&lt;-0 for(initating_action in possible_starting_actions){ # print(initating_action) set &lt;- graph_results_test initating_action_count&lt;-initating_action_count+1 storage_results&lt;- list() branches&lt;-0 state_to_kill &lt;- set%&gt;%filter(State==start_index&amp;Action==initating_action)%&gt;%pull(NextState) start_killed &lt;- sum(set%&gt;%filter(State==state_to_kill)%&gt;%pull(Valid)) while(start_killed&gt;0){ #print(branches) # print(start_killed) branches &lt;- branches +1 number_of_mutations&lt;-0 state_log&lt;- list() optimal_reward&lt;-list() action_log&lt;-list() current_state&lt;- start_index indicator&lt;-TRUE nextState&lt;-0 while(current_state!=nextState) { # print(number_of_mutations) number_of_mutations &lt;- number_of_mutations+1 if(number_of_mutations==1){ state_log[[number_of_mutations]] &lt;- start_index } current_state &lt;- state_log[[number_of_mutations]] nextState_indicator&lt;- FALSE while(nextState_indicator==FALSE){ if(number_of_mutations==1){ max_potential_action_index&lt;- set%&gt;% filter(State==current_state&amp;Action==initating_action) } else { max_potential_action_index &lt;- set%&gt;% filter(State==current_state&amp;Valid==TRUE)%&gt;% filter(Q==max(Q))%&gt;%slice_sample(n=1) } if(nrow(max_potential_action_index)==0){ break } max_potential_action &lt;- max_potential_action_index%&gt;%pull(NextState) next_valid_action &lt;- any(set%&gt;%filter(State==max_potential_action&amp;Action!=&quot;stay&quot;)%&gt;%pull(Valid)) if(next_valid_action==TRUE){ nextState &lt;-max_potential_action current_action &lt;- max_potential_action_index%&gt;%pull(Action) nextState_indicator==TRUE break } else{ set[set$State%in%max_potential_action_index[&quot;State&quot;]&amp; set$Action%in%max_potential_action_index[&quot;Action&quot;],&quot;Valid&quot;] &lt;- FALSE } } if(nrow(set%&gt;%filter(State==current_state&amp;Action==current_action))==0){ optimal_reward[[number_of_mutations]] &lt;-NA } else { optimal_reward[[number_of_mutations]] &lt;- set%&gt;% filter(State==current_state&amp;Action==current_action)%&gt;% pull(Reward) } state_log[[number_of_mutations+1]]&lt;- nextState action_log[[number_of_mutations]] &lt;- current_action if(current_action==nextState){ indicator==FALSE state_log[[number_of_mutations+1]]&lt;-NULL break } } optimal_reward[[number_of_mutations+1]] &lt;- NA action_log[[number_of_mutations+1]] &lt;- NA storage_results[[branches]] &lt;-data.frame(&quot;states&quot;=do.call(rbind,state_log),#[1:(length(state_log)-1)]), &quot;actions&quot;=do.call(rbind,action_log), &quot;reward&quot;=do.call(rbind,optimal_reward), &quot;nextState&quot;=do.call(rbind,c(state_log[2:length(state_log)],NA)) ) storage_results[[branches]] &lt;- storage_results[[branches]]%&gt;% filter(states!=nextState) storage_results[[branches]]$cumulative_reward &lt;- cumsum(storage_results[[branches]]$reward) #storage_results[[branches]] &lt;-storage_results[[branches]][1:which.max(storage_results[[branches]]$cumulative_reward), ] set[set$State%in%current_state&amp;set$Action%in%current_action,&quot;Valid&quot;] &lt;- FALSE start_killed &lt;- sum(set%&gt;%filter(State==state_to_kill)%&gt;%pull(Valid)) } final_results[[initating_action_count]]&lt;-storage_results[!duplicated(storage_results)] } names(final_results)&lt;-possible_starting_actions return(final_results) } Trajectory summarization trajectory_summariztion &lt;- function(sample,optimal_mutants_only=FALSE){ #Extract out sample of interest all_results &lt;-final_results[[sample]] #apply over each potential initating mutation and identify the stepwise trajectory that accumulates the most reward all_results_filtered&lt;-setNames(lapply(names(all_results),function(initiating_mutation){ #print(initiating_mutation) storage_results&lt;-all_results[[initiating_mutation]] storage_results[lapply(storage_results,function(x){sum(x$reward,na.rm = TRUE)})==0]&lt;-NULL if(length(storage_results)==0){ return(NULL) } storage_results&lt;-lapply(storage_results,function(x){x[1:which.max(x$cumulative_reward),]}) if(length(storage_results)==0){ print(&quot;error&quot;) return(NULL) break } else { # Extract columnss of interest final&lt;-do.call(rbind,storage_results)[,c(&quot;states&quot;,&quot;nextState&quot;,&quot;reward&quot;,&quot;actions&quot;)] # Remove decisions that do not result in a state change, or terminal nodes that do not exist nodes_to_remove &lt;- setdiff( setdiff(final$nextState, final$states), final_sample_summary[[sample]]$Clones$Clone) final &lt;- final%&gt;% filter(!nextState%in%nodes_to_remove)%&gt;% distinct()%&gt;% mutate(&quot;initiating_mutation&quot;=initiating_mutation)%&gt;% unite(col=&quot;edge&quot;,states,nextState,sep=&quot;-&gt;&quot;,remove=FALSE)%&gt;% relocate(edge,.after = last_col()) return(final) } }),names(all_results)) if(length(all_results_filtered)==0){ return(NULL) } else if(all(lapply(all_results_filtered,is.null))){ return(NULL) } else { optimal&lt;-names(which.max(do.call(c,lapply(all_results_filtered,function(x){ sum(x$reward) })))) all_mutants &lt;-unique(names(all_results_filtered)) mutation_output &lt;-if(optimal_mutants_only){ (optimal) } else{ (all_mutants) } final&lt;-do.call(rbind,all_results_filtered)%&gt;% filter(initiating_mutation%in%mutation_output)%&gt;% mutate(observed=ifelse(states%in%final_sample_summary[[sample]]$Clones$Clone&amp; nextState%in%final_sample_summary[[sample]]$Clones$Clone, &quot;Yes&quot;,&quot;No&quot;)) return(final) } } plot_optimal_graph_for_trajectory_new&lt;-function(sample,optimal_mutants_only){ final &lt;- trajectory_summariztion(sample,optimal_mutants_only=TRUE) if(final==&quot;error&quot;|is.null(final)){ return(&quot;error&quot;) } else{ graph&lt;-graph_from_data_frame(final,directed=T) weights&lt;-final_sample_summary[[sample]]$Clones$Count/sum(final_sample_summary[[sample]]$Clones$Count) names(weights) &lt;-final_sample_summary[[sample]]$Clones$Clone weight_subset&lt;-weights[names(weights)%in%names(V(graph))] nodes_to_add_names&lt;-setdiff(names(V(graph)),names(weights)) nodes_to_add &lt;- rep(0.1,length(nodes_to_add_names)) names(nodes_to_add)&lt;-nodes_to_add_names weight_final &lt;- c(weight_subset,nodes_to_add)[names(V(graph))] clone_colors &lt;-ifelse(names(V(graph))%in%final_sample_summary[[sample]]$Clones$Clone,brewer.pal(5,&quot;Reds&quot;)[5],&quot;grey80&quot;) observe_edges &lt;- final%&gt;%filter(observed==&quot;Yes&quot;)%&gt;%pull(edge) plot(graph,layout=layout_as_tree, vertex.color=ifelse(names(V(graph))%in%final_sample_summary[[sample]]$Clones$Clone,brewer.pal(5,&quot;Reds&quot;)[5],&quot;grey80&quot;), vertex.frame.color=ifelse(names(V(graph))%in%final_sample_summary[[sample]]$Clones$Clone ,brewer.pal(5,&quot;Reds&quot;)[5],&quot;grey80&quot;), vertex.size=log2(1+weight_final*500), vertex.label=NA, edge.color=ifelse(edge_attr(graph)$edge %in%observe_edges,brewer.pal(5,&quot;Blues&quot;)[5],&quot;grey80&quot;))#, } } "],["executing-the-analysis.html", "4.3 Executing the Analysis", " 4.3 Executing the Analysis Create reward matrices graph_results&lt;-list() graph_results &lt;- lapply(DTAI_AML_samples, function(i){ mutations &lt;-setdiff(colnames(final_sample_summary[[i]]$NGT),&quot;Clone&quot;) Known_mat &lt;-final_sample_summary[[i]]$Clones%&gt;% separate(col=Clone, remove = FALSE, into=`mutations`)%&gt;% select(c(all_of(mutations),Clone))%&gt;% pivot_longer(cols=`mutations`, names_to=&quot;Genes&quot;, values_to=&quot;Genotype&quot;)%&gt;% pivot_wider(names_from=Clone, values_from = Genotype)%&gt;% mutate_at(vars(-Genes), funs(as.numeric)) weights &lt;-final_sample_summary[[i]]$Clones$Count/sum(final_sample_summary[[i]]$Clones$Count)*100 names(weights)&lt;- final_sample_summary[[i]]$Clones$Clone graph_results[[i]]&lt;-create_reward_matrix(Known_mat,weights) }) names(graph_results) &lt;-DTAI_AML_samples saveRDS(graph_results,file=&quot;graph_results_complete.rds&quot;) Query mutations graph_results &lt;-readRDS(file=&quot;./data/graph_results_complete.rds&quot;) final_results&lt;-list() for(i in 1:length(graph_results)){ # print(names(graph_results)[i]) final_results[[i]]&lt;-query_initiating_mutations(graph_results[[i]]) } names(final_results) &lt;- names(graph_results) saveRDS(final_results,file=&quot;./data/MDP_trajectory_final.rds&quot;) "],["plotting-the-data.html", "4.4 Plotting the data", " 4.4 Plotting the data library(dplyr) library(tidyr) library(reshape2) library(RColorBrewer) library(igraph) options(stringsAsFactors = FALSE) setwd(&quot;/Users/bowmanr/Projects/scDNA/scDNA_myeloid/&quot;) final_sample_summary&lt;-readRDS(file=&quot;./data/final_sample_summary.rds&quot;) pheno&lt;-readRDS(file=&quot;./data/pheno.rds&quot;) graph_results &lt;-readRDS(file=&quot;./data/graph_results_complete.rds&quot;) final_results&lt;-readRDS(file=&quot;./data/MDP_trajectory_final.rds&quot;) plot_optimal_graph_for_trajectory_new(&quot;MSK78&quot;,optimal_mutants_only=TRUE) output&lt;-lapply(names(final_results),function(sample){ if(!sample%in%c(&quot;MSK94&quot;)){ final&lt;-trajectory_summariztion(sample,optimal_mutants_only = FALSE) if(final==&quot;error&quot;){ return(NULL) } else { final%&gt;%group_by(initiating_mutation)%&gt;% distinct(nextState,reward)%&gt;% summarize(total=sum(reward)) }} }) genes_of_interest &lt;- c(&quot;ASXL1&quot;,&quot;DNMT3A&quot;,&quot;TET2&quot;,&quot;IDH1&quot;,&quot;IDH2&quot;,&quot;NPM1&quot;,&quot;KRAS&quot;,&quot;NRAS&quot;,&quot;PTPN11&quot;,&quot;FLT3&quot;,&quot;JAK2&quot;) out_mat&lt;-data.frame(do.call(rbind,output))%&gt;%filter(initiating_mutation!=&quot;exclude&quot;) out_mat$Gene &lt;- do.call(rbind,strsplit(out_mat$initiating_mutation,split=&quot;[_\\\\.]&quot;))[,1] out_mat&lt;- out_mat%&gt;%filter(Gene%in%genes_of_interest) out_mat$total &lt;- as.numeric(out_mat$total) gene_order &lt;- out_mat%&gt;%group_by(Gene)%&gt;%summarize(median=median(total))%&gt;%arrange(median)%&gt;%pull(Gene) out_mat$Gene &lt;- factor(out_mat$Gene,levels=gene_order) ggA&lt;-ggplot(out_mat,aes(x=Gene,y=total,fill=Gene))+ geom_boxplot(outlier.shape=NA)+ scale_fill_manual(values=tol.rainbow(n=length(levels(out_mat$Gene))))+ geom_jitter(width=0.2,size=0.5)+ coord_flip()+theme_bw(base_size=8)+ guides(fill=FALSE)+ ylab(&quot;Fraction of sample explained \\n by initiating mutation&quot;) A&lt;- &quot;NPM1&quot; B&lt;-&quot;NRAS&quot; double_mutant_samples&lt;-names(graph_results)[do.call(c,lapply(names(graph_results),function(x){ with(graph_results[[x]],any(grepl(A,unique(Action)))&amp;any(grepl(B,unique(Action)))) }))] double_mutant_order&lt;-setNames(lapply(double_mutant_samples,function(x){ sample &lt;- final_sample_summary[[x]] mutations &lt;- colnames(sample$NGT) clones&lt;- sample$Clone A_het_clones &lt;-sample$Architecture%&gt;%filter(Genotype==&quot;Heterozygous&quot;)%&gt;%filter(grepl(A,Mutant))%&gt;%distinct(Clone)%&gt;%pull(Clone) B_het_clones &lt;-sample$Architecture%&gt;%filter(Genotype==&quot;Heterozygous&quot;)%&gt;%filter(grepl(B,Mutant))%&gt;%distinct(Clone)%&gt;%pull(Clone) AB_het_clones&lt;-intersect(A_het_clones,B_het_clones) AB_clone_sizes &lt;- graph_results[[x]]%&gt;%filter(NextState%in%AB_het_clones)%&gt;%filter(grepl(A,Action)|grepl(B,Action))%&gt;%filter(Reward==max(Reward))%&gt;%distinct(Reward)%&gt;%pull(Reward) antecdenent_options&lt;-graph_results[[x]]%&gt;%filter(NextState%in%AB_het_clones)%&gt;%filter(grepl(A,Action)|grepl(B,Action))%&gt;%filter(Reward==max(Reward)) antecendent_clones&lt;-graph_results[[x]]%&gt;%filter(NextState%in%antecdenent_options$State)%&gt;%filter(Reward!=0) set&lt;-setNames(merge(antecdenent_options[,1:4],antecendent_clones[,3:4],by.x=&quot;State&quot;,by.y=&quot;NextState&quot;), c(&quot;Antecedent&quot;,&quot;Mutation&quot;,&quot;Max_het_state&quot;,&quot;Max_het_size&quot;,&quot;Antecednet_size&quot;)) Mut_A &lt;- set%&gt;%filter(grepl(A,set$Mutation))%&gt;%distinct(Mutation,Antecednet_size)%&gt;%filter(Antecednet_size==max(Antecednet_size))%&gt;%pull(Mutation) Mut_B &lt;- set%&gt;%filter(grepl(B,set$Mutation))%&gt;%distinct(Mutation,Antecednet_size)%&gt;%filter(Antecednet_size==max(Antecednet_size))%&gt;%pull(Mutation) set &lt;- set%&gt;%filter(Mutation%in%c(Mut_A,Mut_B)) convergence &lt;- ifelse((any(grepl(A,set$Mutation)) &amp;any(grepl(B,set$Mutation))),&quot;Yes&quot;,&quot;No&quot;) if(convergence==&quot;Yes&quot;){ sizes &lt;- setNames(data.frame(&quot;Double_mutant&quot;=unique(set$Max_het_size), B=unique(set%&gt;%filter(grepl(A,set$Mutation))%&gt;%pull(Antecednet_size)), A=unique(set%&gt;%filter(grepl(B,set$Mutation))%&gt;%pull(Antecednet_size))), c(&quot;Double_mutant&quot;,B,A)) } else if(any(grepl(B,set$Mutation))) { sizes &lt;- setNames(data.frame(&quot;Double_mutant&quot;=unique(set$Max_het_size), A=unique(set%&gt;%filter(grepl(B,set$Mutation))%&gt;%pull(Antecednet_size))), c(&quot;Double_mutant&quot;,A)) } else if(any(grepl(A,set$Mutation))) { sizes &lt;- setNames(data.frame(&quot;Double_mutant&quot;=unique(set$Max_het_size), B=unique(set%&gt;%filter(grepl(A,set$Mutation))%&gt;%pull(Antecednet_size))), c(&quot;Double_mutant&quot;,B)) } else if(nrow(set)&lt;1){ return(data.frame(&quot;Double_mutant&quot;=0)) } return(sizes) }),double_mutant_samples) double_mutant_order$Dummy &lt;- data.frame(A=0, &quot;Double_mutant&quot;=0, B=0) colnames(double_mutant_order$Dummy) &lt;- c(A,&quot;Double_mutant&quot;,B) double_mutant_order_mat&lt;-plyr::rbind.fill(setNames(lapply(double_mutant_order,function(x){data.frame(x)}),c(double_mutant_samples))) rownames(double_mutant_order_mat) &lt;- c(double_mutant_samples,&quot;Dummy&quot;) double_mutant_order_mat$Sample &lt;- rownames(double_mutant_order_mat) double_mutant_order_mat&lt;- double_mutant_order_mat%&gt;%filter(!Double_mutant==0&amp;!Sample==&quot;Dummy&quot;) double_mutant_order_mat$Convergence &lt;- ifelse((!is.na(double_mutant_order_mat[,A])&amp;!is.na(double_mutant_order_mat[,B]))&amp; double_mutant_order_mat[,A]&gt;0&amp; double_mutant_order_mat[,B]&gt;0,&quot;Convergent&quot;, ifelse(is.na(double_mutant_order_mat[,A])&amp;double_mutant_order_mat[,B]&gt;0,B,A)) melted_set &lt;-setNames(melt(double_mutant_order_mat),c(&quot;Sample&quot;,&quot;Convergence&quot;,&quot;Clone&quot;,&quot;Size&quot;)) melted_set$Clone &lt;-factor(melted_set$Clone,levels=c(A,&quot;Double_mutant&quot;,B)) melted_set$Clone &lt;-plyr::revalue(melted_set$Clone,c(&quot;Double_mutant&quot;=&quot;Double mutant&quot;)) melted_set$Convergence &lt;-factor(melted_set$Convergence,levels=c(&quot;Convergent&quot;,A,B)) melted_set[is.na(melted_set)]&lt;-0 gene_name_A &lt;- melted_set%&gt;%filter(Convergence==A) colors_set &lt;- c(&quot;black&quot;, &quot;black&quot;, brewer.pal(5,&quot;Blues&quot;)[5], brewer.pal(5,&quot;Reds&quot;)[5]) names(colors_set) &lt;- c(&quot;Double mutant&quot;,&quot;Convergent&quot;,A,B) alpha_set &lt;- c(0.5,0.5,1,1) names(alpha_set) &lt;- names(colors_set) melted_set$Mutation_status &lt;- factor(ifelse(melted_set$Clone==&quot;Double mutant&quot;,&quot;Double mutant&quot;,&quot;Single Mutant&quot;),levels=c(&quot;Single Mutant&quot;,&quot;Double mutant&quot;)) melted_set_x&lt;-rbind(melted_set%&gt;%filter(Mutation_status==&quot;Double mutant&quot;),melted_set) samples &lt;- tally(melted_set%&gt;%distinct(Sample))%&gt;%pull(n) melted_set_x[1:(samples),&quot;Gene&quot;] &lt;-A melted_set_x[(samples+1):(2*samples),&quot;Gene&quot;] &lt;-B melted_set_x[is.na(melted_set_x$Gene),&quot;Gene&quot;] &lt;- as.character(melted_set_x[is.na(melted_set_x$Gene),&quot;Clone&quot;]) melted_set_x$Group2 &lt;- paste(melted_set_x$Sample,melted_set_x$Gene,sep=&quot; &quot;) ggA&lt;-ggplot(melted_set_x#%&gt;% # filter(Convergence==&quot;Convergent&quot;)%&gt;% # distinct(Sample,Clone,Size,Gene) ,aes(x=Clone,y=Size/100,group=Sample))+ geom_point(aes(fill=Clone),shape=ifelse(melted_set_x$Size==0,1,21), size=2) + geom_line(aes(color=Gene),guide=FALSE)+ scale_fill_manual(values=colors_set[-2],guide=FALSE) + scale_colour_manual(values=colors_set[-2],guide=FALSE) + ggtitle(paste(A,B))+ theme_classic(base_size=8)+theme(plot.title = element_text(hjust=0.5))+ ylab(&quot;Fraction of sample \\n in mutant clone&quot;)+ xlab(&quot;&quot;)#+ #melted_set%&gt;%filter(Clone%in%c(A,B))%&gt;%summarize(p=t.test(Size~Clone)$p.value) #melted_set%&gt;%filter(Clone%in%c(A,&quot;Double_mutant&quot;))%&gt;%summarize(p=t.test(Size~Clone)$p.value) #melted_set%&gt;%filter(Clone%in%c(B,&quot;Double_mutant&quot;))%&gt;%summarize(p=t.test(Size~Clone)$p.value) ggB&lt;-ggplot(melted_set%&gt;%distinct(Sample,Convergence), aes(x=Convergence,fill=Convergence))+ scale_fill_manual(values=colors_set,guide=FALSE) + geom_bar()+theme_classic(base_size=8)+ ggtitle(&quot;Initiating Mutation&quot;)+ scale_y_continuous(expand=c(0,0))+ theme(plot.title = element_text(hjust=0.5))+ scale_x_discrete(drop=FALSE)+ xlab(&quot;&quot;)#+ ggC&lt;-ggplot(melted_set%&gt;%filter(Clone%in%c(A,B)),aes(x=Clone,y=Size/100,fill=Clone))+ geom_boxplot()+ theme_classic(base_size=8)+ scale_fill_manual(values=colors_set,guide=FALSE) + ggtitle(&quot;Single mutant \\n clone size&quot;)+ ylab(&quot;Fraction of sample in \\n single mutant clone&quot;)+ theme(plot.title = element_text(hjust=0.5))+ #scale_x_discrete(drop=FALSE)+ xlab(&quot;&quot;)#+ "],["final-words.html", "Chapter 5 Final Words", " Chapter 5 Final Words So much more to come… Thanks for your patience. "],["Appendix.html", "Chapter 6 Appendix ", " Chapter 6 Appendix "],["AppendixA.html", "6.1 Import from Tapestri Insights", " 6.1 Import from Tapestri Insights Here is how we used to do it and what I wrote last time: Our first step is to extract the data from output from Tapestri Insights. To do so, I’ve written a few functions that will be helpful to do this on a long list of samples. As this project grew it becamse clear that this work was better suited for a package. Before that though, looking forward we’ll plan to analyze data using the tapestri R package and integrate formatting from standard single cell rna-seq data in R. For now, we’ll just source a series of functions that can be found in the appendix. I’ll build in explanations as best I can over time. Below I’ve copied directly the README.txt file output from Tapestri Insights, as it most accurately describes the output from each of the files. This folder contains data exported from Tapestri Insights 2.1 application. The following files are included: DP.csv - read depth. The Read Depth per Variant metric is the filtered depth, at the cell level. This gives the number of filtered reads that support each of the reported alleles. GQ.csv - quality scores. The genotype quality score represents the Phred-scaled confidence that the genotype assignment (GT) is correct, derived from the genotype normalized likelihoods of possible genotypes (PL). Specifically, the quality score is the difference between the PL of the second most likely genotype, and the PL of the most likely genotype. The values of the PLs are normalized so that the most likely PL is always 0, so the quality score ends up being equal to the second smallest PL, unless that PL is greater than 99. In GATK, the value of quality score is capped at 99 because larger values are not more informative, but they take more space in the file. So if the second most likely PL is greater than 99, we still assign a quality score of 99. Basically the GQ gives you the difference between the likelihoods of the two most likely genotypes. If it is low, you can tell there is not much confidence in the genotype, i.e. there was not enough evidence to confidently choose one genotype over another. NGT.csv - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown). Calls are made by GATK/Haplotypecaller. AF.csv - variant allele frequency (# of reads with evidence for mutation / total # of reads * 100) Variants.csv - variant metadata In the weeds a little here to explain a detour It is worth mentioning here on why we chose to proceed in the following fashion, and why we didn’t do all the parsing in R directly from the loom file. When we first started running these samples, there were some incompatibilities with the loom v3 files produced from Bluebee, and the available packages in R that were only working with loom v2. This has now of course been corrected. We considered using python, but the reality was my proficiency in R was significantly greater than python and this was not a tennable solutuon. Going through Tapestri Insights also had two added benefits: 1) efficient SNV to protein identification, and 2) data access for others in the lab who were not quickly pouring into the data in R. Future projects in our lab are likely to bypass Tapestri Insights, and bring loom files straight into R as you’ll see in the DNA+Protein section. Furthermore, as this project progressed, new versions of Tapestri Insights became available, and this led to minor modifications in column names and file names. All of this was parsed in R, and the version of Tapestri Insight did not change the analysis, we just did not rerun &gt;100 samples through Tapestri Insights to make sure it was all formatted directly. This is all to explain why you will see some patchwork code in some of the extraction functions upcoming in the next section. all_samples &lt;- list.files(&quot;/Volumes/LevineLab/Levine Lab/MissionBio_Tapestri/Insights_Output/ASH_Cohort&quot;) blacklist &lt;- read.xls(&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/From_LAM/Blacklist2.xlsx&quot;) whitelist &lt;- read.xls(&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/From_LAM/Whitelist.xlsx&quot;) pheno &lt;- read.xls(&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/From_LAM/pheno_MBio.xlsx&quot;) sample_set&lt;- intersect(as.character(all_samples),as.character(pheno$Sample.ID)) setwd(&quot;/Volumes/LevineLab/Levine Lab/MissionBio_Tapestri/Insights_Output/ASH_Cohort&quot;) sample_SNPS&lt;-lapply(as.list(sample_set),function(x){ y&lt;-extract_SNP_info(x) z &lt;- y[!(rownames(y)%in%blacklist[,&quot;Blacklisted.coordinate&quot;]|y[,&quot;protein&quot;]%in%blacklist[,&quot;Protein.Change&quot;]),] z[,&quot;SNP_variant&quot;] &lt;- rownames(z) z[,&quot;Sample&quot;] &lt;- x return(z) }) names(sample_SNPS) &lt;- sample_set saveRDS(sample_SNPS,file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/sample_SNPS.rds&quot;) sample_NGTs&lt;-lapply(as.list(names(sample_SNPS)),function(x){ extract_NGT_files(x,sample_SNPS[[x]]$SNP_variant) }) names(sample_NGTs) &lt;- names(sample_SNPS) named_sample_NGTs&lt;-lapply(sample_NGTs,function(x){ rownames(x) &lt;- paste(&quot;Cell&quot;,1:nrow(x),sep=&quot;_&quot;) return(x) }) saveRDS(named_sample_NGTs,file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/sample_NGTs.rds&quot;) pheno &lt;- read.xls(&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/From_LAM/pheno_MBio.xlsx&quot;) # Now we filter out any synonymous mutations as well sample_SNPS_filter&lt;-lapply(sample_SNPS,function(x){ x%&gt;%filter(!(grepl(&quot;[=&gt;]&quot;,protein)))%&gt;%filter(!grepl(&quot;ASXL1:p.[DNGPIL]81&quot;,protein))%&gt;%filter(!grepl(&quot;FLT3_INS_chr13:28602226:&quot;,protein)) }) colnames_to_grab &lt;- c(&quot;Variant&quot;,&quot;protein&quot;,&quot;Gene&quot;,&quot;gene&quot;,&quot;allele_freq_loom&quot;,&quot;allele_freq&quot;,&quot;SNP_variant&quot;,&quot;Sample&quot;) sample_SNPS_filter_cols&lt;-lapply(sample_SNPS_filter,function(x){x[,colnames(x)%in%colnames_to_grab]}) sample_NGTs_filter&lt;-lapply(names(sample_SNPS),function(x){setNames(data.frame(sample_NGTs[[x]][,sample_SNPS_filter[[x]][,&quot;SNP_variant&quot;]]),sample_SNPS_filter[[x]][,&quot;SNP_variant&quot;])}); names(sample_NGTs_filter) &lt;- names(sample_SNPS) final_variants_of_interest&lt;-lapply(sample_NGTs_filter,function(x){colnames(x)[colSums(x)&gt;0]}) names(final_variants_of_interest) &lt;-names(sample_SNPS) test_NGT &lt;- setNames(lapply(names(final_variants_of_interest),function(x){setNames(data.frame(sample_NGTs_filter[[x]][,final_variants_of_interest[[x]]]),final_variants_of_interest[[x]] )}),names(sample_SNPS)) final_NGT&lt;-setNames(lapply(names(test_NGT),function(x){ if(ncol(test_NGT[[x]])&gt;1){ j&lt;-test_NGT[[x]][,apply(test_NGT[[x]],2,function(z){sum(z%in%c(1,2))&gt;=2})] z&lt;-j[!apply(j,1,function(y){any(y==3)}),] q&lt;-z[,apply(z,2,function(h){sum(h%in%c(1,2))&gt;=2})] } else{ j&lt;-data.frame(test_NGT[[x]][test_NGT[[x]]==1|test_NGT[[x]]==2]) q&lt;-data.frame(j[!j==3]) } return(q) }),names(test_NGT)) final_variants_of_interest &lt;- lapply(final_NGT,colnames) final_SNP &lt;-setNames(lapply(names(final_variants_of_interest),function(x){ sample_SNPS_filter_cols[[x]]%&gt;%filter(SNP_variant%in%final_variants_of_interest[[x]])}),names(sample_SNPS)) final_SNP_mat&lt;-do.call(bind_rows,final_SNP) final_SNP_mat$Gene &lt;- ifelse(final_SNP_mat$Gene==&quot;&quot;,&quot;FLT3&quot;,final_SNP_mat$Gene) final_SNP_mat$gene &lt;- ifelse(final_SNP_mat$gene==&quot;&quot;,&quot;FLT3&quot;,final_SNP_mat$gene) final_SNP_mat$Gene &lt;- ifelse(is.na(final_SNP_mat$Gene),final_SNP_mat$gene,final_SNP_mat$Gene) colnames(final_SNP_mat)[5] &lt;- &quot;Sample.ID&quot; pheno_mut_melted&lt;-inner_join(pheno,final_SNP_mat[,2:5]) pheno_mut_melted$Gene&lt;- factor(pheno_mut_melted$Gene,levels=names(sort(table(pheno_mut_melted$Gene), decreasing=TRUE))) for(x in 1:length(names(final_NGT))){ colnames(final_NGT[x][[1]])&lt;-pheno_mut_melted[pheno_mut_melted$SNP_variant%in%colnames(final_NGT[[x]])&amp; pheno_mut_melted$Sample.ID==names(final_NGT)[x],&quot;protein&quot;] rownames(final_NGT[x][[1]])&lt;-paste(&quot;Cell&quot;,1:dim(final_NGT[x][[1]])[[1]],sep=&quot;_&quot;) } #These lines were used to regenerated a new blacklist protein_variant_counts&lt;-data.frame(sort(table(pheno_mut_melted[,&quot;protein&quot;]),decreasing=TRUE)) SNP_variant_counts&lt;-data.frame(sort(table(pheno_mut_melted[,&quot;SNP_variant&quot;]),decreasing=TRUE)) Muts_per_patientx&lt;-data.frame(sort(table(pheno_mut_melted[,&quot;Sample.ID&quot;]),decreasing=TRUE)) processing_NGT &lt;- final_NGT names(processing_NGT) &lt;- names(final_NGT) cell_number_per_sample_cutoff&lt;-40 final_sample_set&lt;-names(which(do.call(rbind,lapply(processing_NGT,dim))[,1]&gt;cell_number_per_sample_cutoff)) samples_of_interest&lt;-setdiff(names(processing_NGT),final_sample_set) lapply(processing_NGT[samples_of_interest],nrow) lapply(sample_NGTs[samples_of_interest],nrow) cells_of_interest&lt;-setNames(lapply(processing_NGT[final_sample_set],function(x){ rownames(x) }),final_sample_set) saveRDS(processing_NGT[final_sample_set],file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/final_NGTs.rds&quot;) saveRDS(pheno_mut_melted,file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/pheno_mut_melted.rds&quot;) saveRDS(final_sample_set,file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/final_sample_set.rds&quot;) saveRDS(cells_of_interest,file=&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/Analysis/2020/January/cells_of_interest.rds&quot;) "],["functions.html", "6.2 Functions", " 6.2 Functions I’m likely going to wrap all of this into a package soon, but here we will start with a set of packages and functions used throughout the study. I need to go through and annotate with package was used with with function, and that will take a little time. So for the sake of making the code available as soon as possible, I’ll present the intermediate product here. Packages The following are a list of packages that are used during the study. I will update this list with the minial set and begin to put together a package soon. library(ape) library(circlize) library(cooccur) library(corrplot) library(cowplot) library(data.table) library(dplyr) library(forcats) library(gdata) library(ggbeeswarm) library(ggcorrplot) library(ggnet) library(ggplotify) library(ggplot2) library(ggrepel) library(ggridges) library(grid) library(gridExtra) library(ggthemes) library(ggtree) library(igraph) library(knitr) library(miscTools) library(network) library(pals) library(parallel) library(pheatmap) library(phylobase) library(purrr) library(qgraph) library(RColorBrewer) library(rcompanion) library(ReinforcementLearning) library(reshape2) library(sna) library(tidygraph) library(tidyr) library(tidyverse) library(TRONCO) library(vegan) library(widyr) Custom functions options(stringsAsFactors=FALSE) random_distribution_NGT_CI &lt;- function(NGT_to_clone_list,clonal_abundance,sample_to_test,replicates,clone_cutoff){ mat_of_interest &lt;- NGT_to_clone[[sample_to_test]][,1:(ncol(NGT_to_clone[[sample_to_test]])-1)] bulk_VAF_order &lt;-names(sort(colSums(mat_of_interest),decreasing=TRUE)) test&lt;-replicate(n=replicates,apply(mat_of_interest,MARGIN=c(2),function(x){ z&lt;-sample(x,size=length(x),replace=FALSE) return(as.numeric(z))}),simplify = &quot;array&quot;) test2&lt;-apply(test,3,function(q){ x&lt;-data.frame(q[,bulk_VAF_order], &quot;Clone&quot;=apply(q[,bulk_VAF_order],1, function(p){paste(p,sep=&quot;_&quot;,collapse=&quot;_&quot;)})) y&lt;-data.table(data.frame(&quot;Count&quot;=as.matrix(table(x[,&quot;Clone&quot;])), &quot;Clone&quot;=names(table(x[,&quot;Clone&quot;]))), key=&quot;Count&quot;) y$Clone&lt;-factor(y$Clone,levels=rev(as.character(y$Clone))) return(data.frame(y))}) if(class(test2)==&quot;list&quot;){y &lt;- lapply(test2,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;)} if(class(test2)==&quot;array&quot;){y &lt;- apply(test2,3,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;)} y[is.na(y)]&lt;-0 rownames(y)&lt;-y[,&quot;Clone&quot;] y&lt;-as.matrix(y[,-2]) mode(y)&lt;-&#39;numeric&#39; z&lt;-t(apply(y,1,function(p){quantile(p,probs=c(0.025,0.975))})) z_mat&lt;-data.frame(z,&quot;Clone&quot;=rownames(z)) set&lt;-setNames(data.frame(full_join(data.frame(clonal_abundance[[sample_to_test]]),z_mat,by=&quot;Clone&quot;)),c(&quot;Count&quot;,&quot;Clone&quot;,&quot;LCI&quot;,&quot;UCI&quot;))%&gt;%filter(LCI&gt;=clone_cutoff&amp;!is.na(Count)) return(set) } bootstrap_allele_dropout_NGT_mat &lt;- function(NGT_to_clone_list,clonal_abundance,sample_to_test,replicates,clone_cutoff){ mat_of_interest &lt;- NGT_to_clone[[sample_to_test]][,1:(ncol(NGT_to_clone[[sample_to_test]])-1)] bulk_VAF_order &lt;-names(sort(colSums(mat_of_interest),decreasing=TRUE)) test&lt;-replicate(n=replicates,apply(mat_of_interest,MARGIN=c(1,2),function(x){ if(x==1){z&lt;-x} if(x==0){z&lt;-sample(x=c(0,1),size=1,prob=c(0.9,0.1))} if(x==2){z&lt;-sample(x=c(2,1),size=1,prob=c(0.9,0.1))} return(as.numeric(z))}),simplify = &quot;array&quot;) test2&lt;-apply(test,3,function(q){ x&lt;-data.frame(q[,bulk_VAF_order], &quot;Clone&quot;=apply(q[,bulk_VAF_order],1, function(p){paste(p,sep=&quot;_&quot;,collapse=&quot;_&quot;)})) y&lt;-data.table(data.frame(&quot;Count&quot;=as.matrix(table(x[,&quot;Clone&quot;])), &quot;Clone&quot;=names(table(x[,&quot;Clone&quot;]))), key=&quot;Count&quot;) y$Clone&lt;-factor(y$Clone,levels=rev(as.character(y$Clone))) return(data.frame(y))}) if(class(test2)==&quot;list&quot;){y &lt;- lapply(test2,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;)} if(class(test2)==&quot;array&quot;){y &lt;- apply(test2,3,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;)} y[is.na(y)]&lt;-0 rownames(y)&lt;-y[,&quot;Clone&quot;] y&lt;-as.matrix(y[,-2]) mode(y)&lt;-&#39;numeric&#39; z&lt;-t(apply(y,1,function(p){quantile(p,probs=c(0.025,0.975))})) z_mat&lt;-data.frame(z,&quot;Clone&quot;=rownames(z)) set&lt;-setNames(data.frame(full_join(data.frame(clonal_abundance[[sample_to_test]]),z_mat,by=&quot;Clone&quot;)),c(&quot;Count&quot;,&quot;Clone&quot;,&quot;LCI&quot;,&quot;UCI&quot;))%&gt;%filter(LCI&gt;=clone_cutoff&amp;!is.na(Count)) return(set) } bootstrap_NGT_mat &lt;- function(NGT_to_clone_list,clonal_abundance,sample_to_test,replicates,clone_cutoff){ test&lt;-replicate(n=replicates,resample_fun(NGT_to_clone[[sample_to_test]]),simplify = &quot;array&quot;) if(class(test)==&quot;list&quot;){ y &lt;- lapply(test,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;) } if(class(test)==&quot;array&quot;){ y &lt;- apply(test,3,data.frame) %&gt;% reduce(full_join, by = &quot;Clone&quot;) } y[is.na(y)]&lt;-0 rownames(y)&lt;-y[,&quot;Clone&quot;] y&lt;-as.matrix(y[,-2]) mode(y)&lt;-&#39;numeric&#39; z&lt;-t(apply(y,1,function(p){ quantile(p,probs=c(0.025,0.975)) })) z_mat&lt;-data.frame(z,&quot;Clone&quot;=rownames(z)) set&lt;-setNames(data.frame(inner_join(data.frame(clonal_abundance[[sample_to_test]]),z_mat,by=&quot;Clone&quot;)),c(&quot;Count&quot;,&quot;Clone&quot;,&quot;LCI&quot;,&quot;UCI&quot;))%&gt;%filter(LCI&gt;=clone_cutoff) return(set) } resample_fun&lt;-function(data){ x &lt;- data[sample(x=1:nrow(data),replace=TRUE),] return(as.matrix(data.table(data.frame(&quot;Count&quot;= as.matrix(table(x[,&quot;Clone&quot;])), &quot;Clone&quot;=names(table(x[,&quot;Clone&quot;]))), key=&quot;Count&quot;))) } extract_NGT_files &lt;- function(sample,variants){ NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) return(NGT) } count_unknown_cells&lt;- function(sample,variants){ NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) cells_with_unknown&lt;-NGT[apply(NGT[,variants],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] return(c(length(cells_with_unknown)/nrow(NGT))) } extract_DP_files &lt;- function(sample,variants){ DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) cells_with_unknown&lt;-DP[apply(DP[,variants],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-DP[!DP$Cell%in%cells_with_unknown,variants] return(matrix_of_interest) } extract_SNP_info &lt;- function(sample){ AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) }) } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) }) } return(SNP_INFO) } # run the following just once to load the function plot_variants_and_selection &lt;- function(sample){ #Load in the data AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } protein_changes_of_interest &lt;- (SNP_INFO %&gt;% filter(protein!=&quot;&quot;)%&gt;%select(protein))[,1] # select column of variants SNP_changes_of_interest &lt;- rownames(SNP_INFO)[SNP_INFO[,&quot;protein&quot;]%in%protein_changes_of_interest] SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) # Cell and clone selection and Average depth per cell per allele distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) NGT_subset&lt;-NGT[,c(&quot;Sample&quot;,&quot;Cell&quot;,SNP_changes_of_interest)] #NGT_interest$Clone &lt;- apply(NGT_interest[,-c(1,2)],1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) #clonal_abundance &lt;- sort(table(NGT_interest$Clone)) DP_subset&lt;- DP[,c(&quot;Sample&quot;,&quot;Cell&quot;,SNP_changes_of_interest)] DP_NGT_melt&lt;-inner_join(melt(DP_subset[,-1],id.var=&quot;Cell&quot;),melt(NGT_subset[,-1],id.var=&quot;Cell&quot;),by=c(&quot;Cell&quot;,&quot;variable&quot;)) colnames(DP_NGT_melt) &lt;- c(&quot;Cell&quot;,&quot;Mutant&quot;,&quot;Depth&quot;,&quot;Genotype&quot;) DP_NGT_melt$Genotype &lt;- ifelse(DP_NGT_melt$Genotype==3,&quot;Unknown&quot;, ifelse(DP_NGT_melt$Genotype==0,&quot;WT&quot;, ifelse(DP_NGT_melt$Genotype==1,&quot;Heterozygous&quot;, ifelse(DP_NGT_melt$Genotype==2,&quot;Homozygous&quot;,DP_NGT_melt$Genotype)))) DP_NGT_melt$Genotype &lt;- factor(DP_NGT_melt$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;,&quot;Unknown&quot;)) summarized&lt;-data.frame(DP_NGT_melt%&gt;%group_by(Mutant,Genotype)%&gt;%summarise(&quot;Depth&quot;=mean(Depth))) summarized_no_unknown &lt;- summarized %&gt;% filter(Genotype!=&quot;Unknown&quot;) grouped &lt;- group_by(summarized_no_unknown, Mutant) output &lt;- data.frame(summarise(grouped, mean=mean(Depth), sd=sd(Depth))) output$Include &lt;- rep(&quot;Include&quot;,length(rownames(output))) output_final &lt;- inner_join(SNP_protein_key,output) depth_plot&lt;- ggplot(summarized_no_unknown,aes(x=Mutant,y=Depth,color=Genotype))+geom_point()+coord_flip()+ scale_x_discrete(limits = rev(levels(summarized_no_unknown$Mutant)))+theme_bw()#+ write.csv(output_final,paste0(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION.csv&quot;),row.names=FALSE) ggsave(paste0(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION.pdf&quot;),depth_plot,width=10,height=20) } run_mbio_analysis&lt;-function(sample,diversity){ #Load in the data if(any(grepl(&quot;VARIANT_SELECTION_LAM&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ LAM_VARIANTS_MAT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION_LAM.csv&quot;,sep=&quot;&quot;)) LAM_VARIANTS_SNP &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Mutant))[,1]) LAM_VARIANTS_Protein &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Protein))[,1]) } else { print(&quot;No variant selection performed!&quot;) return(&quot;next&quot;) } AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } SNP_changes_of_interest &lt;- LAM_VARIANTS_SNP protein_changes_of_interest &lt;- LAM_VARIANTS_Protein SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) # Cell and clone selection distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) #print(distribution_of_unknowns_by_variant) cells_with_unknown&lt;-NGT[apply(NGT[,SNP_changes_of_interest],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-NGT[!NGT$Cell%in%cells_with_unknown,SNP_changes_of_interest] bulk_VAF_order&lt;-SNP_INFO[colnames(matrix_of_interest)[order(colSums(matrix_of_interest),decreasing=TRUE)],&quot;protein&quot;] bulk_VAF_order &lt;- bulk_VAF_order[!duplicated(bulk_VAF_order)] matrix_of_interest$Clone &lt;- apply(matrix_of_interest,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) clonal_abundance &lt;- sort(table(matrix_of_interest$Clone)) clones_to_include&lt;-names(clonal_abundance)[clonal_abundance&gt;length(rownames(matrix_of_interest))*0] matrix_subset_clones &lt;- matrix_of_interest[matrix_of_interest$Clone%in%clones_to_include,] #Average depth per cell per allele DP_subset&lt;- DP[-cells_with_unknown,c(&quot;Sample&quot;,&quot;Cell&quot;,rownames(SNP_INFO)[SNP_INFO$protein%in%protein_changes_of_interest])] NGT_subset &lt;- NGT[NGT$Cell%in%DP_subset$Cell,colnames(DP_subset)] DP_NGT_melt&lt;-inner_join(melt(DP_subset[,-1],id.var=&quot;Cell&quot;),melt(NGT[,-1],id.var=&quot;Cell&quot;),by=c(&quot;Cell&quot;,&quot;variable&quot;)) colnames(DP_NGT_melt) &lt;- c(&quot;Cell&quot;,&quot;Mutant&quot;,&quot;Depth&quot;,&quot;Genotype&quot;) DP_NGT_melt$Genotype &lt;- ifelse(DP_NGT_melt$Genotype==3,&quot;Unknown&quot;, ifelse(DP_NGT_melt$Genotype==0,&quot;WT&quot;, ifelse(DP_NGT_melt$Genotype==1,&quot;Heterozygous&quot;, ifelse(DP_NGT_melt$Genotype==2,&quot;Homozygous&quot;,DP_NGT_melt$Genotype)))) DP_NGT_melt$Genotype &lt;- factor(DP_NGT_melt$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;,&quot;Unknown&quot;)) summarized&lt;-data.frame(DP_NGT_melt%&gt;%group_by(Mutant,Genotype)%&gt;%summarise(&quot;Depth&quot;=mean(Depth))) # Verify variants selected are unique and encode protein changes !any(duplicated(SNP_INFO[colnames(matrix_subset_clones),&quot;protein&quot;])) #Should return TRUE colnames(matrix_subset_clones)&lt;- c(as.character(SNP_INFO[colnames(matrix_subset_clones)[1:length(SNP_changes_of_interest)],&quot;protein&quot;]),&quot;Clone&quot;) # Aggregate data to get clone counts and architecture. dedup&lt;-matrix_subset_clones[!duplicated(matrix_subset_clones),] clonal_architecture &lt;- melt(dedup) colnames(clonal_architecture) &lt;- c(&quot;Clone&quot;,&quot;Mutant&quot;,&quot;Genotype&quot;) clonal_architecture$Genotype &lt;- ifelse(clonal_architecture$Genotype==3,NA, ifelse(clonal_architecture$Genotype==0,&quot;WT&quot;, ifelse(clonal_architecture$Genotype==1,&quot;Heterozygous&quot;, ifelse(clonal_architecture$Genotype==2,&quot;Homozygous&quot;,clonal_architecture$Genotype)))) clonal_architecture$Genotype &lt;- factor(clonal_architecture$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;)) clonal_abundance &lt;- data.frame(&quot;Count&quot;=as.matrix(table(matrix_subset_clones$Clone))) clonal_abundance$Clone &lt;- rownames(clonal_abundance) clonal_abundance &lt;- data.table(clonal_abundance,key=&quot;Count&quot;) clonal_abundance$Clone &lt;- factor(clonal_abundance$Clone,levels=rev(c(clonal_abundance$Clone))) clonal_architecture$Clone &lt;- factor(as.character(clonal_architecture$Clone),levels=rev(as.character(clonal_abundance$Clone))) clonal_architecture$Mutant &lt;-factor(clonal_architecture$Mutant , levels=rev(as.character(bulk_VAF_order))) # Generate clonal architecture heatmap gg_heatmap &lt;- ggplot(data = clonal_architecture, aes(x = Clone, y = factor(Mutant), fill = Genotype)) + geom_tile() + scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme_classic() + ylab(&quot;Mutation&quot;)+ theme(legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,1,1,1),&quot;cm&quot;)) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data = data.frame(clonal_abundance), aes(x = factor(Clone), y = Count)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Count)) + theme_gray() + theme_classic()+ ylim(0,max(clonal_abundance$Count)*1.3) + ylab(&quot;Cell Count&quot;)+ geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25)+ scale_fill_distiller(name = &quot;Value&quot;, palette = &quot;Reds&quot;, direction = 1) + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line=element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(1,1,-0.2,1),&quot;cm&quot;)) # Generate genotype calls by allele distribution_of_unknowns_by_variant &lt;- t(apply(NGT[,SNP_changes_of_interest],MARGIN=2,function(x){table(factor(x,levels=c(0,1,2,3)))})) rownames(distribution_of_unknowns_by_variant) &lt;- SNP_INFO[rownames(distribution_of_unknowns_by_variant),&quot;protein&quot;] colnames(distribution_of_unknowns_by_variant) &lt;- c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;,&quot;Unknown&quot;) allele_melted &lt;-melt(distribution_of_unknowns_by_variant) colnames(allele_melted) &lt;- c(&quot;Mutant&quot;,&quot;Genotype&quot;,&quot;Cells&quot;) allele_melted$Genotype &lt;- factor(allele_melted$Genotype,levels=rev(c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;,&quot;Unknown&quot;))) allele_melted$Mutant &lt;-factor(allele_melted$Mutant , levels=as.character(bulk_VAF_order)) #Generate allele barplot gg_alleles &lt;- ggplot(data = data.frame(allele_melted), aes(x = factor(Mutant), y = Cells)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Genotype),position=&quot;stack&quot;) + theme_gray() + theme_minimal()+ ylab(&quot;Cell Count&quot;)+ scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme(axis.text.x=element_text(angle=30,hjust=1,vjust=1)) #Generate depth by alelle by mutant gg_depth &lt;- ggplot(summarized,aes(x=Mutant,color=Genotype,y=Depth))+ geom_point(position=position_dodge(width=0.4))+ scale_color_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme(axis.text.x=element_text(angle=30,hjust=1,vjust=1), plot.margin=unit(c(1,1,1,2),&quot;cm&quot;)) # Compute spacing of graphs plots &lt;- list(gg_depth,gg_clonal_barplot,gg_alleles,gg_heatmap) grobs &lt;- list() widths &lt;- list() for (i in 1:length(plots)){ grobs[[i]] &lt;- ggplotGrob(plots[[i]]) widths[[i]] &lt;- grobs[[i]]$widths[2:5] } maxwidth &lt;- do.call(grid::unit.pmax, widths) for (i in 1:length(grobs)){ grobs[[i]]$widths[2:5] &lt;- as.list(maxwidth) } # Generate plot grob.title &lt;- textGrob(sample, hjust = 0.5, vjust = 0.5, gp = gpar(fontsize = 20)) pdf(paste(output_folder,&quot;Graphs/&quot;,sample,&quot;.pdf&quot;,sep=&quot;&quot;), width = 16, height = 8) # Open a new pdf file grid.arrange(grobs=grobs, ncol = 2, top = grob.title) graphics.off() if(diversity==TRUE){ clonal_abundance_mat &lt;- clonal_abundance clonal_abundance$Clone &lt;- rownames(clonal_abundance) clonal_abundance_mat$Clone &lt;- rownames(clonal_abundance_mat) clonal_abundance_count &lt;- data.table(clonal_abundance,key=&quot;Count&quot;) shannon &lt;- diversity(clonal_abundance_mat[,&quot;Count&quot;]) write.csv2(shannon,paste(output_folder,&quot;Diversity_score/&quot;,sample,&quot;.csv&quot;,sep=&quot;&quot;)) } } stats_output&lt;-function(sample){ #Load in the data if(any(grepl(&quot;VARIANT_SELECTION_LAM&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ LAM_VARIANTS_MAT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION_LAM.csv&quot;,sep=&quot;&quot;)) LAM_VARIANTS_SNP &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Mutant))[,1]) LAM_VARIANTS_Protein &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Protein))[,1]) } else { print(&quot;No variant selection performed!&quot;) return(&quot;next&quot;) } AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } SNP_changes_of_interest &lt;- LAM_VARIANTS_SNP protein_changes_of_interest &lt;- LAM_VARIANTS_Protein SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) # Cell and clone selection distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) #print(distribution_of_unknowns_by_variant) cells_with_unknown&lt;-NGT[apply(NGT[,SNP_changes_of_interest],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-NGT[!NGT$Cell%in%cells_with_unknown,SNP_changes_of_interest] bulk_VAF_order&lt;-SNP_INFO[colnames(matrix_of_interest)[order(colSums(matrix_of_interest),decreasing=TRUE)],&quot;protein&quot;] bulk_VAF_order &lt;- bulk_VAF_order[!duplicated(bulk_VAF_order)] matrix_of_interest$Clone &lt;- apply(matrix_of_interest,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) # Aggregate data to get clone counts and architecture. dedup&lt;-matrix_of_interest[!duplicated(matrix_of_interest),] clonal_abundance &lt;- data.frame(&quot;Count&quot;=as.matrix(table(matrix_of_interest$Clone))) clonal_abundance$Clone &lt;- factor(rownames(clonal_abundance),levels=rev(c(rownames(clonal_abundance)))) clonal_abundance$Count &lt;- as.numeric(clonal_abundance$Count) clonal_abundance$Dominance &lt;- apply(clonal_abundance,1,function(x){ (as.numeric(x[&quot;Count&quot;])/sum(clonal_abundance[&quot;Count&quot;]) ) / (max(as.numeric(clonal_abundance[,&quot;Count&quot;]))/sum(clonal_abundance[&quot;Count&quot;])) }) clonal_abundance$Mutation_count &lt;- apply(clonal_abundance,1,function(x){ sum(as.numeric(strsplit( as.character(x[2]),split=&quot;_&quot;)[[1]])) }) shannon &lt;- diversity(clonal_abundance[,&quot;Count&quot;]) print(shannon) matrix_output &lt;- dedup%&gt;%select(-Clone) matrix_output_t &lt;- t(matrix_output) rownames(matrix_output_t) &lt;- 0:(dim(matrix_output_t)[[1]]-1) write.table(shannon,paste0(output_folder,&quot;Diversity_score/&quot;,sample,&quot;.txt&quot;),sep=&quot;\\t&quot;,row.names=FALSE) write.table(matrix_output_t,paste0(output_folder,&quot;Genotype_matrix/&quot;,sample,&quot;.txt&quot;),sep=&quot; &quot;,row.names=TRUE,quote=FALSE,col.names = FALSE) write.table(clonal_abundance,paste0(output_folder,&quot;Summary_mat/&quot;,sample,&quot;.txt&quot;),sep=&quot;\\t&quot;,row.names=FALSE) } permute_data &lt;- function(sample,nrun){ #Load in the data if(any(grepl(&quot;VARIANT_SELECTION_LAM&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ LAM_VARIANTS_MAT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION_LAM.csv&quot;,sep=&quot;&quot;)) LAM_VARIANTS_SNP &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Mutant))[,1]) LAM_VARIANTS_Protein &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Protein))[,1]) } else { print(&quot;No variant selection performed!&quot;) return(&quot;next&quot;) } AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } SNP_changes_of_interest &lt;- LAM_VARIANTS_SNP protein_changes_of_interest &lt;- LAM_VARIANTS_Protein SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) # Cell and clone selection distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) #print(distribution_of_unknowns_by_variant) cells_with_unknown&lt;-NGT[apply(NGT[,SNP_changes_of_interest],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-NGT[!NGT$Cell%in%cells_with_unknown,SNP_changes_of_interest] bulk_VAF_order&lt;-SNP_INFO[colnames(matrix_of_interest)[order(colSums(matrix_of_interest),decreasing=TRUE)],&quot;protein&quot;] bulk_VAF_order &lt;- bulk_VAF_order[!duplicated(bulk_VAF_order)] matrix_of_interest$Clone &lt;- apply(matrix_of_interest,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) # Aggregate data to get clone counts and architecture. dedup&lt;-matrix_of_interest[!duplicated(matrix_of_interest),] clonal_abundance &lt;- data.frame(&quot;Count&quot;=as.matrix(table(matrix_of_interest$Clone))) clonal_abundance$Clone &lt;- factor(rownames(clonal_abundance),levels=rev(c(rownames(clonal_abundance)))) clonal_abundance$Count &lt;- as.numeric(clonal_abundance$Count) clonal_architecture &lt;- melt(dedup) colnames(clonal_architecture) &lt;- c(&quot;Clone&quot;,&quot;Mutant&quot;,&quot;Genotype&quot;) clonal_architecture$Genotype &lt;- ifelse(clonal_architecture$Genotype==3,NA, ifelse(clonal_architecture$Genotype==0,&quot;WT&quot;, ifelse(clonal_architecture$Genotype==1,&quot;Heterozygous&quot;, ifelse(clonal_architecture$Genotype==2,&quot;Homozygous&quot;,clonal_architecture$Genotype)))) clonal_architecture$Genotype &lt;- factor(clonal_architecture$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;)) results_holder &lt;- unlist(list(1:nrun)) randomization_list&lt;-lapply(results_holder,function(x){ apply(matrix_of_interest[,1:length(colnames(matrix_of_interest))-1],2,function(x){ y &lt;- sample(x,length(x),replace=FALSE) })}) #randomization_list&lt;-plyr::alply(randomization_array,3) # names(randomization_list) &lt;- NULL empirical_distribution&lt;-suppressMessages(lapply(randomization_list, function(randomization){ randomization$Clone &lt;- apply(randomization,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) loop_dedup&lt;-matrix_of_interest[!duplicated(randomization),] loop_clonal_architecture &lt;- melt(loop_dedup) colnames(loop_clonal_architecture) &lt;- c(&quot;Clone&quot;,&quot;Mutant&quot;,&quot;Genotype&quot;) loop_clonal_architecture$Genotype &lt;- ifelse(loop_clonal_architecture$Genotype==3,NA, ifelse(loop_clonal_architecture$Genotype==0,&quot;WT&quot;, ifelse(loop_clonal_architecture$Genotype==1,&quot;Heterozygous&quot;, ifelse(loop_clonal_architecture$Genotype==2,&quot;Homozygous&quot;,clonal_architecture$Genotype)))) loop_clonal_architecture$Genotype &lt;- factor(loop_clonal_architecture$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;)) loop_clonal_abundance &lt;- data.frame(&quot;Count&quot;=as.matrix(table(randomization$Clone))) loop_clonal_abundance$Clone &lt;- rownames(loop_clonal_abundance) return(data.frame(loop_clonal_abundance)) })) empirical_distribution_mat&lt;-empirical_distribution%&gt;%purrr::reduce(dplyr::full_join,by=&quot;Clone&quot;) colnames(empirical_distribution_mat)&lt;-1:length(colnames(empirical_distribution_mat)) rownames(empirical_distribution_mat) &lt;- empirical_distribution_mat[,2] empirical_distribution_mat &lt;- empirical_distribution_mat[,-2] empirical_distribution_mat[is.na(empirical_distribution_mat)]&lt;-0 clonal_abundance$Clone &lt;- as.character(clonal_abundance$Clone) clonal_abundance$Count &lt;- as.numeric(clonal_abundance$Count) clonal_abundance$pvalue &lt;-apply(clonal_abundance,1,function(x){ 1- sum(as.numeric(x[[&quot;Count&quot;]])&gt;empirical_distribution_mat[x[[&quot;Clone&quot;]],])/nrun }) #print(dedup) colnames(clonal_abundance)[2] &lt;- paste(colnames(dedup)[1:length(SNP_changes_of_interest)],sep=&quot;_&quot;,collapse=&quot;__&quot;) clonal_abundance &lt;- clonal_abundance[order(clonal_abundance[,&quot;Count&quot;],decreasing = TRUE),] clonal_abundance$Dominance &lt;- apply(clonal_abundance,1,function(x){ (as.numeric(x[&quot;Count&quot;])/sum(clonal_abundance[&quot;Count&quot;]) ) / (max(as.numeric(clonal_abundance[,&quot;Count&quot;]))/sum(clonal_abundance[&quot;Count&quot;])) }) clonal_abundance$Poisson &lt;- apply(clonal_abundance,1,function(x){ poisson.test(as.numeric(x[&quot;Count&quot;]),mean(as.numeric(clonal_abundance$Count)),alternative=&quot;greater&quot;)$p.value }) clonal_abundance$Mutation_count &lt;- apply(clonal_abundance,1,function(x){ sum(as.numeric(strsplit( as.character(x[2]),split=&quot;_&quot;)[[1]])) }) write.table(clonal_abundance,paste0(output_folder,&quot;Summary_mat/&quot;,sample,&quot;.txt&quot;),sep=&quot;\\t&quot;,row.names=FALSE) } replot_clonal_selection &lt;- function(sample){ if(any(grepl(&quot;VARIANT_SELECTION_LAM&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ LAM_VARIANTS_MAT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION_LAM.csv&quot;,sep=&quot;&quot;)) LAM_VARIANTS_SNP &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Mutant))[,1]) LAM_VARIANTS_Protein &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Protein))[,1]) } else { print(&quot;No variant selection performed!&quot;) return(&quot;next&quot;) } DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(NGT)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(NGT)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } SNP_changes_of_interest &lt;- LAM_VARIANTS_SNP protein_changes_of_interest &lt;- LAM_VARIANTS_Protein SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) rownames(SNP_protein_key) &lt;- SNP_protein_key$Mutant # Cell and clone selection distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) #print(distribution_of_unknowns_by_variant) cells_with_unknown&lt;-NGT[apply(NGT[,SNP_changes_of_interest],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-NGT[!NGT$Cell%in%cells_with_unknown,SNP_changes_of_interest] bulk_VAF_order&lt;-SNP_INFO[colnames(matrix_of_interest)[order(colSums(matrix_of_interest),decreasing=TRUE)],&quot;protein&quot;] bulk_VAF_order &lt;- bulk_VAF_order[!duplicated(bulk_VAF_order)] matrix_of_interest$Clone &lt;- apply(matrix_of_interest,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) dedup&lt;-matrix_of_interest[!duplicated(matrix_of_interest),] colnames(dedup) &lt;- SNP_protein_key[colnames(dedup),&quot;Protein&quot;] clonal_architecture &lt;- melt(dedup) colnames(clonal_architecture) &lt;- c(&quot;Clone&quot;,&quot;Mutant&quot;,&quot;Genotype&quot;) clonal_architecture$Genotype &lt;- ifelse(clonal_architecture$Genotype==3,NA, ifelse(clonal_architecture$Genotype==0,&quot;WT&quot;, ifelse(clonal_architecture$Genotype==1,&quot;Heterozygous&quot;, ifelse(clonal_architecture$Genotype==2,&quot;Homozygous&quot;,clonal_architecture$Genotype)))) clonal_architecture$Genotype &lt;- factor(clonal_architecture$Genotype ,levels=c(&quot;WT&quot;,&quot;Heterozygous&quot;,&quot;Homozygous&quot;)) clonal_abundance &lt;- data.frame(&quot;Count&quot;=as.matrix(table(matrix_of_interest$Clone))) clonal_abundance$Clone &lt;- rownames(clonal_abundance) clonal_abundance &lt;- data.table(clonal_abundance,key=&quot;Count&quot;) clonal_abundance$Clone &lt;- factor(clonal_abundance$Clone,levels=rev(c(clonal_abundance$Clone))) clonal_architecture$Clone &lt;- factor(as.character(clonal_architecture$Clone),levels=rev(as.character(clonal_abundance$Clone))) clonal_architecture$Mutant &lt;-factor(clonal_architecture$Mutant , levels=rev(as.character(bulk_VAF_order))) clones_import &lt;- read.delim(paste0(&quot;/Volumes/LevineLab/Levine Lab/Bobby/Collaborations/MissionBio/08_08_19/Summary_mat/&quot;,sample,&quot;.txt&quot;),sep=&quot;\\t&quot;) colnames(clones_import)[2] &lt;- &quot;Clone&quot; select_clones_full &lt;- clones_import %&gt;% filter(pvalue&lt;0.1|Poisson&lt;0.05)%&gt;%select(Clone) select_clones_dominant &lt;- clones_import %&gt;% filter(pvalue&lt;0.1|Poisson&lt;0.05)%&gt;%filter(Dominance&gt;0.05)%&gt;%select(Clone) if(length(select_clones_dominant[,1])&gt;3){ clonal_architecture_subset &lt;- clonal_architecture%&gt;%filter(Clone%in%select_clones_dominant[,1]) clonal_abundance_subset &lt;- clonal_abundance%&gt;%filter(Clone%in%select_clones_dominant[,1]) name_var &lt;- &quot;VAF Subset&quot; } else if(length(select_clones_full[,1])&gt;20){ print(&quot;Complex clonal picture, skipping&quot;) return(next) } else if(length(select_clones_full[,1])&lt;2){ print(&quot;Simple clonal picture, plotting all clones&quot;) clonal_architecture_subset &lt;- clonal_architecture clonal_abundance_subset &lt;- clonal_abundance name_var &lt;- &quot;All Clones&quot; } else { clonal_architecture_subset &lt;- clonal_architecture%&gt;%filter(Clone%in%select_clones_full[,1]) clonal_abundance_subset &lt;- clonal_abundance%&gt;%filter(Clone%in%select_clones_full[,1]) name_var &lt;- &quot;Full&quot; } # Generate clonal architecture heatmap gg_heatmap &lt;- ggplot(data = clonal_architecture_subset, aes(x = Clone, y = factor(Mutant), fill = Genotype)) + geom_tile() + scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme_classic() + ylab(&quot;Mutation&quot;)+ theme(legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,1,1,1),&quot;cm&quot;)) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data = data.frame(clonal_abundance_subset), aes(x = factor(Clone), y = Count)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Count)) + theme_gray() + theme_classic()+ ylim(0,max(clonal_abundance$Count)*1.3) + ylab(&quot;Cell Count&quot;)+ geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25)+ scale_fill_distiller(name = &quot;Value&quot;, palette = &quot;Reds&quot;, direction = 1) + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line=element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(1,1,-0.2,1),&quot;cm&quot;)) # Compute spacing of graphs plots &lt;- list(gg_clonal_barplot,gg_heatmap) grobs &lt;- list() widths &lt;- list() for (i in 1:length(plots)){ grobs[[i]] &lt;- ggplotGrob(plots[[i]]) widths[[i]] &lt;- grobs[[i]]$widths[2:5] } maxwidth &lt;- do.call(grid::unit.pmax, widths) for (i in 1:length(grobs)){ grobs[[i]]$widths[2:5] &lt;- as.list(maxwidth) } # Generate plot grob.title &lt;- textGrob(paste(sample,&quot;-&quot;,name_var), hjust = 0.5, vjust = 0.5, gp = gpar(fontsize = 20)) pdf(paste(output_folder,&quot;Graphs_significant/&quot;,sample,&quot;.pdf&quot;,sep=&quot;&quot;), width = 16, height = 8) # Open a new pdf file grid.arrange(grobs=grobs, ncol = 1, top = grob.title) graphics.off() } plot_clonal_heatmap_and_barplot &lt;-function(sample,output_folder,clonal_abundance,clonal_architecture,clone_cell_count,shrink) { #clonal_abundance_subset &lt;-data.frame( clonal_abundance[[sample]])%&gt;%filter(Count&gt;=5) #clonal_architecture_subset &lt;- data.frame(clonal_architecture[[sample]])%&gt;% # filter(Clone%in%as.character(clonal_abundance_subset$Clone)) clonal_abundance_subset&lt;-final_sample_summary[[sample]]$Clones#clonal_abundance clonal_abundance_subset$Clone&lt;-factor(final_sample_summary[[sample]]$Clones[,&quot;Clone&quot;],levels=rev(c(final_sample_summary[[sample]]$Clones[,&quot;Clone&quot;])))#clonal_abundance clonal_architecture_subset&lt;-final_sample_summary[[sample]]$Architecture%&gt;% filter(Clone%in%as.character(clonal_abundance_subset$Clone)) clonal_architecture_subset$Clone &lt;- factor(clonal_architecture_subset$Clone, levels=levels(clonal_abundance_subset$Clone)) gg_heatmap &lt;- ggplot(data = clonal_architecture_subset, aes(x = Clone, y = factor(Mutant,levels=rev(levels(factor(Mutant)))), fill = Genotype)) + geom_tile() +# scale_y_discrete(limits = rev(levels(Mutant)))+ scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme_classic(base_size=6) + ylab(&quot;Mutation&quot;)+ theme(legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,1,1,1),&quot;cm&quot;)) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data = data.frame(clonal_abundance_subset), aes(x = Clone, y = Count)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Count)) + theme_gray() + theme_classic(base_size=6)+ ylim(0,max(clonal_abundance_subset$Count)*1.3) + ylab(&quot;Cell Count&quot;)+ geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25,size=1)+ scale_fill_distiller(name = &quot;Value&quot;, palette = &quot;Reds&quot;, direction = 1) + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line=element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(1,1,-0.2,1),&quot;cm&quot;)) grob.title &lt;- textGrob(paste(sample,&quot;-&quot;), hjust= 0.5, vjust = 0.5, gp = gpar(fontsize = 12)) final_plot&lt;-plot_grid(grob.title,gg_clonal_barplot,gg_heatmap,ncol=1,align=&quot;hv&quot;,axis=&quot;l&quot;,rel_heights = c(0.1,1,0.75)) save_plot(paste(output_folder,sample,&quot;.pdf&quot;,sep=&quot;&quot;),final_plot, ncol=1) # Open a new pdf file } generate_and_plot_cooccurence &lt;- function(mut_mat){ cooccur_mat &lt;- cooccur(mat=t(mut_mat),type=&quot;spp_site&quot;,only_effects = FALSE,eff_matrix=TRUE,thresh=FALSE,eff_standard=FALSE,spp_names=TRUE)$results cooccur_mat$score&lt;- ifelse(cooccur_mat[,&quot;p_lt&quot;]&lt;=0.05,-1,ifelse(cooccur_mat[,&quot;p_gt&quot;]&lt;=0.05,1,0)) cooccur_mat_subset &lt;- rbind(cooccur_mat[,c(&quot;sp1_name&quot;,&quot;sp2_name&quot;,&quot;score&quot;)],c(setdiff(cooccur_mat$sp2_name,cooccur_mat$sp1_name),setdiff(cooccur_mat$sp1_name,cooccur_mat$sp2_name),0)) cooccur_data_mat &lt;- dcast(cooccur_mat_subset, sp1_name ~ sp2_name, value.var=&quot;score&quot;) rownames(cooccur_data_mat) &lt;- cooccur_data_mat[,1] cooccur_data_mat2&lt;-cooccur_data_mat[,-1] cooccur_data_mat2[is.na(cooccur_data_mat2)]&lt;-0 cooccur_data_mat2[lower.tri(cooccur_data_mat2)]&lt;-NA cooccur_data_mat2$Gene &lt;- rownames(cooccur_data_mat2) cooccur_data_mat_melt &lt;- na.omit(melt(cooccur_data_mat2, &#39;Gene&#39;, variable_name=&#39;Gene2&#39;)) cooccur_data_mat_melt$variable &lt;- factor(cooccur_data_mat_melt$variable, levels=rev(levels(cooccur_data_mat_melt$variable))) # Triangle heatmap to compare cohorts grob_corrplot&lt;-ggplot(cooccur_data_mat_melt, aes(Gene, variable))+ geom_tile(aes(fill = factor(value)), color=&#39;grey90&#39;) + scale_fill_manual(values=c(&quot;-1&quot;=&quot;firebrick3&quot;,&quot;0&quot;=&quot;white&quot;,&quot;1&quot;=&quot;steelblue2&quot;),&quot;Correlation&quot;, labels=c(&quot;Mutually Exclusive&quot;,&quot;Not Significant&quot;,&quot;Mutually Inclusive&quot;))+ theme_classic(base_size=10)+xlab(&quot;&quot;)+ylab(&quot;&quot;)+ theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1), axis.line = element_blank(), legend.position = c(0.8,1), legend.justification = c(1, 1), legend.direction = &quot;vertical&quot;)+ theme(legend.key.size = unit(0.5,&quot;line&quot;)) return(list(&quot;plot&quot;=grob_corrplot, &quot;data&quot;=cooccur_mat)) } diversity_from_bulk_VAF &lt;- function(sample){ if(any(grepl(&quot;VARIANT_SELECTION_LAM&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ LAM_VARIANTS_MAT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_VARIANT_SELECTION_LAM.csv&quot;,sep=&quot;&quot;)) LAM_VARIANTS_SNP &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Mutant))[,1]) LAM_VARIANTS_Protein &lt;- as.character((LAM_VARIANTS_MAT %&gt;% filter(Include==&quot;Include&quot;)%&gt;%select(Protein))[,1]) } else { print(&quot;No variant selection performed!&quot;) return(&quot;next&quot;) } #AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency #DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth #GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) if(any(grepl(&quot;SNP_INFO.csv&quot;,list.files(paste(&quot;./&quot;,sample,&quot;/&quot;,sep=&quot;&quot;))))){ SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(NGT)[-c(1:2)] # - renames SNP info to have the variants as rownames SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cdna&quot;]!=&quot;&quot;,paste(x[&quot;gene&quot;],x[&quot;cdna&quot;],sep=&quot;_&quot;), ifelse(x[&quot;amplicon&quot;]%in%c(&quot;MSK_RL_AMP54&quot;, &quot;MSK_RL_AMP55&quot;, &quot;MSK_RL_AMP56&quot;,&quot;MSK_RL_AMP57&quot;,&quot;MSK_RL_AMP58&quot;),paste(&quot;FLT3_INS&quot;,x[&quot;POS&quot;],x[&quot;ALT&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } else { SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;Variants.csv&quot;,sep=&quot;&quot;)) rownames(SNP_INFO) &lt;-colnames(NGT)[-c(1:2)] # - renames SNP info to have the variants as rownames colnames(SNP_INFO)[3] &lt;- &quot;protein&quot; SNP_INFO$cDNA &lt;- as.character(SNP_INFO$cDNA) SNP_INFO$protein &lt;- as.character(SNP_INFO$protein) SNP_INFO$Variant &lt;- as.character(SNP_INFO$Variant) SNP_INFO$Gene &lt;- as.character(SNP_INFO$Gene) SNP_INFO[,c(&quot;protein&quot;)] &lt;- apply(SNP_INFO,1,function(x){ ifelse(x[&quot;protein&quot;]!=&quot;&quot;,x[&quot;protein&quot;], ifelse(x[&quot;cDNA&quot;]!=&quot;&quot;,paste(x[&quot;Gene&quot;],x[&quot;cDNA&quot;],sep=&quot;_&quot;), ifelse(grepl(&quot;^chr13&quot;,x[&quot;Variant&quot;]),paste(&quot;FLT3_INS&quot;,x[&quot;Variant&quot;],sep=&quot;_&quot;),&quot;&quot;))) })# - variant metadata } SNP_changes_of_interest &lt;- LAM_VARIANTS_SNP protein_changes_of_interest &lt;- LAM_VARIANTS_Protein SNP_protein_key &lt;- data.frame(&quot;Mutant&quot;=SNP_changes_of_interest,&quot;Protein&quot;=protein_changes_of_interest) # Cell and clone selection distribution_of_unknowns_by_variant &lt;- apply(NGT[,SNP_changes_of_interest],MARGIN=2,table) #print(distribution_of_unknowns_by_variant) cells_with_unknown&lt;-NGT[apply(NGT[,SNP_changes_of_interest],MARGIN=1,FUN=function(x){sum(x==3)&gt;0}),&quot;Cell&quot;] matrix_of_interest&lt;-NGT[!NGT$Cell%in%cells_with_unknown,SNP_changes_of_interest] bulk_VAF_order&lt;-SNP_INFO[colnames(matrix_of_interest)[order(colSums(matrix_of_interest),decreasing=TRUE)],&quot;protein&quot;] bulk_VAF_order &lt;- bulk_VAF_order[!duplicated(bulk_VAF_order)] matrix_of_interest$Clone &lt;- apply(matrix_of_interest,1,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) output&lt;-diversity(colSums(matrix_of_interest[colnames(matrix_of_interest)!=&quot;Clone&quot;])/length(rownames(matrix_of_interest))) write.table(output,paste0(output_folder,&quot;Diversity_score_faux_VAF/&quot;,sample,&quot;.txt&quot;),sep=&quot;\\t&quot;) } ## Old Functions plot_variants_AF_and_DP &lt;- function(sample){ #Load in the data AF &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;AF.csv&quot;,sep=&quot;&quot;)) # - variant allele frequency DP &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;DP.csv&quot;,sep=&quot;&quot;)) # - read depth GQ &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;GQ.csv&quot;,sep=&quot;&quot;)) # - quality scores NGT &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;NGT.csv&quot;,sep=&quot;&quot;)) # - genotype call converted to categorical (0-reference, 1-heterozygous mutation, 2-homozygous mutation, 3-unknown) SNP_INFO &lt;- read.csv(paste(&quot;./&quot;,sample,&quot;/&quot;,&quot;SNP_INFO.csv&quot;,sep=&quot;&quot;)) # - variant metadata rownames(SNP_INFO) &lt;-colnames(AF)[-c(1:2)] # - renames SNP info to have the variants as rownames AF_NGT_Melt&lt;-inner_join(AF %&gt;% unite(&quot;Sample_cell&quot;,c(&quot;Sample&quot;,&quot;Cell&quot;)) %&gt;%melt(&quot;Sample_cell&quot;), NGT %&gt;% unite(&quot;Sample_cell&quot;,c(&quot;Sample&quot;,&quot;Cell&quot;)) %&gt;%melt(&quot;Sample_cell&quot;), by=c(&quot;Sample_cell&quot;,&quot;variable&quot;)) colnames(AF_NGT_Melt) &lt;- c(&quot;Cell&quot;,&quot;Variant&quot;,&quot;AF&quot;,&quot;NGT&quot;) gg_AF_NGT&lt;- ggplot(AF_NGT_Melt,aes(x=as.factor(NGT),y=AF,color=NGT))+ geom_quasirandom()+facet_wrap(~Variant,ncol=3) DP_NGT_Melt&lt;-inner_join(DP %&gt;% unite(&quot;Sample_cell&quot;,c(&quot;Sample&quot;,&quot;Cell&quot;)) %&gt;%melt(&quot;Sample_cell&quot;), NGT %&gt;% unite(&quot;Sample_cell&quot;,c(&quot;Sample&quot;,&quot;Cell&quot;)) %&gt;%melt(&quot;Sample_cell&quot;), by=c(&quot;Sample_cell&quot;,&quot;variable&quot;)) colnames(DP_NGT_Melt) &lt;- c(&quot;Cell&quot;,&quot;Variant&quot;,&quot;DP&quot;,&quot;NGT&quot;) gg_DP_NGT&lt;- ggplot(DP_NGT_Melt,aes(x=as.factor(NGT),y=DP,fill=NGT))+geom_boxplot()+facet_wrap(~Variant,ncol=3,scale=&quot;free_y&quot;) ggsave(paste0(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_DP_NGT.pdf&quot;),gg_DP_NGT,width=10,height=40) ggsave(paste0(&quot;./&quot;,sample,&quot;/&quot;,sample,&quot;_AF_NGT.pdf&quot;),gg_AF_NGT,width=10,height=40) } plot_COMPASS_data &lt;-function(sample,output_folder,melted_protein_mat,clonal_abundance,clonal_architecture,clone_cell_count,shrink) { melted_protein_mat &lt;-melted_protein_mat[[sample]] clonal_abundance_subset &lt;-data.frame( clonal_abundance[[sample]])#%&gt;%filter(Count&gt;=5) clonal_architecture_subset &lt;- data.frame(clonal_architecture[[sample]])#%&gt;% # filter(Clone%in%as.character(clonal_abundance_subset$Clone)) genes_to_display &lt;-unique(as.character(clonal_architecture_subset[clonal_architecture_subset$Genotype%in%c(&quot;Heterozygous&quot;,&quot;Homozygous&quot;),&quot;Mutant&quot;])) if(shrink==TRUE){ clonal_architecture_subset &lt;-clonal_architecture_subset%&gt;%filter(Mutant%in%genes_to_display) } clonal_architecture_subset$Clone &lt;- factor(clonal_architecture_subset$Clone, levels=levels(clonal_abundance_subset$Clone)) melted_protein_mat_subset&lt;-melted_protein_mat%&gt;%filter(Clone%in%as.character(clonal_architecture_subset$Clone)) melted_protein_mat_subset$Clone &lt;-factor(melted_protein_mat_subset$Clone, levels=levels(clonal_abundance_subset$Clone)) gg_protein_heatmap&lt;-ggplot(melted_protein_mat_subset, aes(y=variable, x=(Clone))) + geom_tile(aes(fill = value),colour = &quot;white&quot;) + scale_fill_distiller(palette = &quot;PRGn&quot;)+ theme_minimal(base_size=6) + theme( axis.text.x = element_blank(), axis.title.x = element_blank(), legend.position = &quot;right&quot;,legend.direction = &quot;vertical&quot;, axis.ticks.x = element_blank(), plot.margin=unit(c(0,0,0,0),&quot;cm&quot;)) gg_heatmap &lt;- ggplot(data = clonal_architecture_subset, aes(x = Clone, y = factor(Mutant,levels=rev(levels(factor(Mutant)))), fill = Genotype)) + geom_tile() +# scale_y_discrete(limits = rev(levels(Mutant)))+ scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme_classic(base_size=6) + ylab(&quot;Mutation&quot;)+ theme(legend.position = &quot;right&quot;, legend.direction = &quot;vertical&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,0,0,0),&quot;cm&quot;)) clone_colors &lt;- alphabet()[1:length(unique(clonal_abundance_subset$Clone))] names(clone_colors) &lt;-levels(clonal_abundance_subset$Clone) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data = data.frame(clonal_abundance_subset), aes(x = Clone, y = Count)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Clone)) + theme_gray() + theme_classic(base_size=6)+ ylim(0,max(clonal_abundance_subset$Count)*1.3) + ylab(&quot;Cell Count&quot;)+ geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25,size=1)+ scale_fill_manual(values=clone_colors)+ theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line=element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(0,0,0,0),&quot;cm&quot;)) grob.title &lt;- textGrob(paste(sample,&quot;-&quot;), hjust= 0.5, vjust = 0.5, gp = gpar(fontsize = 12)) final_plot&lt;-plot_grid(gg_clonal_barplot,addSmallLegend(gg_heatmap),addSmallLegend(gg_protein_heatmap),ncol=1,align=&quot;hv&quot;,axis=&quot;lrtb&quot;,rel_heights = c(1,(length(genes_to_display)*0.15),1)) save_plot(paste(output_folder,sample,&quot;.pdf&quot;,sep=&quot;&quot;),final_plot, ncol=1) # Open a new pdf file } addSmallLegend &lt;- function(myPlot, pointSize = 3, textSize = 8, spaceLegend = 0.5) { myPlot + guides(shape = guide_legend(override.aes = list(size = pointSize)), color = guide_legend(override.aes = list(size = pointSize))) + theme(legend.title = element_text(size = textSize), legend.text = element_text(size = textSize), legend.key.size = unit(spaceLegend, &quot;lines&quot;)) } create_reward_matrix_deprecated&lt;-function(Known_mat,weights){ set.seed(68864) names(weights) &lt;- apply(Known_mat,2,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) num_type &lt;- 2 num_mutations &lt;- nrow(Known_mat); num_clones &lt;- ncol(Known_mat) num_states &lt;- num_type^num_mutations states&lt;-data.frame(expand.grid(rep(list(0:num_type), num_mutations))) state_interactions&lt;-expand.grid(apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}), apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)})) states$Reward_states&lt;-ifelse(apply(states,1,function(x){ any(apply(Known_mat,2,function(y){ all(x==t(y))})) }),2,NA) states$Clone &lt;- apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}) state_interactions$possible&lt;-ifelse(apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) sum(abs(A-B))&lt;=1 }),2,NA) dat&lt;-acast(Var1~Var2,value.var=&quot;possible&quot;,data=data.frame(state_interactions, &quot;value&quot;=-1)) diag(dat)&lt;-0 lowerTriangle(dat)&lt;-NA test_dat&lt;-do.call(cbind,lapply(colnames(dat),function(Clone){ if(Clone%in%names(weights)){ output&lt;-ifelse(dat[,Clone]==2,weights[Clone],dat[,Clone]) } else{ output&lt;-dat[,Clone] } return(output) })) colnames(test_dat) &lt;-rownames(test_dat) graph&lt;-graph.adjacency(test_dat,mode=&quot;directed&quot;,weighted=TRUE) graph_mat &lt;- get.data.frame(graph)%&gt;% drop_na() subgraphs&lt;-make_ego_graph(graph_from_data_frame(graph_mat,directed=TRUE), order=1,nodes=names(weights), mode=&quot;all&quot;) subgraph_bind&lt;-do.call(rbind,lapply(subgraphs,get.data.frame)) %&gt;% distinct(to,from,weight, .keep_all = TRUE) subgraph_subset&lt;-subgraph_bind%&gt;%filter(!to%in%setdiff(setdiff(subgraph_bind$to,subgraph_bind$from),names(weights))) return(subgraph_subset) } create_reward_matrix&lt;-function(Known_mat,weights){ set.seed(68864) names(weights) &lt;- apply(Known_mat,2,function(x){paste(x,sep=&quot;_&quot;,collapse=&quot;_&quot;)}) num_type &lt;- 2 num_mutations &lt;- nrow(Known_mat); mutant_names&lt;-rownames(Known_mat) num_clones &lt;- ncol(Known_mat) num_states &lt;- num_type^num_mutations possible_mut_list&lt;- unlist(apply(Known_mat,1,function(x){list(0:max(unique(x))) }),recursive = FALSE) states&lt;-data.frame(expand.grid(possible_mut_list)) state_interactions&lt;-data.frame(expand.grid(apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}), apply(states[,1:num_mutations],1,function(x){paste(x,collapse=&quot;_&quot;,sep=&quot;_&quot;)}))) state_interactions$possible&lt;-ifelse(apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) sum(abs(A-B))&lt;=1 }),0,NA) state_interactions$action&lt;-apply(state_interactions,1,function(x){ A&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[1]),split=&quot;_&quot;))) B&lt;-as.numeric(do.call(cbind,strsplit(as.character(x[2]),split=&quot;_&quot;))) if(!is.na(x[&quot;possible&quot;])){ if(sum(abs(B-A))==0){ return(&quot;stay&quot;) } else{ return(mutant_names[which((B-A)==1)]) } } }) dat&lt;-setNames(state_interactions%&gt;%filter(action%in%c(mutant_names,&quot;stay&quot;)), c(&quot;State&quot;,&quot;NextState&quot;,&quot;Reward&quot;,&quot;Action&quot;))[,c(1,4,2,3)] dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$NextState%in%names(weights),weights[x$NextState],x$Reward) })) dat$Reward &lt;- as.numeric(apply(dat,1,function(x){ ifelse(x$Action%in%&quot;stay&quot;,0,x$Reward) })) dat$State &lt;- as.character(dat$State) dat$NextState &lt;- as.character(dat$NextState) dat$Action &lt;- as.character(dat$Action) control &lt;- list(alpha = 0.8, gamma = 0.9) model &lt;- ReinforcementLearning(data = dat, s = &quot;State&quot;, a = &quot;Action&quot;, r = &quot;Reward&quot;, s_new = &quot;NextState&quot;, iter = 1,control=control) x&lt;- model$Q rownames(x) &lt;- substring(rownames(x),2) Q_mat &lt;- setNames(melt(x),c(&quot;State&quot;,&quot;Action&quot;,&quot;Q&quot;)) set&lt;-inner_join(dat,Q_mat,by=c(&quot;State&quot;,&quot;Action&quot;)) set$Valid &lt;- TRUE return(set) } plot_clonal_heatmap_and_barplot_with_SD &lt;-function(sample,output_folder,clonal_abundance,clonal_architecture,clone_cell_count,shrink) { clonal_abundance_subset &lt;-data.frame( clonal_abundance[[sample]])#%&gt;%filter(Count&gt;=5) clones_to_use &lt;- intersect(as.character(clonal_abundance_subset$Clone),as.character(clonal_architecture[[sample]]$Clone)) clonal_architecture_subset &lt;- data.frame(clonal_architecture[[sample]])%&gt;% filter(data.frame(clonal_architecture[[sample]])$Clone%in%clones_to_use) clonal_abundance_subset &lt;- data.frame(clonal_abundance_subset)%&gt;% filter(Clone%in%clones_to_use) genes_to_display &lt;-unique(as.character(clonal_architecture_subset[clonal_architecture_subset$Genotype%in%c(&quot;Heterozygous&quot;,&quot;Homozygous&quot;),&quot;Mutant&quot;])) if(shrink==TRUE){ clonal_architecture_subset &lt;-clonal_architecture_subset%&gt;%filter(Mutant%in%genes_to_display) } clonal_architecture_subset$Clone &lt;- factor(clonal_architecture_subset$Clone, levels=rev(clonal_abundance_subset$Clone)) clonal_abundance_subset$Clone &lt;- factor(clonal_abundance_subset$Clone, levels=levels(clonal_architecture_subset$Clone)) gg_heatmap &lt;- ggplot(data = clonal_architecture_subset, aes(x = Clone, y = factor(Mutant,levels=rev(levels(factor(Mutant)))), fill = Genotype)) + geom_tile() +# scale_y_discrete(limits = rev(levels(Mutant)))+ scale_fill_manual(values=c(&quot;WT&quot;=brewer.pal(7,&quot;Reds&quot;)[1], &quot;Heterozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[3], &quot;Homozygous&quot;=brewer.pal(7,&quot;Reds&quot;)[6], &quot;Unknown&quot;=&quot;grey50&quot;),&quot;Genotype&quot;) + theme_classic(base_size=6) + ylab(&quot;Mutation&quot;)+ theme(legend.position = &quot;bottom&quot;, legend.direction = &quot;horizontal&quot;, axis.text.x = element_blank(), axis.line=element_blank(), axis.title.x=element_blank(), axis.ticks.x = element_blank(), plot.margin=unit(c(0,1,1,1),&quot;cm&quot;)) # Generate clonal abundance barplot gg_clonal_barplot &lt;- ggplot(data = data.frame(clonal_abundance_subset), aes(x = Clone, y = Count)) + geom_bar(stat = &quot;identity&quot;, aes(fill = Count)) + theme_gray() + theme_classic(base_size=6)+ ylim(0,max(clonal_abundance_subset$Count)*1.3) + ylab(&quot;Cell Count&quot;)+ geom_errorbar(aes(ymin = X2.5., ymax = X97.5.), width = 0.2)+ geom_text(aes(label=Count), position=position_dodge(width=0.9), vjust=-0.25,size=1)+ scale_fill_distiller(name = &quot;Value&quot;, palette = &quot;Reds&quot;, direction = 1) + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line=element_blank(), legend.position = &quot;none&quot;, plot.margin=unit(c(1,1,-0.2,1),&quot;cm&quot;)) grob.title &lt;- textGrob(paste(sample,&quot;-&quot;), hjust= 0.5, vjust = 0.5, gp = gpar(fontsize = 12)) final_plot&lt;-plot_grid(grob.title,gg_clonal_barplot,gg_heatmap,ncol=1,align=&quot;hv&quot;,axis=&quot;l&quot;,rel_heights = c(0.1,1,0.75)) save_plot(paste(output_folder,sample,&quot;.pdf&quot;,sep=&quot;&quot;),final_plot, ncol=1) # Open a new pdf file } query_initiating_mutations&lt;-function(graph_results){ start_index&lt;-paste(rep(0,length(strsplit(graph_results$State[1],split=&quot;_&quot;)[[1]])),sep=&quot;_&quot;,collapse=&quot;_&quot;) possible_starting_actions&lt;-graph_results%&gt;%filter(State==start_index&amp;Action!=&quot;stay&quot;)%&gt;%pull(Action) final_results&lt;-list() initating_action_count&lt;-0 for(initating_action in possible_starting_actions){ print(initating_action) set &lt;- graph_results initating_action_count&lt;-initating_action_count+1 storage_results&lt;- list() branches&lt;-0 state_to_kill &lt;- set%&gt;%filter(State==start_index&amp;Action==initating_action)%&gt;%pull(NextState) start_killed &lt;- sum(set%&gt;%filter(State==state_to_kill)%&gt;%pull(Valid)) while(start_killed&gt;0){ #print(branches) # print(start_killed) branches &lt;- branches +1 number_of_mutations&lt;-0 state_log&lt;- list() optimal_reward&lt;-list() action_log&lt;-list() current_state&lt;- start_index indicator&lt;-TRUE nextState&lt;-0 while(current_state!=nextState) { # print(number_of_mutations) number_of_mutations &lt;- number_of_mutations+1 if(number_of_mutations==1){ state_log[[number_of_mutations]] &lt;- start_index } current_state &lt;- state_log[[number_of_mutations]] nextState_indicator&lt;- FALSE while(nextState_indicator==FALSE){ if(number_of_mutations==1){ max_potential_action_index&lt;- set%&gt;% filter(State==current_state&amp;Action==initating_action) } else { max_potential_action_index &lt;- set%&gt;% filter(State==current_state&amp;Valid==TRUE)%&gt;% filter(Q==max(Q))%&gt;%sample_n(1) } if(nrow(max_potential_action_index)==0){ break } max_potential_action &lt;- max_potential_action_index%&gt;%pull(NextState) next_valid_action &lt;- any(set%&gt;%filter(State==max_potential_action&amp;Action!=&quot;stay&quot;)%&gt;%pull(Valid)) if(next_valid_action==TRUE){ nextState &lt;-max_potential_action current_action &lt;- max_potential_action_index%&gt;%pull(Action) nextState_indicator==TRUE break } else{ set[set$State%in%max_potential_action_index[&quot;State&quot;]&amp; set$Action%in%max_potential_action_index[&quot;Action&quot;],&quot;Valid&quot;] &lt;- FALSE } } if(nrow(set%&gt;%filter(State==current_state&amp;Action==current_action))==0){ optimal_reward[[number_of_mutations]] &lt;-NA } else { optimal_reward[[number_of_mutations]] &lt;- set%&gt;% filter(State==current_state&amp;Action==current_action)%&gt;% pull(Reward) } state_log[[number_of_mutations+1]]&lt;- nextState action_log[[number_of_mutations]] &lt;- current_action if(current_action==nextState){ indicator==FALSE state_log[[number_of_mutations+1]]&lt;-NULL break } } optimal_reward[[number_of_mutations+1]] &lt;- NA action_log[[number_of_mutations+1]] &lt;- NA storage_results[[branches]] &lt;-data.frame(&quot;states&quot;=do.call(rbind,state_log),#[1:(length(state_log)-1)]), &quot;actions&quot;=do.call(rbind,action_log), &quot;reward&quot;=do.call(rbind,optimal_reward), &quot;nextState&quot;=do.call(rbind,c(state_log[2:length(state_log)],NA)) ) storage_results[[branches]] &lt;- storage_results[[branches]]%&gt;% filter(states!=nextState) storage_results[[branches]]$cumulative_reward &lt;- cumsum(storage_results[[branches]]$reward) #storage_results[[branches]] &lt;-storage_results[[branches]][1:which.max(storage_results[[branches]]$cumulative_reward), ] set[set$State%in%current_state&amp;set$Action%in%current_action,&quot;Valid&quot;] &lt;- FALSE start_killed &lt;- sum(set%&gt;%filter(State==state_to_kill)%&gt;%pull(Valid)) } final_results[[initating_action_count]]&lt;-storage_results[!duplicated(storage_results)] } names(final_results)&lt;-possible_starting_actions return(final_results) } "],["references.html", "References", " References "]]
